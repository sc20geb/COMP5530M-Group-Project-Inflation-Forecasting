{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine data and Cleaning\n",
    "This notebook:\n",
    "* combines all the exogenous data\n",
    "* removes exogenous variables that start too late or end too early\n",
    "* performs grangers causality test to then remove non-useful exogenous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbookdir = Path.cwd() #path to current folder\n",
    " \n",
    "datasetsPath= workbookdir.parent / 'Data' /'Raw' #Path to data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare start and end dates\n",
    "**Change these values to alter the dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#could import helper and use as suggested below\n",
    "#from data_manipulation_helpers import getTestDate\n",
    "START_YEAR=1990\n",
    "END_YEAR=2024\n",
    "TEST_DATE= datetime(2024,1,1).strftime('%m/%Y')\n",
    "#usage example (first argument is the test set size ratio)\n",
    "#TEST_DATE = getTestDate(0.1, START_YEAR, END_YEAR)\n",
    "\n",
    "TARGET='PCEPI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values are used to detect discontinued data or data which starts after the starting period.\n",
    "If an exogenous vatiable starts 6 months late or ends 6 months early, it will be **dropped**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startDate= datetime(START_YEAR,1,1).strftime('%m/%Y')\n",
    "startDate_plus_half_year=datetime(START_YEAR,6,1).strftime('%m/%Y')\n",
    "endDate= datetime(END_YEAR,12,1,1).strftime('%m/%Y')\n",
    "endDate_minus_half_year=datetime(END_YEAR,7,1).strftime('%m/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Data:\n",
    "### Useful functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manipulation_helpers import str_to_float, rename_cols, remove_percent, interpolateAndRoundColumn, getMissingCols, printMissingCols, is_granger_caused"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import fred data\n",
    "this data includes the target variable (PCEPI **and its varients**) and has been combined from fred: https://fred.stlouisfed.org/categories\n",
    "\n",
    "Fred kindly allows data to be combined into a data list, which can then be downloaded (instead of indivigually downloading each dataset and then combining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly data has been split into 3 CSV files and needs to be combined:\n",
    "\n",
    "#read dataframes:\n",
    "df1= pd.read_csv(datasetsPath/'monthly_1.csv', parse_dates=[0])\n",
    "df2= pd.read_csv(datasetsPath/'monthly_2.csv', parse_dates=[0])\n",
    "df3= pd.read_csv(datasetsPath/'monthly,_end_of_period.csv', parse_dates=[0])\n",
    "\n",
    "#Make a date-time index\n",
    "df1 = df1.set_index(['observation_date'],drop = True)\n",
    "df2 = df2.set_index(['observation_date'],drop = True)\n",
    "df3 = df3.set_index(['observation_date'],drop = True)\n",
    "\n",
    "#Combine Monthly data:\n",
    "combinedDf= pd.concat([df1,df2,df3],axis=1,join='outer')\n",
    "\n",
    "\n",
    "#Rename and display combined data:\n",
    "rename_cols(combinedDf,'fred')\n",
    "display(combinedDf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fred_TERMCBAUTO48NS and fred_TERMCBPER24NS are not actually monthly, but mid-quarterly. Linearly interpolate between observation dates (as is performed in FRED visualisation) to give 01/01/1990 date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDf = interpolateAndRoundColumn(combinedDf, 'fred_TERMCBAUTO48NS', method='linear')\n",
    "combinedDf = interpolateAndRoundColumn(combinedDf, 'fred_TERMCBPER24NS', method='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fred quarterly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine quarterly data:\n",
    "\n",
    "fred_quartely_1= pd.read_csv(datasetsPath/'quarterly.csv', parse_dates=[0])\n",
    "fred_quartely_2= pd.read_csv(datasetsPath/'quarterly,_end_of_quarter.csv', parse_dates=[0])\n",
    "fred_quartely_3= pd.read_csv(datasetsPath/'quarterly,_end_of_period.csv', parse_dates=[0])\n",
    "\n",
    "# Set Date-time index\n",
    "fred_quartely_1 = fred_quartely_1.set_index(['observation_date'],drop = True)\n",
    "fred_quartely_2 = fred_quartely_2.set_index(['observation_date'],drop = True)\n",
    "fred_quartely_3 = fred_quartely_3.set_index(['observation_date'],drop = True)\n",
    "\n",
    "#Combine data:\n",
    "quarterly=pd.concat([fred_quartely_1,fred_quartely_2,fred_quartely_3],axis=1,join='outer')\n",
    "\n",
    "\n",
    "# Remove data which starts too late or ends to early (used to find the quarterly feature names so they font get removed for having too mant null values (nature of converting quarterly to monthly)):\n",
    "late_data=quarterly.loc[startDate:startDate_plus_half_year].isna().all().loc[quarterly.loc[startDate:startDate_plus_half_year].isna().all()==True].index\n",
    "quarterly.drop(late_data,axis=1,inplace=True)\n",
    "early_data=quarterly.loc[endDate_minus_half_year:endDate].isna().all().loc[quarterly.loc[endDate_minus_half_year:endDate].isna().all()==True].index\n",
    "quarterly.drop(early_data,axis=1,inplace=True)\n",
    "\n",
    "#Rename:\n",
    "rename_cols(quarterly,'fred')\n",
    "\n",
    "quarterlyCols=quarterly.columns # Save the column names\n",
    "\n",
    "#Combine with monthly data:\n",
    "combinedDf= pd.concat([combinedDf,quarterly],axis=1,join='outer')\n",
    "combinedDf= combinedDf.loc[startDate:endDate]\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the index to month/year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDf.set_index(pd.to_datetime(pd.Series(combinedDf.index)).dt.strftime('%m/%Y'),drop = True,inplace=True)\n",
    "combinedDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fred daily and weekly data\n",
    "**aggregates data for each month into one value**\n",
    "Achieves this by removing data which starts too late or ends too early (same as later), then takes the arithmetic mean for that month.\n",
    "\n",
    "**NOTE:** arithmetic mean should not be used for variables which involve change/percentage change/rates of change (geometric or harmonic means must be used instead). However for the sake of simplicity, all variables involving changes have been dropped excluding their levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read daily data\n",
    "dailyDf=pd.read_csv(datasetsPath/'daily.csv', parse_dates=[0])\n",
    "\n",
    "# Change to date-time index\n",
    "dailyDf = dailyDf.set_index(['observation_date'],drop = True)\n",
    "\n",
    "\n",
    "# Remove data that starts too late or ends too early:\n",
    "late_data=dailyDf.loc[startDate:startDate_plus_half_year].isna().all().loc[dailyDf.loc[startDate:startDate_plus_half_year].isna().all()==True].index\n",
    "dailyDf.drop(late_data,axis=1,inplace=True)\n",
    "early_data=dailyDf.loc[endDate_minus_half_year:endDate].isna().all().loc[dailyDf.loc[endDate_minus_half_year:endDate].isna().all()==True].index\n",
    "dailyDf.drop(early_data,axis=1,inplace=True)\n",
    "\n",
    "# Select the data with the dates of interest\n",
    "dailyDf= dailyDf.loc[startDate:endDate]\n",
    "\n",
    "# Remove features involving change:\n",
    "dropCols= []\n",
    "\n",
    "for i in dailyDf.columns:\n",
    "    if '_' in i:\n",
    "        dropCols.append(i)\n",
    "\n",
    "dailyDf.drop(dropCols,axis=1,inplace=True)\n",
    "\n",
    "# Take the mean of the month:\n",
    "dailyDf=dailyDf.resample('M').mean()\n",
    "\n",
    "# Rename columns\n",
    "rename_cols(dailyDf,'fred')\n",
    "\n",
    "display(dailyDf)\n",
    "dailyDf.set_index(pd.to_datetime(pd.Series(dailyDf.index)).dt.strftime('%m/%Y'),drop = True,inplace=True)\n",
    "\n",
    "# Combine data\n",
    "combinedDf=pd.merge(combinedDf,dailyDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read weekly data:\n",
    "weeklyDf=pd.read_csv(datasetsPath/'weekly,_ending_thursday.csv', parse_dates=[0])\n",
    "weeklyDf = weeklyDf.set_index(['observation_date'],drop = True)\n",
    "\n",
    "# Remove data that starts too late or ends too early:\n",
    "late_data=weeklyDf.loc[startDate:startDate_plus_half_year].isna().all().loc[weeklyDf.loc[startDate:startDate_plus_half_year].isna().all()==True].index\n",
    "weeklyDf.drop(late_data,axis=1,inplace=True)\n",
    "early_data=weeklyDf.loc[endDate_minus_half_year:endDate].isna().all().loc[weeklyDf.loc[endDate_minus_half_year:endDate].isna().all()==True].index\n",
    "weeklyDf.drop(early_data,axis=1,inplace=True)\n",
    "\n",
    "# Select the data with the dates of interest\n",
    "weeklyDf= weeklyDf.loc[startDate:endDate]\n",
    "\n",
    "# Remove features involving change:\n",
    "dropCols= []\n",
    "\n",
    "for i in weeklyDf.columns:\n",
    "    if '_' in i:\n",
    "        dropCols.append(i)\n",
    "\n",
    "weeklyDf.drop(dropCols,axis=1,inplace=True)\n",
    "\n",
    "# Take the mean of the month:\n",
    "weeklyDf=weeklyDf.resample('M').mean()\n",
    "\n",
    "# rename columns\n",
    "rename_cols(weeklyDf,'fred')\n",
    "\n",
    "display(weeklyDf)\n",
    "weeklyDf.set_index(pd.to_datetime(pd.Series(weeklyDf.index)).dt.strftime('%m/%Y'),drop = True,inplace=True)\n",
    "\n",
    "# combine:\n",
    "combinedDf=pd.merge(combinedDf,weeklyDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other exogenous Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crude oil:\n",
    "https://www.investing.com/commodities/crude-oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='CrudeOilWTI'\n",
    "\n",
    "#read data:\n",
    "tempDf= pd.read_csv(datasetsPath/f'{name}.csv', parse_dates=[0])\n",
    "\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y') # convert to just month and year\n",
    "#set date as index\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "#remove the order of magnitude symbols:\n",
    "tempDf['Vol.']=tempDf['Vol.'].apply(str_to_float)\n",
    "\n",
    "# Remove percent sign:\n",
    "tempDf['Change %']=tempDf['Change %'].apply(remove_percent)\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brent oil:\n",
    "https://www.investing.com/commodities/brent-oil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='BrentOil'\n",
    "\n",
    "tempDf= pd.read_csv(datasetsPath/f'{name}.csv', parse_dates=[0])\n",
    "\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "#remove the order of magnitude symbols:\n",
    "tempDf['Vol.']=tempDf['Vol.'].apply(str_to_float)\n",
    "\n",
    "# Remove percent sign:\n",
    "tempDf['Change %']=tempDf['Change %'].apply(remove_percent)\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Gas (Henry Hub Natural Gas Spot Price Dollars per Million Btu):\n",
    "https://www.eia.gov/dnav/ng/hist/rngwhhdm.htm\n",
    "\n",
    "(replaced original investing.com offer of futures (https://www.investing.com/commodities/natural-gas), since this had missing data from the first 3 months)\n",
    "\n",
    "**Removed as could not find a dataset containing the first 4 months of 1990.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold:\n",
    "https://www.investing.com/commodities/gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='Gold'\n",
    "\n",
    "tempDf= pd.read_csv(datasetsPath/f'{name}.csv', parse_dates=[0])\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "#remove the order of magnitude symbols:\n",
    "tempDf['Vol.']=tempDf['Vol.'].apply(str_to_float)\n",
    "\n",
    "# Remove percent sign:\n",
    "tempDf['Change %']=tempDf['Change %'].apply(remove_percent)\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silver:\n",
    "https://www.investing.com/commodities/silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='Silver'\n",
    "\n",
    "tempDf= pd.read_csv(datasetsPath/f'{name}.csv', parse_dates=[0])\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "#remove the order of magnitude symbols:\n",
    "tempDf['Vol.']=tempDf['Vol.'].apply(str_to_float)\n",
    "\n",
    "# Remove percent sign:\n",
    "tempDf['Change %']=tempDf['Change %'].apply(remove_percent)\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copper:\n",
    "https://www.investing.com/commodities/copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='Copper'\n",
    "\n",
    "tempDf= pd.read_csv(datasetsPath/f'{name}.csv', parse_dates=[0])\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "#remove the order of magnitude symbols:\n",
    "tempDf['Vol.']=tempDf['Vol.'].apply(str_to_float)\n",
    "\n",
    "# Remove percent sign:\n",
    "tempDf['Change %']=tempDf['Change %'].apply(remove_percent)\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US Soybean:\n",
    "Already included via the FRED-derived PSOYBUSDM variable (which has better coverage from 1990-)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baltic Dry Index:\n",
    "https://uk.investing.com/indices/baltic-dry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='BalticDryIndex'\n",
    "\n",
    "tempDf= pd.read_csv(datasetsPath/f'{name}.csv', parse_dates=[0],dayfirst=True)\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "\n",
    "tempDf.drop('Vol.',axis=1,inplace=True)# vol. not used\n",
    "\n",
    "# Remove percent sign:\n",
    "tempDf['Change %']=tempDf['Change %'].apply(remove_percent)\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nasdaq Composite\n",
    "https://www.investing.com/indices/nasdaq-composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name='NASDAQComposite'\n",
    "\n",
    "tempDf= pd.read_csv(datasetsPath/f'{name}.csv', parse_dates=[0],dayfirst=True)\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "tempDf.drop('Vol.',axis=1,inplace=True)# vol. not used\n",
    "\n",
    "# Remove percent sign:\n",
    "tempDf['Change %']=tempDf['Change %'].apply(remove_percent)\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P 500\n",
    "https://www.investing.com/indices/us-spx-500-historical-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='SP500'\n",
    "\n",
    "tempDf= pd.read_csv(datasetsPath/f'{name}.csv', parse_dates=[0])\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "tempDf.drop('Vol.',axis=1,inplace=True) # vol. not used\n",
    "# Remove percent sign:\n",
    "tempDf['Change %']=tempDf['Change %'].apply(remove_percent)\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOE VIX\n",
    "Chicago Board Options Exchange Volatility Index\n",
    "https://www.investing.com/indices/volatility-s-p-500-historical-data\n",
    "\n",
    "Augmented with 01/01/1990 data from\n",
    "https://finance.yahoo.com/quote/%5EVIX/history/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAANwY8S-Sgd81YqLYXYfh9HiLXqf649edKr-K5ZwFLKKG9jKBZwoE1VPX7-CHVWmn2KtIsjlk8mRQmccZsAXuwrw1jzb1LO-owPdHemT5Y5tsgIbcB9T4JxwkPlOORz4svx8Vj8wNyGIatWqcKw5iWTnpnH4Szw6VynT1gnTn3rHf&frequency=1mo&period1=631267200&period2=1741608394\n",
    "\n",
    "This matches the main dataset, but includes earlier dates from which the first datapoint needed (January 1990) can be derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='CBOEVIX'\n",
    "\n",
    "tempDf= pd.read_csv(datasetsPath/f'{name}.csv', parse_dates=[0])\n",
    "display(tempDf['Date'])\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "tempDf.drop('Vol.',axis=1,inplace=True) # vol. not used\n",
    "# Remove percent sign:\n",
    "tempDf['Change %']=tempDf['Change %'].apply(remove_percent)\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "#display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "#display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### food price indices data\n",
    "\n",
    "https://www.fao.org/worldfoodsituation/foodpricesindex/en/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='food_price_indices_data_f'\n",
    "\n",
    "tempDf= pd.read_csv(datasetsPath/f'{name}.csv', parse_dates=[0],header=2,usecols=list(range(0,7)))\n",
    "tempDf.drop(0,axis=0,inplace=True)\n",
    "\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCI\n",
    "https://www.oecd.org/en/data/indicators/business-confidence-index-bci.html?oecdcontrol-b2a0dbca4d-var3=1974-06&oecdcontrol-b2a0dbca4d-var4=2024-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='BCI'\n",
    "\n",
    "tempDf= pd.read_csv(datasetsPath/f'{name}.csv', parse_dates=[0])\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "tempDf.sort_index(inplace=True)\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gscpi\n",
    "https://www.newyorkfed.org/research/policy/gscpi#/interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='gscpi_data'\n",
    "\n",
    "tempDf= pd.read_excel(datasetsPath/f'{name}.xls',sheet_name='GSCPI_Monthly_Data',engine=None,skiprows=4,names=['Date','gscpi'],usecols=[0,1])\n",
    "\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UK policy uncertainty Index\n",
    "https://www.policyuncertainty.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='UK_Policy_Uncertainty_Data'\n",
    "\n",
    "tempDf= pd.read_excel(datasetsPath/f'{name}.xlsx',engine=None,skipfooter=1)\n",
    "\n",
    "tempDf['Date']=tempDf['year'].astype(str)+'/'+tempDf['month'].astype(str)\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "\n",
    "tempDf.drop(['year','month'],axis=1,inplace=True)\n",
    "\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US policy uncertainty Index\n",
    "https://www.policyuncertainty.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='US_Policy_Uncertainty_Data'\n",
    "\n",
    "tempDf= pd.read_excel(datasetsPath/f'{name}.xlsx',sheet_name='Main Index',engine=None,skipfooter=1)\n",
    "\n",
    "#Combine year and month columns to form a date:\n",
    "tempDf['Date']=tempDf['Year'].astype(str)+'/'+tempDf['Month'].astype(str)\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "\n",
    "tempDf.drop(['Year','Month'],axis=1,inplace=True)\n",
    "\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='US_Policy_Uncertainty_Data'\n",
    "\n",
    "tempDf= pd.read_excel(datasetsPath/f'{name}.xlsx',sheet_name='Components',engine=None,skipfooter=1)\n",
    "\n",
    "#Combine year and month columns to form a date:\n",
    "tempDf['Date']=tempDf['Year'].astype(str)+'/'+tempDf['Month'].astype(str)\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "\n",
    "tempDf.drop(['Year','Month'],axis=1,inplace=True)\n",
    "\n",
    "tempDf.set_index(['Date'],drop = True,inplace=True)\n",
    "\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### World Bank Commodity Price Data\n",
    "https://thedocs.worldbank.org/en/doc/5d903e848db1d1b83e0ec8f744e55570-0350012021/related/CMO-Historical-Data-Monthly.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='CMO-Historical-Data-Monthly'\n",
    "\n",
    "tempDf= pd.read_excel(datasetsPath/f'{name}.xlsx',sheet_name='Monthly Prices',engine=None,skiprows=4)\n",
    "tempDf.drop(0,axis=0,inplace=True)\n",
    "\n",
    "#Replace M with '/' to turn it into a valid date:\n",
    "tempDf.iloc[:,0]=tempDf.iloc[:,0].str.replace('M','/')\n",
    "tempDf.iloc[:,0]=pd.to_datetime(tempDf.iloc[:,0]).dt.strftime('%m/%Y')\n",
    "\n",
    "tempDf.set_index(tempDf.columns[0],drop = True,inplace=True)\n",
    "\n",
    "#Drop already used features (and ['Barley','Sorghum','Wheat, US SRW'] because they contain '…' with different encodings):\n",
    "tempDf.drop(['Crude oil, average','Crude oil, Brent','Crude oil, Dubai','Crude oil, WTI', 'Natural gas, US','Natural gas, Europe','Liquefied natural gas, Japan',\n",
    "             'Natural gas index','Soybeans','Copper','Gold','Silver','Barley','Sorghum','Wheat, US SRW'],axis=1,inplace=True)\n",
    "\n",
    "# turn '…' into NaN\n",
    "tempDf.replace('…',pd.NA,inplace=True)\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf.iloc[-1,-1])\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='CMO-Historical-Data-Monthly'\n",
    "\n",
    "tempDf= pd.read_excel(datasetsPath/f'{name}.xlsx',sheet_name='Monthly Indices',engine=None,skiprows=8, names=['Date','Total_Index','Energy','Non_Energy','Agriculture',\n",
    "                                                                                                              'Beverages','Food','Oils_and_meals','Grains','Other_foods','Raw_materials',\n",
    "                                                                                                              'Timber','Other_raw_materials','Fertilizers','Metals_minerals','Base metals', 'Precious_metals'])\n",
    "#replace 'M' with slash to turn it into a date:\n",
    "tempDf['Date']=tempDf['Date'].str.replace('M','/')\n",
    "\n",
    "tempDf['Date']=pd.to_datetime(tempDf['Date']).dt.strftime('%m/%Y')\n",
    "tempDf.set_index(tempDf.columns[0],drop = True,inplace=True)\n",
    "\n",
    "\n",
    "rename_cols(tempDf,name)\n",
    "display(tempDf)\n",
    "\n",
    "combinedDf=pd.merge(combinedDf,tempDf,how= 'left',left_index=True,right_index=True)\n",
    "display(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FTSE 100\n",
    "https://uk.finance.yahoo.com/quote/%5EFTSE/\n",
    "\n",
    "(**Data contains errorous dates hence why it has been excluded**)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for duplicate values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDf.index.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove late/early data:\n",
    "Remove data that misses the first 6 months of `START_YEAR` **or** the last 6 months of `END_YEAR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "late_data=combinedDf.loc[startDate:startDate_plus_half_year].isna().all().loc[combinedDf.loc[startDate:startDate_plus_half_year].isna().all()==True].index\n",
    "for i in late_data:\n",
    "    print(i)\n",
    "\n",
    "combinedDf.drop(list(late_data),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_data=combinedDf.loc[endDate_minus_half_year:endDate].isna().all().loc[combinedDf.loc[endDate_minus_half_year:endDate].isna().all()==True].index\n",
    "#for i in early_data:\n",
    "#    print(i)\n",
    "\n",
    "combinedDf.drop(list(early_data),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combinedDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(combinedDf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cols=combinedDf.drop(quarterlyCols,axis=1).isna().sum(axis=0).loc[combinedDf.drop(quarterlyCols,axis=1).isna().sum(axis=0)>combinedDf.shape[0]//5]\n",
    "\n",
    "#display(null_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon further inspection for TB1YR, there is a big gap between 2001 and 2008. hence all data relating to this variable should be removed (https://fred.stlouisfed.org/series/TB1YR).\n",
    "\n",
    "For TERMCBAUTO48NS and TERMCBPER24NS the data doesnt seem to be released every month all the time henc the number of missing values, hence the levels can stay (and be interpolated) however percentage changes related to this variable should be dropped (https://fred.stlouisfed.org/series/TERMCBAUTO48NS \n",
    "\n",
    "https://fred.stlouisfed.org/series/TERMCBPER24NS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDf.drop([\n",
    "'fred_TB1YR'\n",
    ",'fred_TB1YR_LOG'\n",
    ",'fred_TB1YR_CH1'\n",
    ",'fred_TB1YR_PC1'\n",
    ",'fred_TERMCBAUTO48NS_CH1'\n",
    ",'fred_TERMCBAUTO48NS_LOG'\n",
    ",'fred_TERMCBAUTO48NS_PC1'\n",
    ",'fred_TERMCBPER24NS_CH1'\n",
    ",'fred_TERMCBPER24NS_LOG'\n",
    ",'fred_TERMCBPER24NS_PC1'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform linear interpolation for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingCols = getMissingCols(combinedDf, prin=True)\n",
    "print(missingCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDf.interpolate(method='linear',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle remaining missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CCA - Continuously compounded annual rate of change\n",
    "- CCH - Continuously compounded rate of change\n",
    "- CHG - Change (from yesterday)\n",
    "- PCA - Compounded annual rate of change\n",
    "- PCH - Percentage change (not annually adjusted)\n",
    "\n",
    "Each of these require one previous value to be defined, hence the initial missing values.\n",
    "Set each of these initial values to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = ['CCA', 'CCH', 'CHG', 'PCA', 'PCH']\n",
    "colsToChange = [col for col in missingCols if col[-3:] in changes]\n",
    "\n",
    "for i in range(len(colsToChange)):\n",
    "    combinedDf.loc[combinedDf.index[0], colsToChange[i]] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some columns are uninterpolatable, let's check them out\n",
    "missingCols = getMissingCols(combinedDf, prin=True)\n",
    "print(f'{len(missingCols)} columns containing missing values.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FRED data missing January 1990 (due to mid-quarter observations) has been interpolated from previous data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fred_DRTSCILM is quarterly and only began in the second quarter of 1990. There is no way of gathering any previous data on this variable, so in order to avoid nulls this column must be dropped.\n",
    "The same applies to the NaturalGas variables, since these started in June 1990."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDf.drop(labels=[colName for colName in combinedDf.columns if 'fred_DRTSCILM' in colName], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingCols(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 25%-broken Thai rice discontinuity could be linearly interpolated, but 2008 discontinuity is more protracted (5 months), during a period of instability, and the July 2008 price may be unreliable (exactly $700.00 as an average over all rice exports of this kind?) Also already have an indicator on 5%-broken Thai rice, so 25%-broken also likely not useful. Drop.\n",
    "\n",
    "Cameroonian Sawnwood data too infrequent and lacking granularity - roughly collected once per year every 5 years. Drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDf.drop(labels=['CMO-Historical-Data-Monthly_Rice, Thai 25% ', 'CMO-Historical-Data-Monthly_Sawnwood, Cameroon'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingCols(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-month discontinuity for Phosphate rock in November 2023, price then more than halves in December compared to October. Index Mundi (https://www.indexmundi.com/commodities/?commodity=rock-phosphate&months=360) suggests price remained at the same level as October for this month before prices changed, so this will be inserted as an imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDf.loc['11/2023', 'CMO-Historical-Data-Monthly_Phosphate rock'] = combinedDf.loc['10/2023', 'CMO-Historical-Data-Monthly_Phosphate rock']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMissingCols(combinedDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert all remaining non-numeric columns to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedDf = combinedDf.infer_objects(copy=False)\n",
    "objectCols = [i for i, el in enumerate(list(combinedDf.dtypes)) if 'float64' not in str(el)]\n",
    "print(objectCols)\n",
    "for col in objectCols:\n",
    "    combinedDf.iloc[:, col] = combinedDf.iloc[:, col].apply(str_to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that there are now no remaining object columns\n",
    "print([i for i, el in enumerate(list(combinedDf.dtypes)) if 'float64' not in str(el)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First remove other PCEPI information to prevent dataleakage:\n",
    "TargetCol=  combinedDf['fred_'+TARGET].copy()\n",
    "combinedDf.drop([\n",
    "'fred_PCEPI',\n",
    "'fred_PCEPI_CCA',\n",
    "'fred_PCEPI_CCH',\n",
    "'fred_PCEPI_CH1',\n",
    "'fred_PCEPI_CHG',\n",
    "'fred_PCEPI_PC1',\n",
    "'fred_PCEPI_PCA',\n",
    "'fred_PCEPI_PCH',\n",
    "'fred_PCEPI_LOG'],\n",
    "axis=1, inplace=True)\n",
    "\n",
    "X_trainDf= combinedDf.iloc[:combinedDf.index.get_loc(TEST_DATE),:]\n",
    "X_testDf= combinedDf.iloc[combinedDf.index.get_loc(TEST_DATE):,:]\n",
    "\n",
    "y_trainDf= TargetCol.iloc[:TargetCol.index.get_loc(TEST_DATE)]\n",
    "y_testDf= TargetCol.iloc[TargetCol.index.get_loc(TEST_DATE):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Granger Causality test:\n",
    "Granger causality test is used to determine if an exogenous variable causes (granger causes) inflation. This hypothesis test assumes the timeseries are stationary, therefore the timeseries should be proccessed accordingly.\n",
    "\n",
    "To test for stationarity, Augmented Dickey-Fuller test is used with a significance level of 5%.\n",
    "\n",
    "The Granger causality test also uses a significance level of 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keepCols=[]# keeps granger caused columns\n",
    "\n",
    "# Iterate over all columns and test for granger causality\n",
    "for i in X_trainDf.columns:\n",
    "    if is_granger_caused(i, y_trainDf, X_trainDf):\n",
    "        keepCols.append(i)\n",
    "    \n",
    "print(len(keepCols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caused_train_df= pd.concat([y_trainDf,X_trainDf[keepCols]],axis=1)\n",
    "caused_test_df= pd.concat([y_testDf,X_testDf[keepCols]],axis=1)\n",
    "\n",
    "display(caused_train_df)\n",
    "display(caused_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caused_train_df.to_csv(workbookdir.parent / 'Data' /'Train'/f'train{START_YEAR}s.csv')\n",
    "caused_test_df.to_csv(workbookdir.parent / 'Data' /'Test'/f'test{START_YEAR}s.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
