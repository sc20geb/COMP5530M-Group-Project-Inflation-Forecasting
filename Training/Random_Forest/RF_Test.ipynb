{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b69b1-8358-4424-8a98-0cbbe6a2c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Find project root –\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def find_project_root(start_at: Optional[Path] = None, max_levels: int = 6) -> Path:\n",
    "    here = start_at or Path.cwd()\n",
    "    for _ in range(max_levels):\n",
    "        if (here / \"Training\" / \"Helper\").is_dir():\n",
    "            return here.resolve()\n",
    "        if here.parent == here:\n",
    "            break\n",
    "        here = here.parent\n",
    "    raise RuntimeError(\"Cannot locate project root containing Training/Helper\")\n",
    "\n",
    "try:\n",
    "    _start = Path(__file__).resolve().parent  \n",
    "except NameError:  \n",
    "    _start = Path.cwd()\n",
    "\n",
    "PROJECT_ROOT = find_project_root(_start)\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Local imports\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from Training.Helper.dataPreprocessing import (\n",
    "    TRAIN_DATA_PATH_1990S,\n",
    "    TEST_DATA_PATH_1990S,\n",
    "    TRAIN_DATA_SPLIT,\n",
    "    build_feature_matrix, # New Func for builder \n",
    ")\n",
    "from Evaluation.Helper.evaluation_helpers import calc_metrics_arrays, display_results\n",
    "from Training.Helper.RF_hyperparameters import tune_rf  # New Optuna Functions are added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1868496-419a-4f84-aa5d-9688105f5fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Config\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "DATE_COL = \"observation_date\"\n",
    "RAW_TARGET_COL = \"fred_PCEPI\"  # original level series\n",
    "TARGET_COL = \"dlog_PCEPI\"      # modelled target = log‑diff\n",
    "EXOG_COLS = [\n",
    "    \"fred_AHETPI\",\n",
    "    \"fred_GDP\",\n",
    "    \"fred_PCUOMFGOMFG\",\n",
    "    \"fred_A053RC1Q027SBEA\",\n",
    "    \"fred_PPIACO\",\n",
    "    \"fred_TERMCBPER24NS\",\n",
    "]\n",
    "\n",
    "N_LAGS = 12\n",
    "RANDOM_STATE = 42\n",
    "N_OPTUNA_TRIALS = 40\n",
    "\n",
    "MODEL_DIR = PROJECT_ROOT / \"Training\" / \"Random_Forest\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PRED_DIR = PROJECT_ROOT / \"Predictions\"\n",
    "PRED_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351986e1-4e72-468f-bccc-3e6c6789e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Helpers\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def add_log_diff(df: pd.DataFrame, *, src: str, dest: str) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[dest] = np.log(df[src]).diff()\n",
    "    return df.dropna(subset=[dest]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def forward_fill_initial_lags(X: pd.DataFrame, last_known_row: pd.Series) -> pd.DataFrame:\n",
    "    #Fill NaNs in first N_LAGS lag rows from `last_known_row`\n",
    "    lag_cols = [f\"lag_{i}\" for i in range(1, N_LAGS + 1)]\n",
    "    X_ff = X.copy()\n",
    "    X_ff.loc[: N_LAGS - 1, lag_cols] = X_ff.loc[: N_LAGS - 1, lag_cols].fillna(\n",
    "        last_known_row[lag_cols]\n",
    "    )\n",
    "    return X_ff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ba8db2-373a-4d05-83a0-bb75ea2816a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Load & split\n",
    "# ---------------------------------------------------------------------------\n",
    "raw_train = (\n",
    "    pd.read_csv(TRAIN_DATA_PATH_1990S, parse_dates=[DATE_COL], date_format=\"%m/%Y\")\n",
    "    .query(f\"{DATE_COL} >= '1990-01-01'\")\n",
    "    .sort_values(DATE_COL)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "train_df = add_log_diff(raw_train, src=RAW_TARGET_COL, dest=TARGET_COL)\n",
    "X_all, y_all = build_feature_matrix(train_df, target_col=TARGET_COL, n_lags=N_LAGS, exog_cols=EXOG_COLS, drop_na=True)\n",
    "split = int(len(X_all) * TRAIN_DATA_SPLIT)\n",
    "X_tr, y_tr, X_val, y_val = X_all.iloc[:split], y_all.iloc[:split], X_all.iloc[split:], y_all.iloc[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d70239b-fa4b-4ed9-a139-6fcca83f42b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Pipeline & Optuna tuning (uses new cv_splits arg)\n",
    "# ---------------------------------------------------------------------------\n",
    "rf_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"rf\", RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1)),\n",
    "])\n",
    "\n",
    "best_params = tune_rf(rf_pipe, X_tr, y_tr, n_trials=N_OPTUNA_TRIALS, cv_splits=5, random_state=RANDOM_STATE)\n",
    "print(\"Best params:\", best_params)\n",
    "\n",
    "rf_pipe.fit(X_tr, y_tr)\n",
    "print(\"Val metrics:\\n\", calc_metrics_arrays(y_val.values.reshape(-1,1), rf_pipe.predict(X_val).reshape(-1,1), model_names=[\"RF tuned\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dba192-1cfe-4b0c-a07d-4fa92e0ea660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Re‑fit on **all** available data\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "rf_full = copy.deepcopy(rf_pipe)\n",
    "rf_full.fit(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba7c8b-2bde-45ed-820b-5b9c3a51c0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Test inference – forward‑fill + imputer\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "raw_test = pd.read_csv(TEST_DATA_PATH_1990S, parse_dates=[DATE_COL], date_format=\"%m/%Y\")\n",
    "raw_test = raw_test.sort_values(DATE_COL)\n",
    "raw_test[TARGET_COL] = np.log(raw_test[RAW_TARGET_COL]).diff()\n",
    "X_test, _ = build_feature_matrix(raw_test, target_col=TARGET_COL, n_lags=N_LAGS, exog_cols=EXOG_COLS, drop_na=False)\n",
    "\n",
    "last_train_feat, _ = build_feature_matrix(train_df.tail(N_LAGS+1), target_col=TARGET_COL, n_lags=N_LAGS, exog_cols=EXOG_COLS)\n",
    "X_test = forward_fill_initial_lags(X_test, last_train_feat.iloc[-1])\n",
    "\n",
    "pred_dlog = rf_full.predict(X_test)\n",
    "last_level = raw_train[RAW_TARGET_COL].iloc[-1]\n",
    "level_forecast = last_level * np.exp(np.cumsum(pred_dlog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2749fd7-1fe4-4d83-9ea3-f95e2b74946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [1, 3, 6, 12]           \n",
    "horizon_preds: dict[int, np.ndarray] = {}\n",
    "\n",
    "for h in horizons:\n",
    "    hor = np.concatenate(\n",
    "        [level_forecast[h - 1 :], np.repeat(level_forecast[-1], h - 1)]\n",
    "    )\n",
    "    horizon_preds[h] = hor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600d9763-30ee-4bda-b728-8fb8db421672",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = MODEL_DIR / \"Random_Forest_X.pkl\"\n",
    "joblib.dump(rf_full, MODEL_PATH)\n",
    "\n",
    "for h, arr in horizon_preds.items():\n",
    "    out_dir = PRED_DIR / f\"Horizon{h}\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fname = out_dir / f\"RFX_horizon_{h}.npy\"\n",
    "    np.save(fname, arr)\n",
    "\n",
    "print(\"Artefacts written:\")\n",
    "print(\" • Model  →\", MODEL_PATH)\n",
    "for h in horizons:\n",
    "    print(f\" • Horizon {h:>2} →\", PRED_DIR / f\"Horizon{h}\" / f\"RFX_horizon_{h}.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de325697-0993-4f42-bcb3-d4412a7f560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Display test results (level) ------------------------------------------------\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "actual_levels = raw_test[RAW_TARGET_COL].iloc[-len(level_forecast):]\n",
    "actual_dates  = raw_test[DATE_COL].iloc[-len(level_forecast):]\n",
    "\n",
    "display_results(actual_levels, level_forecast, actual_dates, \"RF full (level)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695675d7-fcc9-4862-ac9a-834d4f4f4082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
