{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d5f80-a081-4c39-bbd6-20d2c99d7c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Project root added to sys.path:\", project_root)\n",
    "\n",
    "model_save_path = os.path.join(project_root, 'Training', 'Random_Forest')\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "predictions_save_path = os.path.join(project_root, 'Predictions')\n",
    "os.makedirs(predictions_save_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465afa7-c872-4fa9-9159-5e0346de1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267a3c8-7034-440d-955b-b3e0e161d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training.Helper.dataPreprocessing import TRAIN_DATA_PATH_1990S, TRAIN_DATA_SPLIT\n",
    "\n",
    "date_col   = 'observation_date'\n",
    "target_col = 'fred_PCEPI'\n",
    "\n",
    "# 1) Load the training data\n",
    "df = pd.read_csv(TRAIN_DATA_PATH_1990S, parse_dates=[date_col], date_format='%m/%Y')\n",
    "df = df[df[date_col] >= '1990-01-01'].reset_index(drop=True)\n",
    "\n",
    "df = df.sort_values(by=date_col).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbcd678-2be4-4be7-85b4-00a1b9a5ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Create 12 lag features for the target\n",
    "n_lags = 12\n",
    "for lag in range(1, n_lags + 1):\n",
    "    df[f'lag_{lag}'] = df[target_col].shift(lag)\n",
    "\n",
    "# 2) Exogenous features you identified:\n",
    "exog_cols = [\n",
    "    'fred_AHETPI',\n",
    "    'fred_GDP',\n",
    "    'fred_PCUOMFGOMFG',\n",
    "    'fred_A053RC1Q027SBEA',\n",
    "    'fred_PPIACO',\n",
    "    'fred_TERMCBPER24NS'\n",
    "]\n",
    "\n",
    "# 3) Drop rows made NaN by lagging (and ensure the exogenous columns exist too!)\n",
    "all_required_cols = [target_col] + exog_cols + [f'lag_{lag}' for lag in range(1, n_lags+1)]\n",
    "df = df.dropna(subset=all_required_cols).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9397d089-a092-4224-8242-6369cde6e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the lag features + exogenous columns\n",
    "feature_cols = [f'lag_{lag}' for lag in range(1, n_lags + 1)] + exog_cols\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "# 80% train, 20% validation (time-ordered, no shuffle)\n",
    "split_index = int(len(X) * TRAIN_DATA_SPLIT)\n",
    "X_train, y_train = X.iloc[:split_index], y.iloc[:split_index]\n",
    "X_val,   y_val   = X.iloc[split_index:], y.iloc[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e820f-6be6-4849-bd06-508f1a1e0b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "fitted_rf_model = copy.deepcopy(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de72b9-61fc-4f5e-a410-26dde571f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_val_pred = rf_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af1099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.Helper.evaluation_helpers import calc_metrics_arrays\n",
    "\n",
    "calc_metrics_arrays(y_val.values.reshape(-1, 1), y_val_pred.reshape(-1, 1), model_names=['Random Forest X validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67649fa-9b36-4682-99dc-98b143e5f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = pd.concat([X_train, X_val], ignore_index=True)\n",
    "y_full = pd.concat([y_train, y_val], ignore_index=True)\n",
    "\n",
    "# This is cheating - fitting on validation data and predicting on validation data\n",
    "rf_model.fit(X_full, y_full)\n",
    "\n",
    "# Evaluate on full (train+val)\n",
    "y_full_pred = rf_model.predict(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite 'cheating' prediction with the actual prediction from the model fitted on the training data only\n",
    "y_full_pred = np.concatenate((y_train_pred, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_metrics_arrays(y_full.values.reshape(-1, 1), y_full_pred.reshape(-1, 1), model_names=['Random Forest X full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f4ee7-5d64-4026-9a5d-efb3f903edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the actual target values in a single series\n",
    "y_all = pd.concat([y_train, y_val], ignore_index=True)\n",
    "\n",
    "# We also need corresponding dates in the same order\n",
    "dates_train = df.loc[X_train.index, date_col]\n",
    "dates_val   = df.loc[X_val.index,   date_col]\n",
    "dates_all   = pd.concat([dates_train, dates_val], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4deba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.Helper.evaluation_helpers import display_results\n",
    "\n",
    "display_results(y_all, y_full_pred, dates_all, 'Random Forest + Exogenous Variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d0fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training.Helper.dataPreprocessing import TEST_DATA_PATH_1990S\n",
    "\n",
    "#TODO: Make the below data preprocessing into a function to avoid this code duplication\n",
    "date_col   = 'observation_date'\n",
    "target_col = 'fred_PCEPI'\n",
    "\n",
    "# 1) Load the training data\n",
    "df = pd.read_csv(TEST_DATA_PATH_1990S, parse_dates=[date_col], date_format='%m/%Y')\n",
    "\n",
    "df = df.sort_values(by=date_col).reset_index(drop=True)\n",
    "\n",
    "# 1) Create 12 lag features for the target\n",
    "n_lags = 12\n",
    "for lag in range(1, n_lags + 1):\n",
    "    df[f'lag_{lag}'] = df[target_col].shift(lag)\n",
    "\n",
    "# 2) Exogenous features you identified:\n",
    "exog_cols = [\n",
    "    'fred_AHETPI',\n",
    "    'fred_GDP',\n",
    "    'fred_PCUOMFGOMFG',\n",
    "    'fred_A053RC1Q027SBEA',\n",
    "    'fred_PPIACO',\n",
    "    'fred_TERMCBPER24NS'\n",
    "]\n",
    "\n",
    "# 3) Do not drop rows made NaN by lagging, as prediction period is 12 months so all rows would be dropped\n",
    "# Instead, leave as NaN and let the model handle the rest\n",
    "\n",
    "# Combine the lag features + exogenous columns\n",
    "feature_cols = [f'lag_{lag}' for lag in range(1, n_lags + 1)] + exog_cols\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_prediction = rf_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3211568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at what the model predicted (probably underpredicting due to NaNs which are treated by default as 0s)\n",
    "display_results(y, test_prediction, df[date_col], 'Random Forest X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2046a-dbc4-4ad4-8d8e-d8f16d968934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# 1) Save final predictions\n",
    "output_path = os.path.join(predictions_save_path, \"Random_Forest_X.npy\")\n",
    "np.save(output_path, test_prediction)\n",
    "print(\"Combined (train+val) multivariate predictions saved to:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb4c5b-570a-4f15-bfde-f2458894d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Save the Random Forest model itself\n",
    "model_filename = os.path.join(model_save_path, 'Random_Forest_X.pkl')\n",
    "joblib.dump(rf_model, model_filename)\n",
    "print(\"Random Forest multivariate model saved to:\", model_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
