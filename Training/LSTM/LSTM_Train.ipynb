{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "\n",
    "# Set up project root path\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from Models.LSTM import LSTMModel\n",
    "from Training.Helper.dataPreprocessing import load_data, prepare_dataloader\n",
    "from Training.Helper.PyTorchModular import train_model, loss_curve, optuna_tune_and_train\n",
    "from Training.Helper.hyperparameters import load_best_hyperparameters\n",
    "\n",
    "# File paths\n",
    "train_file = os.path.join(ROOT_PATH, \"Data\", \"Train\", \"train1990s.csv\")\n",
    "model_save_path = os.path.join(ROOT_PATH, \"Models\", \"Weights\", \"LSTM\")\n",
    "model_name = \"LSTM\"\n",
    "sequence_length = 48\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (no exogenous variables)\n",
    "X_train, y_train, \\\n",
    "X_val, y_val, \\\n",
    "X_test, y_test, \\\n",
    "dates, y_scaler = load_data(\n",
    "    train_file=train_file,\n",
    "    sequence_length=sequence_length,\n",
    "    config={\"use_exog\": False}\n",
    ")\n",
    "\n",
    "# Reshape input to [batch, sequence_length, input_size=1] for LSTM\n",
    "X_train = X_train.reshape(X_train.shape[0], -1, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], -1, 1)\n",
    "\n",
    "# Prepare DataLoaders\n",
    "train_loader = prepare_dataloader(X_train, y_train)\n",
    "val_loader   = prepare_dataloader(X_val, y_val)\n",
    "\n",
    "# Load Optuna-tuned or fallback hyperparameters\n",
    "best_params = load_best_hyperparameters() or {\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"lr\": 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LSTM model\n",
    "model = LSTMModel(\n",
    "    input_size=X_train.shape[-1],\n",
    "    hidden_size=best_params[\"hidden_size\"],\n",
    "    num_layers=best_params[\"num_layers\"],\n",
    "    output_size=1\n",
    ").to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_params[\"lr\"])\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model, metadata = optuna_tune_and_train(\n",
    "    model_class=LSTMModel,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    max_epochs=50,\n",
    "    model_save_path=model_save_path,\n",
    "    model_name=model_name,\n",
    "    use_best_hyperparams=False,\n",
    "    n_trials=20,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Plot training/validation loss\n",
    "loss_curve(\n",
    "    metadata[\"trainLoss\"],\n",
    "    metadata[\"validLoss\"],\n",
    "    title=\"LSTM Training vs Validation Loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "X_test = X_test.reshape(X_test.shape[0], -1, 1)  # Ensure correct shape\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_scaled = model(torch.tensor(X_test, dtype=torch.float32).to(device)).cpu().numpy()\n",
    "\n",
    "# Inverse scale\n",
    "y_pred = y_scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# Save to Predictions folder\n",
    "np.save(os.path.join(ROOT_PATH, \"Predictions\", \"LSTM.npy\"), y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences again from full training data\n",
    "X_all = X_train.reshape(X_train.shape[0], -1, 1)\n",
    "X_all_tensor = torch.tensor(X_all, dtype=torch.float32).to(device)\n",
    "\n",
    "# Predict on all training sequences\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_preds_scaled = model(X_all_tensor).cpu().numpy()\n",
    "\n",
    "# Inverse transform predictions and actuals\n",
    "train_preds = y_scaler.inverse_transform(train_preds_scaled)\n",
    "train_actual = y_scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "train_plot_dates = dates[:len(train_preds)]\n",
    "\n",
    "# Plot predictions on full training range\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(train_plot_dates, train_actual, label=\"Actual PCEPI\", color=\"blue\", linewidth=2)\n",
    "plt.plot(train_plot_dates, train_preds, label=\"Predicted PCEPI\", linestyle=\"--\", color=\"orange\", linewidth=2)\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"PCEPI\")\n",
    "plt.title(\"LSTM PCE Prediction on Training Set (One-Step Ahead Forecast)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Format x-axis with readable dates\n",
    "plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
