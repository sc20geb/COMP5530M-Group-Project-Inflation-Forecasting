{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARDL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(\"..\", \"..\")))  # adds root of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from statsmodels.tsa.statespace.structural import UnobservedComponents\n",
    "\n",
    "from Training.Helper.dataPreprocessing import (\n",
    "    add_time_features,\n",
    "    add_lagged_features,\n",
    "    add_rolling_features,\n",
    "    rank_features_ccf,\n",
    "    sklearn_fit_transform,\n",
    "    integer_index,\n",
    "    TRAIN_DATA_PATH_1990S\n",
    ")\n",
    "\n",
    "HORIZON = 12\n",
    "DATA_PATH = TRAIN_DATA_PATH_1990S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1: Diff of Log(PCEPI) with Target Lag and PCA Features\n",
    "- Log-differenced target (\\u0394log)\n",
    "- Top 40 CCF-selected features\n",
    "- PCA(20) with lagged target + Kalman smoothing\n",
    "- Includes Fourier terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 23:10:42,314 - INFO - Added time features: year, month, quarter. DataFrame shape: (408, 363)\n"
     ]
    }
   ],
   "source": [
    "# Load raw dataset and prepare datetime\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"ds\"] = pd.to_datetime(df[\"observation_date\"], format=\"%m/%Y\")\n",
    "df = df.rename(columns={\"fred_PCEPI\": \"y_original\"})\n",
    "\n",
    "# Add basic time features (month, quarter, etc.)\n",
    "df = add_time_features(df, date_col=\"ds\")\n",
    "\n",
    "# Add Fourier terms (harmonics to capture seasonality)\n",
    "for k in [1, 2, 3, 4]:\n",
    "    df[f\"sin_{k}\"] = np.sin(2 * np.pi * k * df[\"month\"] / 12)\n",
    "    df[f\"cos_{k}\"] = np.cos(2 * np.pi * k * df[\"month\"] / 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Lag, Momentum, Rolling Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add momentum, lagged values, and rolling window features for the target\n",
    "df[\"pct_change\"] = df[\"y_original\"].pct_change()\n",
    "df[\"momentum\"] = df[\"pct_change\"].diff()\n",
    "df = add_lagged_features(df, [\"y_original\"], lags=[1, 6, 12])\n",
    "df = add_rolling_features(df, \"y_original\", windows=[3, 6, 12])\n",
    "df[\"y_original_rolling_skew6\"] = df[\"y_original\"].rolling(6).skew()\n",
    "df[\"y_original_rolling_kurt6\"] = df[\"y_original\"].rolling(6).kurt()\n",
    "\n",
    "# Remove NaNs after feature generation\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log + differencing for stationarity of the target\n",
    "df[\"y_log\"] = np.log(df[\"y_original\"])\n",
    "df[\"y\"] = df[\"y_log\"].diff()\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection and Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top exogenous features using CCF (correlation with target)\n",
    "exog_df = df.drop(columns=[\"observation_date\", \"ds\", \"y_original\", \"y_log\", \"y\"])\n",
    "exog_df[\"fred_PCEPI\"] = df[\"y_original\"]\n",
    "selected_features = rank_features_ccf(exog_df, targetCol=\"fred_PCEPI\")[:40]\n",
    "\n",
    "# Scale + PCA for feature reduction\n",
    "X = df[selected_features].copy()\n",
    "X_scaled, scaler = sklearn_fit_transform(X, StandardScaler())\n",
    "X_scaled = X_scaled[0]\n",
    "pca = PCA(n_components=20)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_pca_df = pd.DataFrame(X_pca, index=df.index, columns=[f\"PC{i+1}\" for i in range(20)])\n",
    "X_pca_df = add_lagged_features(X_pca_df, target_cols=X_pca_df.columns.tolist(), lags=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Final Model DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine PCA and target into final modeling DataFrame\n",
    "df_model = pd.concat([df[[\"ds\", \"y\"]], X_pca_df], axis=1)\n",
    "df_model.dropna(inplace=True)\n",
    "df_model = integer_index(df_model)\n",
    "\n",
    "# Train/Validation split\n",
    "train_df = df_model.iloc[:-HORIZON]\n",
    "val_df = df_model.iloc[-HORIZON:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use lagged target and PCs as features for regression\n",
    "X_cols = [col for col in train_df.columns if col.startswith(\"PC\")]\n",
    "target_lags = 2\n",
    "Y_train = train_df[\"y\"].values[target_lags:]\n",
    "X_train = np.hstack([\n",
    "    train_df[X_cols].iloc[target_lags:].values,\n",
    "    np.column_stack([train_df[\"y\"].shift(l).values[target_lags:] for l in range(1, target_lags + 1)])\n",
    "])\n",
    "\n",
    "# Train Lasso and Ridge using grid search\n",
    "models = {}\n",
    "for name, reg in {\"Lasso\": Lasso(max_iter=5000), \"Ridge\": Ridge()}.items():\n",
    "    grid = GridSearchCV(reg, {\"alpha\": [0.001, 0.01, 0.1, 1.0]}, cv=3)\n",
    "    grid.fit(X_train, Y_train)\n",
    "    models[name] = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform autoregressive rolling prediction for next 12 months\n",
    "val_pca = val_df[X_cols].reset_index(drop=True)\n",
    "prev_y = list(train_df[\"y\"].iloc[-target_lags:])\n",
    "base_log = df[\"y_log\"].iloc[-HORIZON - 1]\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    pred_diff, y_lags = [], prev_y.copy()\n",
    "    for i in range(HORIZON):\n",
    "        X_exog = val_pca.iloc[i].values\n",
    "        X_input = np.concatenate([X_exog, y_lags[::-1]]).reshape(1, -1)\n",
    "        pred = model.predict(X_input)[0]\n",
    "        pred_diff.append(pred)\n",
    "        y_lags = y_lags[1:] + [pred]\n",
    "    y_log_forecast = np.cumsum(pred_diff) + base_log\n",
    "    y_forecast = np.exp(y_log_forecast)\n",
    "    results[name] = y_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Smoothing + Final Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kalman smoothing on the best model prediction\n",
    "y_true = df[\"y_original\"].iloc[-HORIZON:].values\n",
    "best_model = min(results, key=lambda k: mean_absolute_error(y_true, results[k]))\n",
    "model_kalman = UnobservedComponents(results[best_model], level='llevel')\n",
    "res_kalman = model_kalman.fit(disp=False)\n",
    "smoothed_v1 = res_kalman.smoothed_state[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2: Simpler log(PCEPI) Regression with PCA + Kalman\n",
    "- Target: log-transformed PCEPI (no differencing)\n",
    "- Features: 30 top CCF-selected exogenous features\n",
    "- PCA(12) dimensionality reduction (fewer components than v1)\n",
    "- No lagged target in regression\n",
    "- Simple prediction + Kalman smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading + Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 23:10:56,550 - INFO - Added time features: year, month, quarter. DataFrame shape: (408, 363)\n"
     ]
    }
   ],
   "source": [
    "# V2: Load and basic time features\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"ds\"] = pd.to_datetime(df[\"observation_date\"], format=\"%m/%Y\")\n",
    "df = df.rename(columns={\"fred_PCEPI\": \"y\"})\n",
    "df = add_time_features(df, date_col=\"ds\")\n",
    "\n",
    "# Technical features\n",
    "df[\"pct_change\"] = df[\"y\"].pct_change()\n",
    "df[\"momentum\"] = df[\"pct_change\"].diff()\n",
    "df = add_lagged_features(df, [\"y\"], lags=[1, 6, 12])\n",
    "df = add_rolling_features(df, \"y\", windows=[3, 6, 12])\n",
    "df[\"y_rolling_skew6\"] = df[\"y\"].rolling(6).skew()\n",
    "df[\"y_rolling_kurt6\"] = df[\"y\"].rolling(6).kurt()\n",
    "\n",
    "# Remove NaNs after feature generation\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Target: log(PCEPI)\n",
    "df[\"y_log\"] = np.log(df[\"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection + PCA for V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop again just to ensure CCF doesn't see NaNs\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Feature selection\n",
    "exog_df = df.drop(columns=[\"observation_date\", \"ds\", \"y\", \"y_log\"])\n",
    "exog_df[\"target\"] = df[\"y_log\"]\n",
    "selected_features = rank_features_ccf(exog_df, targetCol=\"target\")[:30]\n",
    "\n",
    "# PCA\n",
    "X = df[selected_features].copy()\n",
    "X_scaled, scaler = sklearn_fit_transform(X, StandardScaler())\n",
    "X_scaled = X_scaled[0]\n",
    "\n",
    "pca = PCA(n_components=12)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_pca_df = pd.DataFrame(X_pca, index=df.index, columns=[f\"PC{i+1}\" for i in range(12)])\n",
    "X_pca_df = add_lagged_features(X_pca_df, X_pca_df.columns.tolist(), lags=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Model DF + Train/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model dataset with target and PCA features\n",
    "df_model = pd.concat([df[[\"ds\", \"y_log\"]], X_pca_df], axis=1)\n",
    "df_model.dropna(inplace=True)\n",
    "df_model = integer_index(df_model)\n",
    "\n",
    "# Split into train and validation sets\n",
    "train_df = df_model.iloc[:-HORIZON]\n",
    "val_df = df_model.iloc[-HORIZON:]\n",
    "\n",
    "X_cols = [col for col in train_df.columns if col.startswith(\"PC\")]\n",
    "Y_train = train_df[\"y_log\"].values\n",
    "X_train = train_df[X_cols].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Lasso + Ridge Models (No Target Lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models using only PCA features (no lagged target)\n",
    "models = {}\n",
    "for name, reg in {\"Lasso\": Lasso(max_iter=5000), \"Ridge\": Ridge()}.items():\n",
    "    grid = GridSearchCV(reg, {\"alpha\": [0.001, 0.01, 0.1, 1.0]}, cv=3)\n",
    "    grid.fit(X_train, Y_train)\n",
    "    models[name] = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict directly without rolling, then invert log\n",
    "val_X = val_df[X_cols].values\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    pred_log = model.predict(val_X)\n",
    "    pred = np.exp(pred_log)\n",
    "    results[name] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman Smoothing on V2 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalman smoothing on best performing model\n",
    "best_model = min(results, key=lambda k: mean_absolute_error(df[\"y\"].iloc[-HORIZON:], results[k]))\n",
    "model_kalman = UnobservedComponents(results[best_model], level='local level')\n",
    "res_kalman = model_kalman.fit(disp=False)\n",
    "smoothed_v2 = res_kalman.smoothed_state[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Version 2 Was Better\n",
    "\n",
    "- V2 outperformed V1 and V3 in both RMSE and trend alignment.\n",
    "- It uses fewer features (30 vs. 40) and avoids differencing, making it more interpretable.\n",
    "- It skips lagged target prediction and uses a cleaner pipeline with less variance.\n",
    "- Final smoothed predictions track inflation trend well with minimal overshooting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 3: Added month dummies + seasonality to v2\n",
    "- But leads to overfitting\n",
    "- Performs worse across all metrics\n",
    "- Omitted from execution as v2 performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final ARDL_v2 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ARDL_v2 saved as best performing version\n"
     ]
    }
   ],
   "source": [
    "np.save(os.path.join(\"..\", \"..\", \"Predictions\", \"ARDL.npy\"), smoothed_v2)\n",
    "pd.DataFrame({\n",
    "    \"observation_date\": df[\"ds\"].iloc[-HORIZON:].dt.strftime(\"%m/%Y\"),\n",
    "    \"ground_truth\": df[\"y\"].iloc[-HORIZON:].values,\n",
    "    \"ARDL_v2\": smoothed_v2\n",
    "}).to_csv(\"ARDL.csv\", index=False)\n",
    "\n",
    "print(\"Final ARDL_v2 saved as best performing version\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
