{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flag whether running in google colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1287,
     "status": "ok",
     "timestamp": 1739272666727,
     "user": {
      "displayName": "Sandra",
      "userId": "02273131005255852305"
     },
     "user_tz": 0
    },
    "id": "al6MDKX6tnwG",
    "outputId": "8cb60974-3216-4e43-bd07-d6c48b2c8e7e"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    #for those using colab, mount\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    train_file = \"/content/drive/MyDrive/group_proj/rnn/Data/Train/PCE.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1739272667025,
     "user": {
      "displayName": "Sandra",
      "userId": "02273131005255852305"
     },
     "user_tz": 0
    },
    "id": "rEq3bxVrry5i",
    "outputId": "765aefc8-bfef-4a4e-f92b-0bacc407dfaf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Define relative file paths for training and testing data\n",
    "train_file = \"..\\\\Data\\\\Train\\\\PCE.csv\"\n",
    "test_file  = \"..\\\\Data\\\\Test\\\\PCE.csv\"\n",
    "\n",
    "\n",
    "# Load Training Data\n",
    "train_df = pd.read_csv(train_file, parse_dates=['Date'])\n",
    "train_df = train_df.rename(columns={'Value': 'PCE'})\n",
    "train_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Load Testing Data\n",
    "test_df = pd.read_csv(test_file, parse_dates=['Date'])\n",
    "test_df = test_df.rename(columns={'Value': 'PCE'})\n",
    "test_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Visualise the trend of the training data\n",
    "plt.figure(figsize=(10, 4))\n",
    "train_df['PCE'].plot(title='Training Data: PCE Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PCE')\n",
    "plt.show()\n",
    "\n",
    "# Fit the scaler on the training data and transform both train and test sets.\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_df[['PCE']])\n",
    "test_scaled = scaler.transform(test_df[['PCE']])\n",
    "\n",
    "# Convert the scaled data to 1D arrays\n",
    "train_series = train_scaled.flatten()\n",
    "test_series  = test_scaled.flatten()\n",
    "\n",
    "# Create Sequences from the Data\n",
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"\n",
    "    Creates sequences of length `seq_length` as inputs and the subsequent value as the target.\n",
    "    \"\"\"\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        xs.append(data[i : i + seq_length])\n",
    "        ys.append(data[i + seq_length])\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Set the sequence length\n",
    "sequence_length = 12\n",
    "X_train, y_train = create_sequences(train_series, sequence_length)\n",
    "X_test, y_test   = create_sequences(test_series, sequence_length)\n",
    "\n",
    "print(f\"Training sequences: {X_train.shape}, Training targets: {y_train.shape}\")\n",
    "print(f\"Testing sequences: {X_test.shape}, Testing targets: {y_test.shape}\")\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(-1)\n",
    "X_test_tensor  = torch.tensor(X_test, dtype=torch.float32).unsqueeze(-1)\n",
    "y_test_tensor  = torch.tensor(y_test, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset  = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZG0LTrCtaw1"
   },
   "source": [
    "1. Import the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1739272708891,
     "user": {
      "displayName": "Sandra",
      "userId": "02273131005255852305"
     },
     "user_tz": 0
    },
    "id": "h_zEYG3ir44u",
    "outputId": "e87088cc-9fb6-4020-d690-cf007f0b1e8d"
   },
   "outputs": [],
   "source": [
    "#allows imports from other folders in project\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "#from RNN_PCE import RNNModel\n",
    "from Models.RNN_PCE import RNNModel\n",
    "\n",
    "# Define computation device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "rnn_model = RNNModel().to(device)\n",
    "print(rnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-b_F2QMqtevF"
   },
   "source": [
    "2. Train the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8266,
     "status": "ok",
     "timestamp": 1739272721491,
     "user": {
      "displayName": "Sandra",
      "userId": "02273131005255852305"
     },
     "user_tz": 0
    },
    "id": "SIfvwNPWr6dK",
    "outputId": "63440b4e-f1cc-46ef-9625-9513a34061bb"
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    rnn_model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rnn_model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    rnn_model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = rnn_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5U829piRthhg"
   },
   "source": [
    "3. Make Predictions with the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "executionInfo": {
     "elapsed": 448,
     "status": "ok",
     "timestamp": 1739272724391,
     "user": {
      "displayName": "Sandra",
      "userId": "02273131005255852305"
     },
     "user_tz": 0
    },
    "id": "vv3Z4lBMr8fQ",
    "outputId": "0fd4cd50-20bd-4773-b3b8-dfa813ca567b"
   },
   "outputs": [],
   "source": [
    "rnn_model.eval()\n",
    "rnn_predictions = []\n",
    "actuals = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = rnn_model(inputs)\n",
    "        rnn_predictions.append(outputs.cpu().numpy())\n",
    "        actuals.append(targets.cpu().numpy())\n",
    "\n",
    "# Concatenate batches into single arrays\n",
    "rnn_predictions = np.concatenate(rnn_predictions)\n",
    "actuals = np.concatenate(actuals)\n",
    "\n",
    "# Inverse transform the normalised predictions and actual values back to the original scale\n",
    "rnn_predictions_inv = scaler.inverse_transform(rnn_predictions)\n",
    "actuals_inv = scaler.inverse_transform(actuals)\n",
    "\n",
    "# Extract the dates corresponding to the test predictions.\n",
    "test_dates = test_df.index[sequence_length:]\n",
    "\n",
    "# Plot the actual vs. predicted PCE values for RNN\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_dates, actuals_inv, label='Actual PCE', marker='o')\n",
    "plt.plot(test_dates, rnn_predictions_inv, label='Predicted PCE (RNN)', marker='x')\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of Actual PCE and Predicted PCE (RNN)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"PCE\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYgM03ZkvJf9"
   },
   "source": [
    "LSTM - Natalie's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3968,
     "status": "ok",
     "timestamp": 1739272830452,
     "user": {
      "displayName": "Sandra",
      "userId": "02273131005255852305"
     },
     "user_tz": 0
    },
    "id": "cPMCtrQ5vInv",
    "outputId": "cd1be640-9f60-459f-a785-4fd7e29582f3"
   },
   "outputs": [],
   "source": [
    "from Models.LSTM_PCE import LSTMModel\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialise model\n",
    "model = LSTMModel().to(device)\n",
    "\n",
    "# Model training\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Making predictions\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions.append(outputs.cpu().numpy())\n",
    "        actuals.append(targets.cpu().numpy())\n",
    "\n",
    "# Concatenate batches into single arrays\n",
    "predictions = np.concatenate(predictions)\n",
    "actuals = np.concatenate(actuals)\n",
    "\n",
    "# Inverse transform the normalised predictions and actual values back to the original scale\n",
    "predictions_inv = scaler.inverse_transform(predictions)\n",
    "actuals_inv = scaler.inverse_transform(actuals)\n",
    "\n",
    "# Extract the dates corresponding to the test predictions.\n",
    "test_dates = test_df.index[sequence_length:]\n",
    "\n",
    "# Plot the actual vs. predicted PCE values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_dates, actuals_inv, label='Actual PCE', marker='o')\n",
    "plt.plot(test_dates, predictions_inv, label='Predicted PCE', marker='x')\n",
    "plt.legend()\n",
    "plt.title(\"Comparision of actual PCE and predicted PCE\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"PCE\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gItTBaostlkY"
   },
   "source": [
    "4. Compare LSTM vs. RNN Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1739272835850,
     "user": {
      "displayName": "Sandra",
      "userId": "02273131005255852305"
     },
     "user_tz": 0
    },
    "id": "kx-l212Sr-Oz",
    "outputId": "03678f3a-a9c7-44ca-d649-787d7dacbe0b"
   },
   "outputs": [],
   "source": [
    "# Compute Mean Squared Error for comparison\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lstm_mse = mean_squared_error(actuals_inv, predictions_inv)\n",
    "rnn_mse = mean_squared_error(actuals_inv, rnn_predictions_inv)\n",
    "\n",
    "print(f\"LSTM Model MSE: {lstm_mse:.4f}\")\n",
    "print(f\"RNN Model MSE: {rnn_mse:.4f}\")\n",
    "\n",
    "# Plot LSTM vs RNN predictions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_dates, actuals_inv, label=\"Actual PCE\", marker=\"o\", linestyle=\"dashed\")\n",
    "plt.plot(test_dates, predictions_inv, label=\"LSTM Predicted PCE\", marker=\"x\")\n",
    "plt.plot(test_dates, rnn_predictions_inv, label=\"RNN Predicted PCE\", marker=\"s\")\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of Actual PCE, LSTM Predictions, and RNN Predictions\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"PCE\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPJ9mg71cP8X3dLmhHsD61m",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
