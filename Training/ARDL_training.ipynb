{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allows imports from other folders in project\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARDL model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Helper.dataPreprocessing import TRAIN_DATA_PATH_1990S\n",
    "\n",
    "# Loading the data\n",
    "df = pd.read_csv(TRAIN_DATA_PATH_1990S)\n",
    "\n",
    "# Convert to datetime and set as index\n",
    "df[\"observation_date\"] = pd.to_datetime(df[\"observation_date\"])\n",
    "df.set_index(\"observation_date\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Helper.dataPreprocessing import add_modified_feature\n",
    "\n",
    "# Identify target column and add new column\n",
    "target_col = 'fred_PCEPI'\n",
    "df = add_modified_feature(df, target_col, np.log)\n",
    "log_col = df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Helper.dataPreprocessing import best_lag_selection, train_val_test_split\n",
    "\n",
    "# Train/Test split and best lag selection\n",
    "train_X, train_y, _, _, test_X, test_y = train_val_test_split(df[log_col], df[target_col], train_size=0.9, val_size=0)\n",
    "\n",
    "print(f\"Train set size: {len(train_X)}\")\n",
    "print(f\"Test  set size: {len(test_X)}\")\n",
    "\n",
    "best_lag = best_lag_selection(train_X, max_lags=12)\n",
    "print(f\"Selected best lag (TRAIN only) for ARDL in levels: {best_lag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Fit ARDL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ardl import ARDL\n",
    "\n",
    "# ARDL model with a linear trend since no exogenous variables\n",
    "final_model = ARDL(endog=train_X, lags=best_lag, trend='ct').fit()\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Forecast in log-levels\n",
    "start_idx = test_X.index[0]\n",
    "end_idx   = test_X.index[-1]\n",
    "\n",
    "pred_log_test = final_model.predict(start=start_idx, end=end_idx)\n",
    "pred_log_test = pd.Series(pred_log_test, index=test_X.index)\n",
    "\n",
    "# Exponentiate to get back to original scale (raw predictions)\n",
    "predictions_raw = np.exp(pred_log_test)  # \"raw\" ARDL forecast in original PCEPI scale\n",
    "\n",
    "# Kalman Filter on the test forecast \n",
    "kf = KalmanFilter(initial_state_mean=predictions_raw.iloc[0], n_dim_obs=1)\n",
    "kf = kf.em(predictions_raw, n_iter=5)\n",
    "\n",
    "predictions_smoothed_arr, _ = kf.filter(predictions_raw)\n",
    "predictions_smoothed = pd.Series(predictions_smoothed_arr.flatten(), \n",
    "                                 index=predictions_raw.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "# Evaluation\n",
    "y_true = test_y\n",
    "\n",
    "# Align both raw and smoothed with the test index\n",
    "y_pred_raw     = predictions_raw.reindex(y_true.index)\n",
    "y_pred_smoothed = predictions_smoothed.reindex(y_true.index)\n",
    "\n",
    "# Evaluate RAW\n",
    "mae_raw = mean_absolute_error(y_true, y_pred_raw)\n",
    "rmse_raw = np.sqrt(mean_squared_error(y_true, y_pred_raw))\n",
    "\n",
    "# Evaluate SMOOTHED\n",
    "mae_smooth = mean_absolute_error(y_true, y_pred_smoothed)\n",
    "rmse_smooth = np.sqrt(mean_squared_error(y_true, y_pred_smoothed))\n",
    "\n",
    "print(f\"\\n=== Evaluation on Test Set ===\")\n",
    "print(f\"RAW Forecast  =>  MAE = {mae_raw:.4f},  RMSE = {rmse_raw:.4f}\")\n",
    "print(f\"Smoothed      =>  MAE = {mae_smooth:.4f},  RMSE = {rmse_smooth:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_true.index, y_true, label=\"Actual (Test)\", marker=\"o\")\n",
    "plt.plot(y_pred_raw.index, y_pred_raw, label=\"Predicted (Raw)\", marker=\"*\")\n",
    "plt.plot(y_pred_smoothed.index, y_pred_smoothed, \n",
    "         label=\"Predicted (Smoothed)\", linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.title(\"ARDL (Levels) + Kalman Filter: RAW vs. SMOOTHED Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Exogenous Variables to catch trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "file_path = \"../Data/train/train1990s.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert to datetime and set as index\n",
    "df[\"observation_date\"] = pd.to_datetime(df[\"observation_date\"])\n",
    "df.set_index(\"observation_date\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify target column and add new column\n",
    "target_col = 'fred_PCEPI'\n",
    "df = add_modified_feature(df, target_col, np.log)\n",
    "log_col = df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "exogenous_columns = [col for col in df.columns if col not in [log_col, target_col]]\n",
    "train_X, train_y, _, _, test_X, test_y = train_val_test_split(df[exogenous_columns], df[target_col], train_size=0.9, val_size=0)\n",
    "\n",
    "print(f\"Train set size: {len(train_X)}\")\n",
    "print(f\"Test  set size: {len(test_X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Helper.dataPreprocessing import drop_near_constant_cols\n",
    "\n",
    "# Remove near-constant columns according to standard deviation (there are none in the current dataset)\n",
    "train_X_clean, dropped_cols = drop_near_constant_cols(train_X, threshold=1e-6)\n",
    "test_X_clean = test_X.drop(columns=dropped_cols)\n",
    "print(f\"\\nDropped near-constant exogenous columns: {dropped_cols}\")\n",
    "print(f\"Number of remaining exogenous columns after drop: {len(train_X_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Helper.dataPreprocessing import sklearn_fit_transform\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "NUM_COMPONENTS = 10\n",
    "\n",
    "train_exog, test_exog = sklearn_fit_transform(train_X_clean, test_X_clean, PCA, n_components=NUM_COMPONENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Helper.dataPreprocessing import add_lagged_features\n",
    "\n",
    "train_exog_lags, test_exog_lags = add_lagged_features(train_exog, list(train_exog.columns), lags=[1]), add_lagged_features(test_exog, list(test_exog.columns), lags=[1])\n",
    "# Drops the first max(lags) rows (in this case, 1), since there are NaN values from having shifted by the number of lags\n",
    "train_exog_lags.dropna(inplace=True)\n",
    "test_exog_lags.dropna(inplace=True)\n",
    "# Drop the same rows in the targets as were dropped in the inputs\n",
    "train_target = df[log_col].loc[train_exog_lags.index]\n",
    "test_target = test_y.loc[test_exog_lags.index]\n",
    "\n",
    "print(f\"\\nAfter adding 1 lag, train exog shape: {train_exog_lags.shape}\")\n",
    "print(f\"Train target shape: {train_target.shape}\")\n",
    "print(f\"Test exog shape: {test_exog_lags.shape}\")\n",
    "print(f\"Test target shape: {test_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Helper.dataPreprocessing import best_lag_selection\n",
    "\n",
    "best_lag = best_lag_selection(train_target, max_lags=12, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Helper.dataPreprocessing import integer_index\n",
    "\n",
    "# Convert everything to integer indexing\n",
    "# Because ARDL tries to produce date-based forecasts for the entire date range,\n",
    "# we can convert both train and test to 0-based integer index so we produce\n",
    "# exactly as many forecasts as test_exog_lags rows.\n",
    "#can input all DataFrames we wish to integer index as a list, and a list is returned\n",
    "train_exog_lags_int, test_exog_lags_int, train_target_int, test_target_int = integer_index([train_exog_lags, test_exog_lags, train_target, test_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Fit ARDL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARDL model using integer index\n",
    "final_model = ARDL(\n",
    "    endog=train_target_int,\n",
    "    exog=train_exog_lags_int,\n",
    "    lags=best_lag,\n",
    "    trend='ct'\n",
    ").fit()\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast with Exog out-of-sample (Integer-based)\n",
    "# Will produce exactly `len(test_exog_lags_int)` forecasts\n",
    "start_i = len(train_exog_lags_int)\n",
    "end_i   = start_i + len(test_exog_lags_int) - 1\n",
    "\n",
    "pred_log_test = final_model.predict(\n",
    "    start=start_i,\n",
    "    end=end_i,\n",
    "    exog_oos=test_exog_lags_int  # The same # of rows as the forecast steps\n",
    ")\n",
    "\n",
    "# pred_log_test is now indexed from `start_i` to `end_i`\n",
    "# re-index it to 0..len(test_exog_lags_int)-1 for convenience:\n",
    "pred_log_test.index = test_exog_lags_int.index\n",
    "\n",
    "# Exponentiate back to original scale\n",
    "predictions_raw = np.exp(pred_log_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kalman Filter\n",
    "kf = KalmanFilter(initial_state_mean=predictions_raw.iloc[0], n_dim_obs=1)\n",
    "kf = kf.em(predictions_raw, n_iter=5)\n",
    "predictions_smoothed_arr, _ = kf.filter(predictions_raw)\n",
    "predictions_smoothed = pd.Series(predictions_smoothed_arr.flatten(), index=predictions_raw.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "y_true = test_target_int.reindex(test_exog_lags_int.index)  # same integer index\n",
    "\n",
    "mae_raw  = mean_absolute_error(y_true, predictions_raw)\n",
    "rmse_raw = np.sqrt(mean_squared_error(y_true, predictions_raw))\n",
    "\n",
    "mae_smooth  = mean_absolute_error(y_true, predictions_smoothed)\n",
    "rmse_smooth = np.sqrt(mean_squared_error(y_true, predictions_smoothed))\n",
    "\n",
    "print(f\"\\n=== Evaluation on Test Set ===\")\n",
    "print(f\"RAW Predictions       => MAE = {mae_raw:.4f},  RMSE = {rmse_raw:.4f}\")\n",
    "print(f\"Smoothed Predictions  => MAE = {mae_smooth:.4f}, RMSE = {rmse_smooth:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_true.index, y_true, label=\"Actual (Test)\", marker=\"o\")\n",
    "plt.plot(predictions_raw.index, predictions_raw, label=\"Predicted (Raw)\", marker=\"*\")\n",
    "plt.plot(predictions_smoothed.index, predictions_smoothed, label=\"Predicted (Smoothed)\", linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.title(\"ARDL + PCA + 1-Lag PCA, with Integer-Based Forecasting (No Data Leakage)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
