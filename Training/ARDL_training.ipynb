{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allows imports from other folders in project\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARDL model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading the data\n",
    "file_path = \"../Data/train/train1990s.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert to datetime and set as index\n",
    "df[\"observation_date\"] = pd.to_datetime(df[\"observation_date\"])\n",
    "df.set_index(\"observation_date\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataPreprocessing import add_modified_feature\n",
    "\n",
    "# Identify target column and add new column\n",
    "target_col = 'fred_PCEPI'\n",
    "df = add_modified_feature(df, target_col, np.log)\n",
    "log_col = df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataPreprocessing import best_lag_selection, train_val_test_split\n",
    "\n",
    "# Train/Test split and best lag selection\n",
    "train_X, train_y, _, _, test_X, test_y = train_val_test_split(df[log_col], df[target_col], train_size=0.9, val_size=0)\n",
    "\n",
    "print(f\"Train set size: {len(train_X)}\")\n",
    "print(f\"Test  set size: {len(test_X)}\")\n",
    "\n",
    "best_lag = best_lag_selection(train_X, max_lags=12)\n",
    "print(f\"Selected best lag (TRAIN only) for ARDL in levels: {best_lag}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Fit ARDL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ardl import ARDL\n",
    "\n",
    "# ARDL model with a linear trend since no exogenous variables\n",
    "final_model = ARDL(endog=train_X, lags=best_lag, trend='ct').fit()\n",
    "print(\"\\n=== ARDL (levels) Model Summary ===\")\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Forecast in log-levels\n",
    "start_idx = test_X.index[0]\n",
    "end_idx   = test_X.index[-1]\n",
    "\n",
    "pred_log_test = final_model.predict(start=start_idx, end=end_idx)\n",
    "pred_log_test = pd.Series(pred_log_test, index=test_X.index)\n",
    "\n",
    "# Exponentiate to get back to original scale (raw predictions)\n",
    "predictions_raw = np.exp(pred_log_test)  # \"raw\" ARDL forecast in original PCEPI scale\n",
    "\n",
    "# Kalman Filter on the test forecast \n",
    "kf = KalmanFilter(initial_state_mean=predictions_raw.iloc[0], n_dim_obs=1)\n",
    "kf = kf.em(predictions_raw, n_iter=5)\n",
    "\n",
    "predictions_smoothed_arr, _ = kf.filter(predictions_raw)\n",
    "predictions_smoothed = pd.Series(predictions_smoothed_arr.flatten(), \n",
    "                                 index=predictions_raw.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "# Evaluation\n",
    "y_true = test_y\n",
    "\n",
    "# Align both raw and smoothed with the test index\n",
    "y_pred_raw     = predictions_raw.reindex(y_true.index)\n",
    "y_pred_smoothed = predictions_smoothed.reindex(y_true.index)\n",
    "\n",
    "# Evaluate RAW\n",
    "mae_raw = mean_absolute_error(y_true, y_pred_raw)\n",
    "rmse_raw = np.sqrt(mean_squared_error(y_true, y_pred_raw))\n",
    "\n",
    "# Evaluate SMOOTHED\n",
    "mae_smooth = mean_absolute_error(y_true, y_pred_smoothed)\n",
    "rmse_smooth = np.sqrt(mean_squared_error(y_true, y_pred_smoothed))\n",
    "\n",
    "print(f\"\\n=== Evaluation on Test Set ===\")\n",
    "print(f\"RAW Forecast  =>  MAE = {mae_raw:.4f},  RMSE = {rmse_raw:.4f}\")\n",
    "print(f\"Smoothed      =>  MAE = {mae_smooth:.4f},  RMSE = {rmse_smooth:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_true.index, y_true, label=\"Actual (Test)\", marker=\"o\")\n",
    "plt.plot(y_pred_raw.index, y_pred_raw, label=\"Predicted (Raw)\", marker=\"*\")\n",
    "plt.plot(y_pred_smoothed.index, y_pred_smoothed, \n",
    "         label=\"Predicted (Smoothed)\", linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.title(\"ARDL (Levels) + Kalman Filter: RAW vs. SMOOTHED Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Exogenous Variables to catch trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "file_path = \"../Data/train/train1990s.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert to datetime and set as index\n",
    "df[\"observation_date\"] = pd.to_datetime(df[\"observation_date\"])\n",
    "df.set_index(\"observation_date\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify target column and add new column\n",
    "target_col = 'fred_PCEPI'\n",
    "df = add_modified_feature(df, target_col, np.log)\n",
    "log_col = df.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "exogenous_columns = [col for col in df.columns if col not in [log_col, target_col]]\n",
    "train_X, train_y, _, _, test_X, test_y = train_val_test_split(df[exogenous_columns], df[target_col], train_size=0.9, val_size=0)\n",
    "\n",
    "print(f\"Train set size: {len(train_X)}\")\n",
    "print(f\"Test  set size: {len(test_X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataPreprocessing import drop_near_constant_cols\n",
    "\n",
    "# Remove near-constant columns according to standard deviation (there are none in the current dataset)\n",
    "train_X_clean, dropped_cols = drop_near_constant_cols(train_X, threshold=1e-6)\n",
    "test_X_clean = test_X.drop(columns=dropped_cols)\n",
    "print(f\"\\nDropped near-constant exogenous columns: {dropped_cols}\")\n",
    "print(f\"Number of remaining exogenous columns after drop: {len(train_X_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataPreprocessing import sklearn_fit_transform\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "NUM_COMPONENTS = 10\n",
    "\n",
    "train_exog1, test_exog1 = sklearn_fit_transform(train_X_clean, test_X_clean, PCA, n_components=NUM_COMPONENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.ardl import ARDL\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Train/Test split\n",
    "train_size = int(0.90 * len(df))\n",
    "train_df = df.iloc[:train_size].copy()\n",
    "test_df  = df.iloc[train_size:].copy()\n",
    "\n",
    "print(f\"\\nTrain set size: {len(train_df)}\")\n",
    "print(f\"Test  set size: {len(test_df)}\")\n",
    "\n",
    "train_exog_clean, dropped_cols = drop_near_constant_cols(train_exog_full, threshold=1e-6)\n",
    "test_exog_clean = test_exog_full.drop(columns=dropped_cols, errors=\"ignore\")\n",
    "\n",
    "print(f\"\\nDropped near-constant exogenous columns: {dropped_cols}\")\n",
    "print(f\"Remaining exog columns after drop: {len(train_exog_clean.columns)}\")\n",
    "\n",
    "# Creating 1 lag of the PCA Components\n",
    "def add_lags_to_pca(df_pca, lags=1):\n",
    "    out_df = df_pca.copy()\n",
    "    for col in df_pca.columns:\n",
    "        for lag_i in range(1, lags+1):\n",
    "            out_df[f\"{col}_L{lag_i}\"] = df_pca[col].shift(lag_i)\n",
    "    return out_df\n",
    "\n",
    "train_exog_lags = add_lags_to_pca(train_exog, lags=1)\n",
    "test_exog_lags  = add_lags_to_pca(test_exog,  lags=1)\n",
    "\n",
    "# Drop the NaNs from shifting\n",
    "train_exog_lags.dropna(inplace=True)\n",
    "test_exog_lags.dropna(inplace=True)\n",
    "\n",
    "# Align the target with the new exog indexes\n",
    "train_target = train_df[\"log_pcepi\"].loc[train_exog_lags.index]\n",
    "test_target = test_df[\"fred_PCEPI\"].loc[test_exog_lags.index]\n",
    "\n",
    "print(f\"\\nAfter adding 1 lag, train exog shape: {train_exog_lags.shape}\")\n",
    "print(f\"Train target shape: {train_target.shape}\")\n",
    "print(f\"Test exog shape: {test_exog_lags.shape}\")\n",
    "print(f\"Test target shape: {test_target.shape}\")\n",
    "\n",
    "# Best Lag selection for the target (no differencing)\n",
    "def best_lag_selection(train_series, max_lags=12):\n",
    "    pacf_vals = pacf(train_series, nlags=max_lags)\n",
    "    best_pacf_lag = np.argmax(np.abs(pacf_vals[1:])) + 1\n",
    "\n",
    "    best_aic_lag, best_aic = 1, float(\"inf\")\n",
    "    for lag in range(1, max_lags + 1):\n",
    "        y = train_series[lag:]\n",
    "        X = train_series.shift(lag)[lag:]\n",
    "        X = sm.add_constant(X, prepend=True)\n",
    "        try:\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            if model.aic < best_aic:\n",
    "                best_aic_lag = lag\n",
    "                best_aic = model.aic\n",
    "        except:\n",
    "            continue\n",
    "    return min(best_pacf_lag, best_aic_lag)\n",
    "\n",
    "best_lag = best_lag_selection(train_target, max_lags=12)\n",
    "print(f\"\\nSelected best AR lag for target: {best_lag}\")\n",
    "\n",
    "# Convert everything to integer indexing\n",
    "# Because ARDL tries to produce date-based forecasts for the entire date range,\n",
    "# we can convert both train and test to 0-based integer index so we produce\n",
    "# exactly as many forecasts as test_exog_lags rows.\n",
    "\n",
    "train_index = np.arange(len(train_exog_lags))\n",
    "test_index  = np.arange(len(test_exog_lags))\n",
    "\n",
    "train_exog_lags_int = train_exog_lags.copy()\n",
    "test_exog_lags_int  = test_exog_lags.copy()\n",
    "\n",
    "train_exog_lags_int.index = train_index\n",
    "test_exog_lags_int.index  = test_index\n",
    "\n",
    "train_target_int = pd.Series(train_target.values, index=train_index)\n",
    "test_target_int  = pd.Series(test_target.values, index=test_index)\n",
    "\n",
    "# ARDL model using integer index\n",
    "final_model = ARDL(\n",
    "    endog=train_target_int,\n",
    "    exog=train_exog_lags_int,\n",
    "    lags=best_lag,\n",
    "    trend='ct'\n",
    ").fit()\n",
    "\n",
    "print(\"\\n=== ARDL (levels) Model Summary ===\")\n",
    "print(final_model.summary())\n",
    "\n",
    "# Forecast with Exog out-of-sample (Integer-based)\n",
    "# Will produce exactly `len(test_exog_lags_int)` forecasts\n",
    "start_i = len(train_exog_lags_int)\n",
    "end_i   = start_i + len(test_exog_lags_int) - 1\n",
    "\n",
    "pred_log_test = final_model.predict(\n",
    "    start=start_i,\n",
    "    end=end_i,\n",
    "    exog_oos=test_exog_lags_int  # The same # of rows as the forecast steps\n",
    ")\n",
    "\n",
    "# pred_log_test is now indexed from `start_i` to `end_i`\n",
    "# re-index it to 0..len(test_exog_lags_int)-1 for convenience:\n",
    "pred_log_test.index = test_index\n",
    "\n",
    "# Exponentiate back to original scale\n",
    "predictions_raw = np.exp(pred_log_test)\n",
    "\n",
    "# Kalman Filter\n",
    "kf = KalmanFilter(initial_state_mean=predictions_raw.iloc[0], n_dim_obs=1)\n",
    "kf = kf.em(predictions_raw, n_iter=5)\n",
    "predictions_smoothed_arr, _ = kf.filter(predictions_raw)\n",
    "predictions_smoothed = pd.Series(predictions_smoothed_arr.flatten(), index=predictions_raw.index)\n",
    "\n",
    "# Evaluation\n",
    "y_true = test_target_int.reindex(test_index)  # same integer index\n",
    "\n",
    "mae_raw  = mean_absolute_error(y_true, predictions_raw)\n",
    "rmse_raw = np.sqrt(mean_squared_error(y_true, predictions_raw))\n",
    "\n",
    "mae_smooth  = mean_absolute_error(y_true, predictions_smoothed)\n",
    "rmse_smooth = np.sqrt(mean_squared_error(y_true, predictions_smoothed))\n",
    "\n",
    "print(f\"\\n=== Evaluation on Test Set ===\")\n",
    "print(f\"RAW Predictions       => MAE = {mae_raw:.4f},  RMSE = {rmse_raw:.4f}\")\n",
    "print(f\"Smoothed Predictions  => MAE = {mae_smooth:.4f}, RMSE = {rmse_smooth:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_true.index, y_true, label=\"Actual (Test)\", marker=\"o\")\n",
    "plt.plot(predictions_raw.index, predictions_raw, label=\"Predicted (Raw)\", marker=\"*\")\n",
    "plt.plot(predictions_smoothed.index, predictions_smoothed, label=\"Predicted (Smoothed)\", linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.title(\"ARDL + PCA + 1-Lag PCA, with Integer-Based Forecasting (No Data Leakage)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
