{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allows imports from other folders in project\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARDL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.ardl import ARDL\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from pykalman import KalmanFilter\n",
    "from dataPreprocessing import best_lag_selection, train_val_test_split\n",
    "\n",
    "# Loading the data\n",
    "file_path = \"../Data/train/train1990s.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert to datetime and set as index\n",
    "df[\"observation_date\"] = pd.to_datetime(df[\"observation_date\"])\n",
    "df.set_index(\"observation_date\", inplace=True)\n",
    "\n",
    "# Ensure target variable exists\n",
    "if \"fred_PCEPI\" not in df.columns:\n",
    "    raise ValueError(\"Column 'fred_PCEPI' not found in dataset\")\n",
    "\n",
    "# (A) LOG-TRANSFORM (assuming PCEPI > 0)\n",
    "df[\"log_pcepi\"] = np.log(df[\"fred_PCEPI\"])\n",
    "\n",
    "# Train/Tets split\n",
    "\n",
    "train_X, train_y, _, _, test_X, test_y = train_val_test_split(df['log_pcepi'], df['fred_PCEPI'], train_size=0.9, val_size=0)\n",
    "\n",
    "print(f\"Train set size: {len(train_X)}\")\n",
    "print(f\"Test  set size: {len(test_X)}\")\n",
    "\n",
    "best_lag = best_lag_selection(train_X, max_lags=12)\n",
    "print(f\"Selected best lag (TRAIN only) for ARDL in levels: {best_lag}\")\n",
    "\n",
    "# ARDL model with a linear trend since no exogenous variables\n",
    "final_model = ARDL(endog=train_X, lags=best_lag, trend='ct').fit()\n",
    "print(\"\\n=== ARDL (levels) Model Summary ===\")\n",
    "print(final_model.summary())\n",
    "\n",
    "# Forecast in log-levels\n",
    "start_idx = test_X.index[0]\n",
    "end_idx   = test_X.index[-1]\n",
    "\n",
    "pred_log_test = final_model.predict(start=start_idx, end=end_idx)\n",
    "pred_log_test = pd.Series(pred_log_test, index=test_X.index)\n",
    "\n",
    "# Exponentiate to get back to original scale (raw predictions)\n",
    "predictions_raw = np.exp(pred_log_test)  # \"raw\" ARDL forecast in original PCEPI scale\n",
    "\n",
    "# Kalman Filter on the test forecast \n",
    "kf = KalmanFilter(initial_state_mean=predictions_raw.iloc[0], n_dim_obs=1)\n",
    "kf = kf.em(predictions_raw, n_iter=5)\n",
    "\n",
    "predictions_smoothed_arr, _ = kf.filter(predictions_raw)\n",
    "predictions_smoothed = pd.Series(predictions_smoothed_arr.flatten(), \n",
    "                                 index=predictions_raw.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "y_true = test_y\n",
    "\n",
    "# Align both raw and smoothed with the test index\n",
    "y_pred_raw     = predictions_raw.reindex(y_true.index)\n",
    "y_pred_smoothed = predictions_smoothed.reindex(y_true.index)\n",
    "\n",
    "# Evaluate RAW\n",
    "mae_raw = mean_absolute_error(y_true, y_pred_raw)\n",
    "rmse_raw = np.sqrt(mean_squared_error(y_true, y_pred_raw))\n",
    "\n",
    "# Evaluate SMOOTHED\n",
    "mae_smooth = mean_absolute_error(y_true, y_pred_smoothed)\n",
    "rmse_smooth = np.sqrt(mean_squared_error(y_true, y_pred_smoothed))\n",
    "\n",
    "print(f\"\\n=== Evaluation on Test Set ===\")\n",
    "print(f\"RAW Forecast  =>  MAE = {mae_raw:.4f},  RMSE = {rmse_raw:.4f}\")\n",
    "print(f\"Smoothed      =>  MAE = {mae_smooth:.4f},  RMSE = {rmse_smooth:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_true.index, y_true, label=\"Actual (Test)\", marker=\"o\")\n",
    "plt.plot(y_pred_raw.index, y_pred_raw, label=\"Predicted (Raw)\", marker=\"*\")\n",
    "plt.plot(y_pred_smoothed.index, y_pred_smoothed, \n",
    "         label=\"Predicted (Smoothed)\", linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.title(\"ARDL (Levels) + Kalman Filter: RAW vs. SMOOTHED Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Exogenous Variables to catch trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.ardl import ARDL\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "# Loading data\n",
    "file_path = \"../Data/train/trains1990s.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert to datetime and set index\n",
    "df[\"observation_date\"] = pd.to_datetime(df[\"observation_date\"])\n",
    "df.set_index(\"observation_date\", inplace=True)\n",
    "\n",
    "# Ensure target\n",
    "if \"fred_PCEPI\" not in df.columns:\n",
    "    raise ValueError(\"Column 'fred_PCEPI' not found in dataset\")\n",
    "\n",
    "# Drop rows that have missing values in ANY column\n",
    "df.dropna(axis=0, how=\"any\", inplace=True)\n",
    "\n",
    "# Take log of the target\n",
    "df[\"log_pcepi\"] = np.log(df[\"fred_PCEPI\"])\n",
    "\n",
    "print(f\"Remaining rows after dropna: {len(df)}\")\n",
    "\n",
    "# Train/Test split\n",
    "train_size = int(0.90 * len(df))\n",
    "train_df = df.iloc[:train_size].copy()\n",
    "test_df  = df.iloc[train_size:].copy()\n",
    "\n",
    "print(f\"\\nTrain set size: {len(train_df)}\")\n",
    "print(f\"Test  set size: {len(test_df)}\")\n",
    "\n",
    "# Remove near-constant columns\n",
    "def drop_near_constant_cols(dataframe, threshold=1e-6):\n",
    "    dropped_cols, keep_cols = [], []\n",
    "    for col in dataframe.columns:\n",
    "        if dataframe[col].std() <= threshold:\n",
    "            dropped_cols.append(col)\n",
    "        else:\n",
    "            keep_cols.append(col)\n",
    "    return dataframe[keep_cols], dropped_cols\n",
    "\n",
    "all_exog_cols = [c for c in df.columns if c not in [\"fred_PCEPI\", \"log_pcepi\"]]\n",
    "train_exog_full = train_df[all_exog_cols]\n",
    "test_exog_full  = test_df[all_exog_cols]\n",
    "\n",
    "train_exog_clean, dropped_cols = drop_near_constant_cols(train_exog_full, threshold=1e-6)\n",
    "test_exog_clean = test_exog_full.drop(columns=dropped_cols, errors=\"ignore\")\n",
    "\n",
    "print(f\"\\nDropped near-constant exogenous columns: {dropped_cols}\")\n",
    "print(f\"Remaining exog columns after drop: {len(train_exog_clean.columns)}\")\n",
    "\n",
    "# PCA Transform\n",
    "NUM_COMPONENTS = 10\n",
    "pca = PCA(n_components=NUM_COMPONENTS)\n",
    "pca.fit(train_exog_clean)  # fit on train only\n",
    "\n",
    "train_exog_pca = pca.transform(train_exog_clean)\n",
    "test_exog_pca  = pca.transform(test_exog_clean)\n",
    "\n",
    "pca_cols = [f\"PC{i+1}\" for i in range(NUM_COMPONENTS)]\n",
    "train_exog = pd.DataFrame(train_exog_pca, index=train_df.index, columns=pca_cols)\n",
    "test_exog  = pd.DataFrame(test_exog_pca,  index=test_df.index,  columns=pca_cols)\n",
    "\n",
    "# Creating 1 lag of the PCA Components\n",
    "def add_lags_to_pca(df_pca, lags=1):\n",
    "    out_df = df_pca.copy()\n",
    "    for col in df_pca.columns:\n",
    "        for lag_i in range(1, lags+1):\n",
    "            out_df[f\"{col}_L{lag_i}\"] = df_pca[col].shift(lag_i)\n",
    "    return out_df\n",
    "\n",
    "train_exog_lags = add_lags_to_pca(train_exog, lags=1)\n",
    "test_exog_lags  = add_lags_to_pca(test_exog,  lags=1)\n",
    "\n",
    "# Drop the NaNs from shifting\n",
    "train_exog_lags.dropna(inplace=True)\n",
    "test_exog_lags.dropna(inplace=True)\n",
    "\n",
    "# Align the target with the new exog indexes\n",
    "train_target = train_df[\"log_pcepi\"].loc[train_exog_lags.index]\n",
    "test_target = test_df[\"fred_PCEPI\"].loc[test_exog_lags.index]\n",
    "\n",
    "print(f\"\\nAfter adding 1 lag, train exog shape: {train_exog_lags.shape}\")\n",
    "print(f\"Train target shape: {train_target.shape}\")\n",
    "print(f\"Test exog shape: {test_exog_lags.shape}\")\n",
    "print(f\"Test target shape: {test_target.shape}\")\n",
    "\n",
    "# Best Lag selection for the target (no differencing)\n",
    "def best_lag_selection(train_series, max_lags=12):\n",
    "    pacf_vals = pacf(train_series, nlags=max_lags)\n",
    "    best_pacf_lag = np.argmax(np.abs(pacf_vals[1:])) + 1\n",
    "\n",
    "    best_aic_lag, best_aic = 1, float(\"inf\")\n",
    "    for lag in range(1, max_lags + 1):\n",
    "        y = train_series[lag:]\n",
    "        X = train_series.shift(lag)[lag:]\n",
    "        X = sm.add_constant(X, prepend=True)\n",
    "        try:\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            if model.aic < best_aic:\n",
    "                best_aic_lag = lag\n",
    "                best_aic = model.aic\n",
    "        except:\n",
    "            continue\n",
    "    return min(best_pacf_lag, best_aic_lag)\n",
    "\n",
    "best_lag = best_lag_selection(train_target, max_lags=12)\n",
    "print(f\"\\nSelected best AR lag for target: {best_lag}\")\n",
    "\n",
    "# Convert everything to integer indexing\n",
    "# Because ARDL tries to produce date-based forecasts for the entire date range,\n",
    "# we can convert both train and test to 0-based integer index so we produce\n",
    "# exactly as many forecasts as test_exog_lags rows.\n",
    "\n",
    "train_index = np.arange(len(train_exog_lags))\n",
    "test_index  = np.arange(len(test_exog_lags))\n",
    "\n",
    "train_exog_lags_int = train_exog_lags.copy()\n",
    "test_exog_lags_int  = test_exog_lags.copy()\n",
    "\n",
    "train_exog_lags_int.index = train_index\n",
    "test_exog_lags_int.index  = test_index\n",
    "\n",
    "train_target_int = pd.Series(train_target.values, index=train_index)\n",
    "test_target_int  = pd.Series(test_target.values, index=test_index)\n",
    "\n",
    "# ARDL model using integer index\n",
    "final_model = ARDL(\n",
    "    endog=train_target_int,\n",
    "    exog=train_exog_lags_int,\n",
    "    lags=best_lag,\n",
    "    trend='ct'\n",
    ").fit()\n",
    "\n",
    "print(\"\\n=== ARDL (levels) Model Summary ===\")\n",
    "print(final_model.summary())\n",
    "\n",
    "# Forecast with Exog out-of-sample (Integer-based)\n",
    "# Will produce exactly `len(test_exog_lags_int)` forecasts\n",
    "start_i = len(train_exog_lags_int)\n",
    "end_i   = start_i + len(test_exog_lags_int) - 1\n",
    "\n",
    "pred_log_test = final_model.predict(\n",
    "    start=start_i,\n",
    "    end=end_i,\n",
    "    exog_oos=test_exog_lags_int  # The same # of rows as the forecast steps\n",
    ")\n",
    "\n",
    "# pred_log_test is now indexed from `start_i` to `end_i`\n",
    "# re-index it to 0..len(test_exog_lags_int)-1 for convenience:\n",
    "pred_log_test.index = test_index\n",
    "\n",
    "# Exponentiate back to original scale\n",
    "predictions_raw = np.exp(pred_log_test)\n",
    "\n",
    "# Kalman Filter\n",
    "kf = KalmanFilter(initial_state_mean=predictions_raw.iloc[0], n_dim_obs=1)\n",
    "kf = kf.em(predictions_raw, n_iter=5)\n",
    "predictions_smoothed_arr, _ = kf.filter(predictions_raw)\n",
    "predictions_smoothed = pd.Series(predictions_smoothed_arr.flatten(), index=predictions_raw.index)\n",
    "\n",
    "# Evaluation\n",
    "y_true = test_target_int.reindex(test_index)  # same integer index\n",
    "\n",
    "mae_raw  = mean_absolute_error(y_true, predictions_raw)\n",
    "rmse_raw = np.sqrt(mean_squared_error(y_true, predictions_raw))\n",
    "\n",
    "mae_smooth  = mean_absolute_error(y_true, predictions_smoothed)\n",
    "rmse_smooth = np.sqrt(mean_squared_error(y_true, predictions_smoothed))\n",
    "\n",
    "print(f\"\\n=== Evaluation on Test Set ===\")\n",
    "print(f\"RAW Predictions       => MAE = {mae_raw:.4f},  RMSE = {rmse_raw:.4f}\")\n",
    "print(f\"Smoothed Predictions  => MAE = {mae_smooth:.4f}, RMSE = {rmse_smooth:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_true.index, y_true, label=\"Actual (Test)\", marker=\"o\")\n",
    "plt.plot(predictions_raw.index, predictions_raw, label=\"Predicted (Raw)\", marker=\"*\")\n",
    "plt.plot(predictions_smoothed.index, predictions_smoothed, label=\"Predicted (Smoothed)\", linestyle=\"--\")\n",
    "plt.legend()\n",
    "plt.title(\"ARDL + PCA + 1-Lag PCA, with Integer-Based Forecasting (No Data Leakage)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
