{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import TiDEModel\n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up two levels from notebook (Training/MLR) to project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Project root added to sys.path:\", project_root)\n",
    "# Ensure the model save directory exists\n",
    "model_save_path = os.path.join('.')\n",
    "os.makedirs(model_save_path, exist_ok=True)  # Creates directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Training.Helper.dataPreprocessing import TRAIN_DATA_PATH_1990S, get_untransformed_exog\n",
    "date_col = 'observation_date'\n",
    "\n",
    "# Load and format training data (only using PCEPI)\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH_1990S)\n",
    "train_df = get_untransformed_exog(train_df)\n",
    "# Convert the date column to datetime format\n",
    "train_df[date_col] = pd.to_datetime(train_df[date_col], format='%m/%Y')\n",
    "\n",
    "# Set the date column as the index\n",
    "train_df.set_index(date_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "target_series = TimeSeries.from_series(train_df['fred_PCEPI'])\n",
    "\n",
    "# Extract the exogenous variables (all columns except 'fred_PCEPI')\n",
    "exogenous_variables = train_df.drop(columns=['fred_PCEPI'])\n",
    "exogenous_series = TimeSeries.from_dataframe(exogenous_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TiDEModel(input_chunk_length=24, output_chunk_length=6)\n",
    "\n",
    "# Fit the model with the target series and exogenous variables\n",
    "model.fit(series=target_series,past_covariates=exogenous_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(6)\n",
    "pred.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is terrible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split validation and training then scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = target_series.split_after(0.8)\n",
    "train_exo, val_exo = exogenous_series.split_after(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetScaler = Scaler()  # default uses sklearn's MinMaxScaler\n",
    "scaled_target = targetScaler.fit_transform(train)\n",
    "scaled_val = targetScaler.transform(val)\n",
    "\n",
    "exoScaler = Scaler() \n",
    "scaled_train_exo = exoScaler.fit_transform(train_exo)\n",
    "scaled_val_exo = exoScaler.transform(val_exo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_target.plot(label=\"train\")\n",
    "scaled_val.plot(label=\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    min_delta=1e-3,\n",
    "    mode='min'\n",
    ")\n",
    "lr_scheduler_kwargs = {\n",
    "    \"gamma\": 0.999,\n",
    "}\n",
    "model = TiDEModel(\n",
    "    input_chunk_length=48,\n",
    "    output_chunk_length=12,\n",
    "    pl_trainer_kwargs={\"callbacks\": [early_stopper]},\n",
    "    optimizer_kwargs={\"lr\": 1e-3},\n",
    "    lr_scheduler_cls= lr_scheduler.ExponentialLR,\n",
    "    lr_scheduler_kwargs = {\"gamma\": 0.999},\n",
    "    use_reversible_instance_norm = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(series=scaled_target,past_covariates=scaled_train_exo,val_series=scaled_val,val_past_covariates=scaled_val_exo,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that good so optuna test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = pd.Timestamp('2022-12')\n",
    "op_train , op_val = target_series.split_after(split_date)\n",
    "op_train_exo , op_val_exo = exogenous_series.split_after(split_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from darts.metrics import mse\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    # Define early stopping callback\n",
    "    early_stopper = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        min_delta=1e-3,\n",
    "        mode='min',\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    trial_params = {\n",
    "        'input_chunk_length': trial.suggest_int(\"input_chunk_length\", 24, 60),\n",
    "        'output_chunk_length': 12,\n",
    "        'num_encoder_layers': trial.suggest_int(\"num_encoder_layers\", 1, 3),\n",
    "        'num_decoder_layers': trial.suggest_int(\"num_decoder_layers\", 1, 3),\n",
    "        'hidden_size': trial.suggest_int(\"hidden_size\", 64, 512),\n",
    "        'dropout': trial.suggest_float(\"dropout\", 0.1, 0.5),\n",
    "        'optimizer_kwargs': {\"lr\": trial.suggest_float(\"optimizer_lr\", 1e-4, 1e-2, log=False)},\n",
    "        'lr_scheduler_cls': lr_scheduler.ExponentialLR,\n",
    "        'lr_scheduler_kwargs': {\"gamma\": trial.suggest_float(\"scheduler_gamma\", 0.9, 1.0)},\n",
    "        'pl_trainer_kwargs': {\"callbacks\": [early_stopper]},\n",
    "        'use_reversible_instance_norm': trial.suggest_categorical('use_reversible_instance_norm', [True, False]),\n",
    "    }\n",
    "\n",
    "    # Initialize the TiDEModel with suggested hyperparameters\n",
    "    model = TiDEModel(**trial_params)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(series=scaled_target,past_covariates=scaled_train_exo, val_series=scaled_val, val_past_covariates=scaled_val_exo, verbose=False)\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_predictions = model.predict(n=12,series=op_train,past_covariates=op_train_exo, verbose=False)\n",
    "    transformed_predictions = targetScaler.inverse_transform(val_predictions, verbose=False)\n",
    "    error = mse(op_val, transformed_predictions, verbose=False)\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(f\"Best hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best params made into a model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TiDEModel with (now fossilised) suggested hyperparameters\n",
    "    # Define early stopping callback\n",
    "#early_stopper = EarlyStopping(\n",
    "#    monitor='val_loss',\n",
    "#    patience=10,\n",
    "#    min_delta=1e-3,\n",
    "#    mode='min'\n",
    "#)\n",
    "#model = TiDEModel(\n",
    "#    input_chunk_length=29,\n",
    "#    output_chunk_length=12,\n",
    "#    num_encoder_layers=3,\n",
    "#    num_decoder_layers=2,\n",
    "#    hidden_size=443,\n",
    "#    dropout= 0.19411763114257125,\n",
    "#    optimizer_kwargs={\"lr\": 0.00014544898516544107},\n",
    "#    lr_scheduler_cls=torch.optim.lr_scheduler.ExponentialLR,\n",
    "#    lr_scheduler_kwargs={\"gamma\": 0.9645025339005199},\n",
    "#    pl_trainer_kwargs={\"callbacks\": [early_stopper]},\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a clean set of parameters from the suggested best parameters\n",
    "import copy\n",
    "\n",
    "# a shallow copy will do\n",
    "clean_params = copy.copy(best_params)\n",
    "del clean_params['optimizer_lr'], clean_params['scheduler_gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    min_delta=1e-3,\n",
    "    mode='min'\n",
    ")\n",
    "clean_params['output_chunk_length'] = 12\n",
    "clean_params['lr_scheduler_cls'] = lr_scheduler.ExponentialLR\n",
    "clean_params['optimizer_kwargs'] = {'lr': best_params['optimizer_lr']}\n",
    "clean_params['lr_scheduler_kwargs'] = {'gamma': best_params['scheduler_gamma']}\n",
    "clean_params['pl_trainer_kwargs'] = {\"callbacks\": [early_stopper]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TiDEModel with suggested hyperparameters\n",
    "    # Define early stopping callback\n",
    "model = TiDEModel(**clean_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(series=scaled_target,past_covariates=scaled_train_exo, val_series=scaled_val, val_past_covariates=scaled_val_exo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict over the test horizon\n",
    "TEST_HORIZON = 12\n",
    "val_predictions = model.predict(n=TEST_HORIZON)\n",
    "transformed_predictions = targetScaler.inverse_transform(val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.Helper.evaluation_helpers import display_results\n",
    "\n",
    "actuals = val[:TEST_HORIZON].values()\n",
    "preds = transformed_predictions.values()\n",
    "\n",
    "display_results(actuals, preds, val[:TEST_HORIZON].time_index, 'TiDE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.Helper.evaluation_helpers import calc_metrics_arrays\n",
    "\n",
    "# Evaluate the model\n",
    "calc_metrics_arrays(actuals, preds, model_names=['TiDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"tide.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go from here if wanting to load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import TiDEModel\n",
    "\n",
    "# Load the model from the file\n",
    "model = TiDEModel.load(\"tide.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_total = targetScaler.fit_transform(target_series)\n",
    "\n",
    "scaled_total_exo = exoScaler.fit_transform(exogenous_series)\n",
    "\n",
    "pred = model.predict(12,series=scaled_total,past_covariates=scaled_total_exo)\n",
    "finalout = targetScaler.inverse_transform(pred)\n",
    "print(f'Final predictions:\\n{finalout.to_dataframe()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(os.path.join(project_root, 'Predictions', 'Tide.npy'), finalout.to_dataframe().to_numpy().flatten())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
