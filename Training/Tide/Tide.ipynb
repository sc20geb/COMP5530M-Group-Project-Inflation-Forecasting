{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import TiDEModel\n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up two levels from notebook (Training/MLR) to project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Project root added to sys.path:\", project_root)\n",
    "# Ensure the model save directory exists\n",
    "model_save_path = os.path.join(project_root, 'Models', 'Weights', 'MLR')\n",
    "os.makedirs(model_save_path, exist_ok=True)  # Creates directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from Training.Helper.dataPreprocessing import TRAIN_DATA_PATH_1990S, get_untransformed_exog\n",
    "date_col = 'observation_date'\n",
    "\n",
    "# Load and format training data (only using PCEPI)\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH_1990S)\n",
    "train_df = get_untransformed_exog(train_df)\n",
    "# Convert the date column to datetime format\n",
    "train_df[date_col] = pd.to_datetime(train_df[date_col], format='%m/%Y')\n",
    "\n",
    "# Set the date column as the index\n",
    "train_df.set_index(date_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "target_series = TimeSeries.from_series(train_df['fred_PCEPI'])\n",
    "\n",
    "# Extract the exogenous variables (all columns except 'fred_PCEPI')\n",
    "exogenous_variables = train_df.drop(columns=['fred_PCEPI'])\n",
    "exogenous_series = TimeSeries.from_dataframe(exogenous_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TiDEModel(input_chunk_length=24, output_chunk_length=6)\n",
    "\n",
    "# Fit the model with the target series and exogenous variables\n",
    "model.fit(series=target_series,past_covariates=exogenous_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(6)\n",
    "pred.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is terrible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split validation and training then scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train , val = target_series.split_after(0.8)\n",
    "train_exo , val_exo = exogenous_series.split_after(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetScaler = Scaler()  # default uses sklearn's MinMaxScaler\n",
    "scaled_target = targetScaler.fit_transform(train)\n",
    "scaled_val = targetScaler.transform(val)\n",
    "\n",
    "exoScaler = Scaler() \n",
    "scaled_train_exo = exoScaler.fit_transform(train_exo)\n",
    "scaled_val_exo = exoScaler.transform(val_exo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_target.plot(label=\"train\")\n",
    "scaled_val.plot(label=\"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    min_delta=1e-3,\n",
    "    mode='min'\n",
    ")\n",
    "lr_scheduler_kwargs = {\n",
    "    \"gamma\": 0.999,\n",
    "}\n",
    "model = TiDEModel(\n",
    "    input_chunk_length=48,\n",
    "    output_chunk_length=12,\n",
    "    pl_trainer_kwargs={\n",
    "        \"callbacks\": [early_stopper]\n",
    "    },\n",
    "    optimizer_kwargs={\n",
    "        \"lr\": 1e-3,\n",
    "    },\n",
    "    lr_scheduler_cls= torch.optim.lr_scheduler.ExponentialLR,\n",
    "    lr_scheduler_kwargs = {\n",
    "        \"gamma\": 0.999,\n",
    "    },\n",
    "    use_reversible_instance_norm = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaled_val)\n",
    "model.fit(series=scaled_target,past_covariates=scaled_train_exo,val_series=scaled_val,val_past_covariates=scaled_val_exo,verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that good so optuna test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_date = pd.Timestamp('2022-12')\n",
    "op_train , op_val = target_series.split_after(split_date)\n",
    "op_train_exo , op_val_exo = exogenous_series.split_after(split_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from darts.metrics import mse\n",
    "def objective(trial):\n",
    "    \n",
    "    input_chunk_length = trial.suggest_int(\"input_chunk_length\", 24, 60)\n",
    "    num_encoder_layers = trial.suggest_int(\"num_encoder_layers\", 1, 3)\n",
    "    num_decoder_layers = trial.suggest_int(\"num_decoder_layers\", 1, 3)\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 64, 512)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.9, 1.0)\n",
    "    urin = trial.suggest_categorical('use_reversible_instance_norm', [True, False])\n",
    "    \n",
    "    # Define early stopping callback\n",
    "    early_stopper = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        min_delta=1e-3,\n",
    "        mode='min'\n",
    "    )\n",
    "\n",
    "    # Initialize the TiDEModel with suggested hyperparameters\n",
    "    model = TiDEModel(\n",
    "        input_chunk_length=input_chunk_length,\n",
    "        output_chunk_length=12,\n",
    "        num_encoder_layers=num_encoder_layers,\n",
    "        num_decoder_layers=num_decoder_layers,\n",
    "        hidden_size=hidden_size,\n",
    "        dropout=dropout,\n",
    "        optimizer_kwargs={\"lr\": lr},\n",
    "        lr_scheduler_cls=torch.optim.lr_scheduler.ExponentialLR,\n",
    "        lr_scheduler_kwargs={\"gamma\": gamma},\n",
    "        pl_trainer_kwargs={\"callbacks\": [early_stopper]},\n",
    "        use_reversible_instance_norm = urin,\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(series=scaled_target,past_covariates=scaled_train_exo, val_series=scaled_val, val_past_covariates=scaled_val_exo)\n",
    "\n",
    "    # Evaluate the model\n",
    "    val_predictions = model.predict(n=12,series=op_train,past_covariates=op_train_exo)\n",
    "    transformed_predictions = targetScaler.inverse_transform(val_predictions)\n",
    "    error = mse(op_val, transformed_predictions)\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Optuna study and optimize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(f\"Best hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params\n",
    "print(f\"Best hyperparameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best params made into a model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Initialize the TiDEModel with suggested hyperparameters\n",
    "        # Define early stopping callback\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    min_delta=1e-3,\n",
    "    mode='min'\n",
    ")\n",
    "model = TiDEModel(\n",
    "    input_chunk_length=29,\n",
    "    output_chunk_length=12,\n",
    "    num_encoder_layers=3,\n",
    "    num_decoder_layers=2,\n",
    "    hidden_size=443,\n",
    "    dropout= 0.19411763114257125,\n",
    "    optimizer_kwargs={\"lr\": 0.00014544898516544107},\n",
    "    lr_scheduler_cls=torch.optim.lr_scheduler.ExponentialLR,\n",
    "    lr_scheduler_kwargs={\"gamma\": 0.9645025339005199},\n",
    "    pl_trainer_kwargs={\"callbacks\": [early_stopper]},\n",
    ")\n",
    "\n",
    "    # Fit the model\n",
    "model.fit(series=scaled_target,past_covariates=scaled_train_exo, val_series=scaled_val, val_past_covariates=scaled_val_exo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Evaluate the model\n",
    "val_predictions = model.predict(n=12)\n",
    "transformed_predictions = targetScaler.inverse_transform(val_predictions)\n",
    "error = mse(val[:12], transformed_predictions)\n",
    "print(transformed_predictions)\n",
    "print(val[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"tide.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go from here if wanting to load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts.models import TiDEModel\n",
    "\n",
    "# Load the model from the file\n",
    "model = TiDEModel.load(\"tide.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd70cee9f32b4b3ab1638e7e769893a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TimeSeries (DataArray) (observation_date: 12, component: 1, sample: 1)> Size: 96B\n",
      "array([[[120.73741928]],\n",
      "\n",
      "       [[119.62603144]],\n",
      "\n",
      "       [[121.67087353]],\n",
      "\n",
      "       [[120.84724138]],\n",
      "\n",
      "       [[120.40772379]],\n",
      "\n",
      "       [[120.50845336]],\n",
      "\n",
      "       [[121.41947704]],\n",
      "\n",
      "       [[121.35732624]],\n",
      "\n",
      "       [[121.01175032]],\n",
      "\n",
      "       [[122.53061746]],\n",
      "\n",
      "       [[119.56874947]],\n",
      "\n",
      "       [[122.01329452]]])\n",
      "Coordinates:\n",
      "  * observation_date  (observation_date) datetime64[ns] 96B 2024-01-01 ... 20...\n",
      "  * component         (component) object 8B 'fred_PCEPI'\n",
      "Dimensions without coordinates: sample\n",
      "Attributes:\n",
      "    static_covariates:  None\n",
      "    hierarchy:          None\n",
      "    metadata:           None\n"
     ]
    }
   ],
   "source": [
    "scaled_total = targetScaler.fit_transform(target_series)\n",
    "\n",
    "scaled_total_exo = exoScaler.fit_transform(exogenous_series)\n",
    "\n",
    "pred = model.predict(12,series=scaled_total,past_covariates=scaled_total_exo)\n",
    "finalout = targetScaler.inverse_transform(pred)\n",
    "print(finalout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "temp = finalout.to_dataframe()\n",
    "flattend = temp.to_numpy().flatten().tolist()\n",
    "np.save(f\"..\\\\..\\\\Predictions\\\\Tide.npy\",flattend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
