{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allows imports from other folders in project\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBEATS MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Models.NBEATS import NBeats\n",
    "from dataPreprocessing import load_data, prepare_dataloader\n",
    "\n",
    "\n",
    "# Load Data and Create Model\n",
    "train_file = \"../Data/Train/train1990s.csv\"\n",
    "config = {\n",
    "    \"use_fft\": False,  # No FFT needed\n",
    "    \"use_exog\": False  # No exogenous variables\n",
    "}\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test, dates, y_scaler = load_data(train_file, config=config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NBeats(input_size=X_train.shape[1]).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train with extant module:\n",
    "from PyTorchModular import train_model\n",
    "\n",
    "# Prepare DataLoaders\n",
    "dataloader_train = prepare_dataloader(X_train, y_train)\n",
    "dataloader_valid = prepare_dataloader(X_valid, y_valid)\n",
    "dataloader_test = prepare_dataloader(X_test, y_test)\n",
    "\n",
    "# Training Setup\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.005, weight_decay=5e-7)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "savepath = '../Models/Weights/'\n",
    "trainingMetadata = train_model(model, 120, savepath, 'nbeats', dataloader_train, dataloader_valid, loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.evaluation_helpers import evaluate_model, get_best_path\n",
    "plt.ioff() #use this if you want to control when the visualisation is shown\n",
    "\n",
    "#find the path to the best model of this kind (may not be the model trained above if training has been run several times)\n",
    "bestPath = get_best_path(savepath, model.__class__.__name__.lower())\n",
    "#make predictions using this model\n",
    "predictions = evaluate_model(model, bestPath, X_test, device, y_scaler)\n",
    "# Convert y_test Back to Original Scale\n",
    "y_test_original = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "# Final Improved Graph\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(dates[-len(y_test_original):], y_test_original, label=\"Actual PCEPI\", color=\"blue\", linewidth=2)\n",
    "plt.plot(dates[-len(predictions):], predictions, label=\"Predicted PCEPI\", linestyle=\"dashed\", color=\"orange\", linewidth=2)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"PCEPI\")\n",
    "plt.title(\"Final Optimized N-BEATS PCE Prediction (Residual Learning + Fourier Features)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# Compute MAE\n",
    "mae = mean_absolute_error(y_test_original, predictions)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_original, predictions))\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.5f}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residual errors\n",
    "residuals = y_test_original - predictions\n",
    "\n",
    "# Visualise residual errors\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(dates[-len(residuals):], residuals, label=\"Residual Errors\", color=\"red\", linewidth=2)\n",
    "plt.axhline(y=0, color='black', linestyle='dashed')  # Reference line at 0\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Residual Error\")\n",
    "plt.title(\"Residual Errors Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=30, edgecolor='black', color='red', alpha=0.7)\n",
    "plt.xlabel(\"Residual Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.axvline(x=0, color='black', linestyle='dashed')  # Reference line at 0\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
