{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allows imports from other folders in project\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBEATS MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Models.NBEATS import NBeats\n",
    "from Helper.dataPreprocessing import load_data, prepare_dataloader, TRAIN_DATA_PATH_1990S\n",
    "from Helper.PyTorchModular import train_model, loss_curve\n",
    "\n",
    "# Load Data and Create Model\n",
    "config = {\n",
    "    \"use_fft\": False,  # No FFT needed\n",
    "    \"use_exog\": False  # No exogenous variables in N-BEATS\n",
    "}\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test, dates, y_scaler = load_data(TRAIN_DATA_PATH_1990S, config=config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NBeats(input_size=X_train.shape[1]).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare DataLoaders\n",
    "dataloader_train = prepare_dataloader(X_train, y_train)\n",
    "dataloader_valid = prepare_dataloader(X_valid, y_valid)\n",
    "dataloader_test = prepare_dataloader(X_test, y_test)\n",
    "\n",
    "# Training Setup\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.005, weight_decay=5e-7)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "savepath = os.path.join(module_path, 'Models', 'Weights', 'NBEATS')\n",
    "\n",
    "# Train Model\n",
    "trainingMetadata = train_model(\n",
    "    model, \n",
    "    maxEpochs=120, \n",
    "    modelSavePath=savepath, \n",
    "    modelName='nbeats', \n",
    "    dataLoaderTrain=dataloader_train, \n",
    "    dataLoaderValid=dataloader_valid, \n",
    "    lossFn=loss_fn, \n",
    "    optimizer=optimizer, \n",
    "    device=device, \n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Output and Make Evaluation Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.Helper.evaluation_helpers import evaluate_model, make_evaluation_predictions\n",
    "\n",
    "# Retrieve best model path from training metadata\n",
    "best_model_path = trainingMetadata.get(\"best_model_path\")\n",
    "\n",
    "# Ensure the model file exists before proceeding\n",
    "if best_model_path and os.path.exists(best_model_path):\n",
    "    print(f\"Loading best model from: {best_model_path}\")\n",
    "    df_comparison, rmse = evaluate_model(model, dataloader_test, y_scaler, dates, device, savepath=best_model_path, verbose=True)\n",
    "    predictions, y_test_original = make_evaluation_predictions(model, dataloader_test, savepath=best_model_path, y_scaler=y_scaler)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Best model file not found: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Evaluation Metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_test_original, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_original, predictions))\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.5f}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residual errors\n",
    "residuals = y_test_original - predictions\n",
    "\n",
    "# Visualize Residual Errors Over Time\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(dates[-len(residuals):], residuals, label=\"Residual Errors\", color=\"red\", linewidth=2)\n",
    "plt.axhline(y=0, color='black', linestyle='dashed')  # Reference line at 0\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Residual Error\")\n",
    "plt.title(\"Residual Errors Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Histogram of Residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=30, edgecolor='black', color='red', alpha=0.7)\n",
    "plt.xlabel(\"Residual Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.axvline(x=0, color='black', linestyle='dashed')  # Reference line at 0\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
