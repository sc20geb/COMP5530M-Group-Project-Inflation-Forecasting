{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBEATS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from scipy.fftpack import fft\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Load and Format Data for N-BEATS\n",
    "def load_data(train_file, sequence_length=48):\n",
    "    df = pd.read_csv(train_file)\n",
    "    df[\"observation_date\"] = pd.to_datetime(df[\"observation_date\"], format=\"%m/%Y\")\n",
    "    df = df.sort_values(by=\"observation_date\").reset_index(drop=True)\n",
    "\n",
    "    target_col = \"fred_PCEPI\"\n",
    "    data = df[[target_col]].values.astype(np.float32)\n",
    "\n",
    "    # Compute Fourier Transform Features for Seasonality\n",
    "    fft_features = np.abs(fft(data.flatten()))[:sequence_length]\n",
    "    fft_features = (fft_features - np.min(fft_features)) / (np.max(fft_features) - np.min(fft_features))\n",
    "\n",
    "    # Create Sequences (Past sequence_length Months â†’ Next Month)\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(np.hstack([data[i : i + sequence_length].flatten(), fft_features]))  \n",
    "        y.append(data[i + sequence_length])  \n",
    "\n",
    "    X, y = np.array(X), np.array(y)\n",
    "\n",
    "    # Train-Validation-Test Split (70%-15%-15%)\n",
    "    train_idx = int(len(X) * 0.7)\n",
    "    valid_idx = int(len(X) * 0.85)\n",
    "\n",
    "    X_train, y_train = X[:train_idx], y[:train_idx]\n",
    "    X_valid, y_valid = X[train_idx:valid_idx], y[train_idx:valid_idx]\n",
    "    X_test, y_test = X[valid_idx:], y[valid_idx:]\n",
    "\n",
    "    # Fix Data Leakage: Scale After Splitting\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_valid = scaler.transform(X_valid)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    y_scaler = MinMaxScaler()\n",
    "    y_train = y_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "    y_valid = y_scaler.transform(y_valid.reshape(-1, 1))\n",
    "    y_test = y_scaler.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test, df[\"observation_date\"][sequence_length:], scaler, y_scaler\n",
    "\n",
    "# Convert Data to PyTorch Tensors\n",
    "def prepare_dataloader(X, y, batch_size=32):\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# N-BEATS Model with Residual Learning\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.hidden = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        self.residual = nn.Linear(input_size, output_size)  # Residual connection\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)  \n",
    "        return self.hidden(x) + self.residual(x)  # Residual Learning\n",
    "\n",
    "class NBeats(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=512, output_size=1):\n",
    "        super(NBeats, self).__init__()\n",
    "        self.trend_block = ResidualBlock(input_size, hidden_size, output_size)\n",
    "        self.seasonality_block = ResidualBlock(input_size, hidden_size, output_size)\n",
    "        self.skip = nn.Linear(input_size, output_size)  # Skip connection\n",
    "\n",
    "    def forward(self, x):\n",
    "        trend = self.trend_block(x)\n",
    "        seasonality = self.seasonality_block(x)\n",
    "        skip_connection = self.skip(x.view(x.shape[0], -1))  # Shortcut\n",
    "        return trend + seasonality + skip_connection\n",
    "\n",
    "# Load Data and Create Model\n",
    "train_file = \"../Data/Train/train1990s.csv\"\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test, dates, scaler, y_scaler = load_data(train_file)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = NBeats(input_size=X_train.shape[1]).to(device)\n",
    "\n",
    "# Prepare DataLoaders\n",
    "dataloader_train = prepare_dataloader(X_train, y_train)\n",
    "dataloader_valid = prepare_dataloader(X_valid, y_valid)\n",
    "dataloader_test = prepare_dataloader(X_test, y_test)\n",
    "\n",
    "# Training Setup\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.005, weight_decay=5e-7)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# Train the Optimized N-BEATS Model with Early Stopping\n",
    "def train_model(model, train_loader, valid_loader, loss_fn, optimizer, scheduler, device, max_epochs=120):\n",
    "    model.train()\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    patience, patience_counter = 15, 0\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        train_loss, valid_loss = 0, 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(X_batch)\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in valid_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                predictions = model(X_batch)\n",
    "                loss = loss_fn(predictions, y_batch)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_valid_loss = valid_loss / len(valid_loader)\n",
    "        print(f\"Epoch {epoch+1}/{max_epochs}, Train Loss: {avg_train_loss:.5f}, Valid Loss: {avg_valid_loss:.5f}\")\n",
    "\n",
    "        # Pass validation loss to scheduler\n",
    "        scheduler.step(avg_valid_loss)\n",
    "\n",
    "        if avg_valid_loss < best_valid_loss:\n",
    "            best_valid_loss = avg_valid_loss\n",
    "            torch.save(model.state_dict(), \"best_nbeats.pth\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break\n",
    "\n",
    "train_model(model, dataloader_train, dataloader_valid, loss_fn, optimizer, scheduler, device, max_epochs=120)\n",
    "\n",
    "# Load Best Model and Evaluate on Test Set\n",
    "model.load_state_dict(torch.load(\"best_nbeats.pth\"))\n",
    "model.eval()\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "predictions = model(X_test_tensor).detach().cpu().numpy()\n",
    "\n",
    "# Convert Predictions Back to Original Scale\n",
    "predictions = y_scaler.inverse_transform(predictions)\n",
    "y_test_original = y_scaler.inverse_transform(y_test)\n",
    "\n",
    "# Final Improved Graph\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(dates[-len(y_test_original):], y_test_original, label=\"Actual PCEPI\", color=\"blue\", linewidth=2)\n",
    "plt.plot(dates[-len(predictions):], predictions, label=\"Predicted PCEPI\", linestyle=\"dashed\", color=\"orange\", linewidth=2)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"PCEPI\")\n",
    "plt.title(\"Final Optimized N-BEATS PCE Prediction (Residual Learning + Fourier Features)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute residual errors\n",
    "residuals = y_test_original - predictions\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(dates[-len(residuals):], residuals, label=\"Residual Errors\", color=\"red\", linewidth=2)\n",
    "plt.axhline(y=0, color='black', linestyle='dashed')  # Reference line at 0\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Residual Error\")\n",
    "plt.title(\"Residual Errors Over Time\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Compute MAE\n",
    "mae = mean_absolute_error(y_test_original, predictions)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test_original, predictions))\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.5f}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse:.5f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=30, edgecolor='black', color='red', alpha=0.7)\n",
    "plt.xlabel(\"Residual Error\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Residuals\")\n",
    "plt.axvline(x=0, color='black', linestyle='dashed')  # Reference line at 0\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
