{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from pathlib import Path\n",
    "from darts.models.forecasting.tft_model import TFTModel\n",
    "from darts.utils.model_selection import train_test_split\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sys.path.append('../Helper/')\n",
    "from dataPreprocessing import add_time_features, rank_features_ccf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_exog(df, nonExogCols=['observation_date','fred_PCEPI']):\n",
    "    exog_df= df.drop(nonExogCols, axis=1).copy()\n",
    "    return exog_df.columns,  exog_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_9324\\956064902.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data= pd.read_csv(cwd.parent.parent / 'Data' /'Train'/'train1990s.csv',parse_dates=[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['fred_PCEPI_LOG', 'fred_PCUOMFGOMFG_LOG', 'fred_PCUOMFGOMFG',\n",
       "       'fred_PPIACO', 'fred_PPIACO_LOG', 'fred_APU000074714',\n",
       "       'fred_APU000074714_LOG', 'BrentOil_Open', 'CrudeOilWTI_Open',\n",
       "       'fred_APU000074714_CH1', 'CMO-Historical-Data-Monthly_Total_Index',\n",
       "       'BrentOil_High', 'CMO-Historical-Data-Monthly_Energy',\n",
       "       'CrudeOilWTI_High', 'fred_DCOILWTICO', 'fred_APU000074714_PC1',\n",
       "       'BrentOil_Low', 'fred_PCUOMFGOMFG_PC1', 'fred_PCUOMFGOMFG_CH1',\n",
       "       'fred_PCUOMINOMIN', 'fred_PPIACO_PC1', 'fred_PPIACO_CH1',\n",
       "       'fred_PCUOMINOMIN_LOG', 'CrudeOilWTI_Low', 'fred_APU000074714_CHG',\n",
       "       'fred_GDP', 'CMO-Historical-Data-Monthly_Non_Energy',\n",
       "       'fred_PPIACO_CHG', 'fred_M2SL_CH1',\n",
       "       'food_price_indices_data_f_Food Price Index', 'fred_CSUSHPISA',\n",
       "       'fred_APU000074714_PCH', 'fred_APU000074714_CCA',\n",
       "       'fred_APU000074714_CCH', 'fred_PCUOMFGOMFG_CHG',\n",
       "       'CMO-Historical-Data-Monthly_TSP', 'fred_PCUOMINOMIN_CH1',\n",
       "       'fred_PPIACO_CCA', 'fred_PPIACO_CCH', 'fred_PCUOMFGOMFG_CCH',\n",
       "       'fred_PCUOMFGOMFG_CCA', 'fred_PCUOMFGOMFG_PCH', 'fred_PPIACO_PCH',\n",
       "       'food_price_indices_data_f_Meat', 'fred_M2SL_PC1',\n",
       "       'fred_PCUOMFGOMFG_PCA', 'BrentOil_Price', 'fred_PPIACO_PCA',\n",
       "       'fred_A053RC1Q027SBEA_CCH', 'fred_A053RC1Q027SBEA_CCA',\n",
       "       'fred_MPRIME_LOG', 'CMO-Historical-Data-Monthly_Agriculture',\n",
       "       'CMO-Historical-Data-Monthly_DAP', 'fred_A053RC1Q027SBEA_CHG',\n",
       "       'fred_A053RC1Q027SBEA_PC1', 'fred_CSUSHPISA_LOG',\n",
       "       'fred_A053RC1Q027SBEA_PCH', 'CrudeOilWTI_Price',\n",
       "       'CMO-Historical-Data-Monthly_Metals_minerals', 'fred_GDP_LOG',\n",
       "       'fred_PCUOMINOMIN_PC1', 'Copper_High', 'fred_APU000074714_PCA',\n",
       "       'CMO-Historical-Data-Monthly_Base metals', 'fred_GDP_PC1',\n",
       "       'BCI_BCI', 'CMO-Historical-Data-Monthly_Food', 'fred_TB6MS',\n",
       "       'CMO-Historical-Data-Monthly_Fertilizers', 'fred_EXNOUS_CH1',\n",
       "       'fred_A053RC1Q027SBEA_PCA', 'fred_FEDFUNDS', 'fred_EXNOUS_PC1',\n",
       "       'fred_PCUOMINOMIN_CHG', 'fred_A053RC1Q027SBEA_CH1',\n",
       "       'fred_EXCAUS_LOG', 'fred_BAA10YM', 'Copper_Open', 'fred_GDP_CH1',\n",
       "       'fred_FDHBPIN_CH1',\n",
       "       'CMO-Historical-Data-Monthly_Coal, South African **',\n",
       "       'CMO-Historical-Data-Monthly_Soybean oil',\n",
       "       'food_price_indices_data_f_Dairy', 'fred_EXCAUS',\n",
       "       'CMO-Historical-Data-Monthly_Aluminum',\n",
       "       'CMO-Historical-Data-Monthly_Urea ', 'fred_FDHBFRBN_LOG',\n",
       "       'fred_FDHBFRBN_CH1', 'fred_BAA10YM_CH1', 'fred_DGS10',\n",
       "       'fred_TERMCBPER24NS', 'fred_FYGFGDQ188S_PC1', 'fred_EXUSAL_PC1',\n",
       "       'fred_MPRIME', 'CMO-Historical-Data-Monthly_Other_raw_materials',\n",
       "       'fred_EXNOUS_LOG', 'fred_FDHBPIN_PC1', 'fred_EXUSAL_CH1',\n",
       "       'fred_GFDEGDQ188S_PC1', 'CMO-Historical-Data-Monthly_Platinum',\n",
       "       'food_price_indices_data_f_Oils', 'fred_PSAVERT_LOG',\n",
       "       'CMO-Historical-Data-Monthly_Oils_and_meals', 'fred_GFDEGDQ188S',\n",
       "       'fred_TB3MS', 'fred_IPMINE', 'fred_A053RC1Q027SBEA_LOG',\n",
       "       'fred_EXNOUS_PCA', 'fred_M2SL_LOG',\n",
       "       'CMO-Historical-Data-Monthly_Coal, Australian', 'fred_FYGFGDQ188S',\n",
       "       'fred_GFDEGDQ188S_CH1', 'CMO-Historical-Data-Monthly_Maize',\n",
       "       'fred_FYGFGDQ188S_CH1', 'CMO-Historical-Data-Monthly_Rubber, RSS3',\n",
       "       'CMO-Historical-Data-Monthly_Grains', 'fred_IPMINE_LOG',\n",
       "       'fred_GFDEGDQ188S_LOG', 'fred_EXUSAL_CCA', 'fred_EXUSAL_CCH',\n",
       "       'fred_EXUSAL', 'fred_EXUSAL_CHG', 'fred_EXUSAL_PCH', 'fred_EXNOUS',\n",
       "       'fred_EXNOUS_PCH', 'Copper_Low', 'fred_GDP_PCA', 'fred_EXUSAL_LOG',\n",
       "       'fred_EXNOUS_CCH', 'fred_EXNOUS_CCA',\n",
       "       'food_price_indices_data_f_Cereals', 'fred_GDP_PCH',\n",
       "       'fred_FDHBFRBN_PCA', 'fred_GDP_CCH', 'fred_GDP_CCA',\n",
       "       'fred_EXCAUS_PCA', 'CMO-Historical-Data-Monthly_Raw_materials',\n",
       "       'fred_BAA10YM_CHG', 'fred_FYGFDPUN_CH1', 'BrentOil_Change %',\n",
       "       'fred_FYGFDPUN_PC1', 'fred_FDHBPIN_LOG', 'fred_EXNOUS_CHG',\n",
       "       'fred_GDP_CHG', 'fred_FYGFGDQ188S_LOG', 'CBOEVIX_Open',\n",
       "       'fred_EXCAUS_PC1', 'fred_EXCAUS_PCH', 'fred_EXCAUS_CH1',\n",
       "       'fred_EXSFUS_LOG', 'fred_FDHBFRBN_PCH', 'fred_BAA10YM_LOG',\n",
       "       'fred_EXUSAL_PCA', 'fred_EXCAUS_CCH', 'fred_EXCAUS_CCA',\n",
       "       'CMO-Historical-Data-Monthly_Iron ore, cfr spot',\n",
       "       'CrudeOilWTI_Change %', 'fred_GFDEGDQ188S_CCH',\n",
       "       'fred_GFDEGDQ188S_CCA', 'fred_BAA10YM_PC1', 'fred_GFDEGDQ188S_PCH',\n",
       "       'fred_PSAVERT', 'fred_EXSLUS',\n",
       "       'CMO-Historical-Data-Monthly_Other_foods', 'fred_FDHBFRBN_CCH',\n",
       "       'fred_FDHBFRBN_CCA', 'fred_PSOYBUSDM', 'fred_EXCAUS_CHG',\n",
       "       'fred_EXSFUS_PC1', 'fred_EXSDUS_PCA', 'fred_EXINUS_CH1',\n",
       "       'fred_PNGASEUUSDM_LOG', 'fred_GFDEGDQ188S_CHG',\n",
       "       'fred_GFDEGDQ188S_PCA', 'BalticDryIndex_Open',\n",
       "       'CMO-Historical-Data-Monthly_Palm oil',\n",
       "       'CMO-Historical-Data-Monthly_Nickel', 'fred_FYGFGDQ188S_CCH',\n",
       "       'fred_FYGFGDQ188S_CCA', 'fred_EXSDUS_PCH', 'fred_FYGFGDQ188S_PCH',\n",
       "       'fred_EXSDUS_CCH', 'fred_EXSDUS_CCA',\n",
       "       'CMO-Historical-Data-Monthly_Tin', 'SP500_Open', 'fred_AHETPI_LOG',\n",
       "       'fred_EXUSNZ_LOG', 'CMO-Historical-Data-Monthly_Beverages',\n",
       "       'fred_EXSIUS_PC1', 'fred_A053RC1Q027SBEA', 'fred_M2SL_CHG',\n",
       "       'fred_FYGFGDQ188S_PCA', 'CMO-Historical-Data-Monthly_Coconut oil',\n",
       "       'fred_FYGFGDQ188S_CHG', 'fred_EXUSNZ',\n",
       "       'CMO-Historical-Data-Monthly_Logs, Cameroon',\n",
       "       'CMO-Historical-Data-Monthly_Sugar, EU', 'fred_FDHBPIN_CHG',\n",
       "       'fred_EXSDUS_LOG', 'fred_PSAVERT_PC1', 'BalticDryIndex_High',\n",
       "       'fred_EXSDUS_CHG', 'fred_EXSIUS_CH1', 'SP500_High',\n",
       "       'fred_EXSLUS_LOG', 'fred_FDHBPIN_PCA', 'fred_EXSDUS',\n",
       "       'CMO-Historical-Data-Monthly_Wheat, US HRW', 'fred_BAA10YM_PCH',\n",
       "       'fred_BAA10YM_CCA', 'fred_BAA10YM_CCH', 'fred_FDHBPIN_PCH',\n",
       "       'fred_TB3MS_PC1', 'fred_FDHBPIN_CCH', 'fred_FDHBPIN_CCA',\n",
       "       'fred_M2SL', 'Copper_Price', 'BalticDryIndex_Change %',\n",
       "       'fred_BAAFFM', 'CMO-Historical-Data-Monthly_Cocoa',\n",
       "       'fred_TB6MS_CH1', 'fred_EXUSUK_PC1', 'NASDAQComposite_Open',\n",
       "       'fred_BAAFFM_CHG', 'CMO-Historical-Data-Monthly_Cotton, A Index',\n",
       "       'CBOEVIX_Low', 'fred_EXSDUS_CH1', 'fred_FYGFDPUN_PCA',\n",
       "       'fred_PNGASEUUSDM', 'fred_FEDFUNDS_PCH', 'fred_EXKOUS_PC1',\n",
       "       'fred_EXSFUS_CCH', 'fred_EXSFUS_CCA', 'fred_EXTAUS',\n",
       "       'fred_EXMAUS_CH1', 'fred_EXTAUS_LOG', 'fred_EXSDUS_PC1',\n",
       "       'fred_FYGFDPUN_CHG', 'BalticDryIndex_Low',\n",
       "       'CMO-Historical-Data-Monthly_Groundnut oil **',\n",
       "       'fred_FYGFDPUN_PCH', 'fred_TB6MS_CHG', 'NASDAQComposite_Price',\n",
       "       'CMO-Historical-Data-Monthly_Beef **',\n",
       "       'CMO-Historical-Data-Monthly_Lead', 'fred_PSAVERT_CCA',\n",
       "       'fred_PSAVERT_CCH', 'fred_EXSFUS_PCA', 'fred_FYGFDPUN_CCH',\n",
       "       'fred_FYGFDPUN_CCA', 'NASDAQComposite_Low', 'fred_EXUSNZ_CHG',\n",
       "       'Silver_Price', 'CBOEVIX_Change %', 'fred_EXUSNZ_CCH',\n",
       "       'fred_EXUSNZ_CCA', 'fred_EXSIUS',\n",
       "       'CMO-Historical-Data-Monthly_Potassium chloride **',\n",
       "       'fred_EXUSNZ_PCH', 'fred_EXINUS',\n",
       "       'CMO-Historical-Data-Monthly_Zinc',\n",
       "       'CMO-Historical-Data-Monthly_Tea, avg 3 auctions',\n",
       "       'fred_TB3MS_CH1', 'BalticDryIndex_Price', 'fred_MPRIME_CCA',\n",
       "       'fred_MPRIME_CCH', 'CBOEVIX_High', 'fred_EXINUS_CHG',\n",
       "       'fred_MPRIME_PCH', 'fred_BAAFFM_PCH', 'fred_TB3MS_CHG',\n",
       "       'fred_FYGFDPUN_LOG', 'fred_BAAFFM_PC1', 'fred_T10Y3MM_PCH',\n",
       "       'fred_MPRIME_PCA', 'fred_EXINUS_LOG', 'fred_PNGASEUUSDM_CHG',\n",
       "       'fred_EXSIUS_PCH', 'CBOEVIX_Price', 'fred_T3MFFM_CHG',\n",
       "       'fred_PSAVERT_PCH', 'fred_EXKOUS_CCA', 'fred_EXKOUS_CCH',\n",
       "       'SP500_Price', 'fred_EXKOUS_LOG', 'fred_EXKOUS',\n",
       "       'CMO-Historical-Data-Monthly_Soybean meal', 'SP500_Change %',\n",
       "       'fred_EXKOUS_CHG', 'fred_EXJPUS_PC1', 'fred_IPMINE_CHG',\n",
       "       'fred_EXKOUS_PCH', 'fred_IPMINE_CCA', 'fred_IPMINE_CCH',\n",
       "       'fred_EXSIUS_CHG', 'fred_EXSLUS_PC1',\n",
       "       'CMO-Historical-Data-Monthly_Tea, Mombasa', 'fred_FEDFUNDS_CHG',\n",
       "       'fred_TDSP_CCH', 'fred_TDSP_CCA', 'fred_IPMINE_PCH',\n",
       "       'fred_EXTAUS_PCA', 'fred_MPRIME_CHG', 'fred_TDSP_PCH',\n",
       "       'fred_BAA10YM_PCA', 'Silver_Change %', 'fred_EXMAUS_LOG',\n",
       "       'fred_APU000072610_PCA', 'SP500_Low', 'CrudeOilWTI_Vol.',\n",
       "       'fred_BAAFFM_PCA', 'Gold_Price', 'fred_DTCOLNVHFNM_CH1',\n",
       "       'fred_T6MFFM_PC1', 'Copper_Change %', 'fred_PNGASEUUSDM_PCH',\n",
       "       'fred_T10Y3MM_PC1', 'fred_UMCSENT_PCA', 'fred_PSAVERT_CHG',\n",
       "       'fred_TDSP_CHG', 'fred_TDSP_PCA', 'NASDAQComposite_Change %',\n",
       "       'fred_EXMAUS', 'fred_EXSLUS_CH1',\n",
       "       'CMO-Historical-Data-Monthly_Rice, Thai 5% ',\n",
       "       'fred_PNGASEUUSDM_PCA', 'fred_IPMINE_PCA',\n",
       "       'CMO-Historical-Data-Monthly_Tea, Colombo',\n",
       "       'US_Policy_Uncertainty_Data_News_Based_Policy_Uncert_Index_x',\n",
       "       'US_Policy_Uncertainty_Data_News_Based_Policy_Uncert_Index_y',\n",
       "       'fred_PNGASEUUSDM_CCH', 'fred_PNGASEUUSDM_CCA', 'Gold_Change %',\n",
       "       'fred_FEDFUNDS_PCA', 'US_Policy_Uncertainty_Data_CPI_disagreement',\n",
       "       'fred_TB1YR_PCA', 'fred_PSAVERT_PCA', 'fred_EXSLUS_CHG',\n",
       "       'US_Policy_Uncertainty_Data_Three_Component_Index',\n",
       "       'fred_EXSLUS_PCA', 'BrentOil_Vol.',\n",
       "       'CMO-Historical-Data-Monthly_Rice, Thai A.1', 'fred_EXMAUS_CCA',\n",
       "       'fred_EXMAUS_CCH', 'fred_UMCSENT_CCH', 'fred_UMCSENT_CCA',\n",
       "       'fred_UMCSENT_PCH', 'fred_EXSLUS_CCA', 'fred_EXSLUS_CCH',\n",
       "       'fred_EXSLUS_PCH', 'fred_T10Y2YM_PC1', 'fred_T1YFFM_PC1',\n",
       "       'fred_FEDFUNDS_PC1', 'fred_FDHBFIN', 'fred_FDHBPIN',\n",
       "       'fred_FYGFDPUN', 'fred_AHETPI', 'fred_AAAFFM_PCA'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 16:23:21,452 - INFO - Added time features: year, month, quarter. DataFrame shape: (408, 363)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fred_AAAFFM_PCA</th>\n",
       "      <th>fred_AHETPI</th>\n",
       "      <th>fred_AHETPI_LOG</th>\n",
       "      <th>fred_APU000072610_PCA</th>\n",
       "      <th>fred_APU000074714</th>\n",
       "      <th>fred_APU000074714_CCA</th>\n",
       "      <th>fred_APU000074714_CCH</th>\n",
       "      <th>fred_APU000074714_CH1</th>\n",
       "      <th>fred_APU000074714_CHG</th>\n",
       "      <th>fred_APU000074714_LOG</th>\n",
       "      <th>...</th>\n",
       "      <th>CMO-Historical-Data-Monthly_Raw_materials</th>\n",
       "      <th>CMO-Historical-Data-Monthly_Other_raw_materials</th>\n",
       "      <th>CMO-Historical-Data-Monthly_Fertilizers</th>\n",
       "      <th>CMO-Historical-Data-Monthly_Metals_minerals</th>\n",
       "      <th>CMO-Historical-Data-Monthly_Base metals</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>observation_date</th>\n",
       "      <th>fred_PCEPI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.049707</td>\n",
       "      <td>-1.463331</td>\n",
       "      <td>-1.747231</td>\n",
       "      <td>-0.190786</td>\n",
       "      <td>-1.209954</td>\n",
       "      <td>1.000346</td>\n",
       "      <td>1.000347</td>\n",
       "      <td>0.092070</td>\n",
       "      <td>0.375009</td>\n",
       "      <td>-1.440204</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.967394</td>\n",
       "      <td>-0.671459</td>\n",
       "      <td>-0.892430</td>\n",
       "      <td>-0.869017</td>\n",
       "      <td>-0.854851</td>\n",
       "      <td>-1.681836</td>\n",
       "      <td>-1.593255</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>58.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.049707</td>\n",
       "      <td>-1.453544</td>\n",
       "      <td>-1.730319</td>\n",
       "      <td>-0.190786</td>\n",
       "      <td>-1.215180</td>\n",
       "      <td>-0.133277</td>\n",
       "      <td>-0.133277</td>\n",
       "      <td>0.066318</td>\n",
       "      <td>-0.070949</td>\n",
       "      <td>-1.450888</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.908690</td>\n",
       "      <td>-0.630489</td>\n",
       "      <td>-0.885012</td>\n",
       "      <td>-0.894980</td>\n",
       "      <td>-0.886989</td>\n",
       "      <td>-1.681836</td>\n",
       "      <td>-1.303572</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>1990-02-01</td>\n",
       "      <td>58.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.049707</td>\n",
       "      <td>-1.445715</td>\n",
       "      <td>-1.716836</td>\n",
       "      <td>-0.190786</td>\n",
       "      <td>-1.229815</td>\n",
       "      <td>-0.283772</td>\n",
       "      <td>-0.283772</td>\n",
       "      <td>0.010852</td>\n",
       "      <td>-0.130854</td>\n",
       "      <td>-1.481073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.948880</td>\n",
       "      <td>-0.621923</td>\n",
       "      <td>-0.873448</td>\n",
       "      <td>-0.751645</td>\n",
       "      <td>-0.709559</td>\n",
       "      <td>-1.681836</td>\n",
       "      <td>-1.013890</td>\n",
       "      <td>-1.341641</td>\n",
       "      <td>1990-03-01</td>\n",
       "      <td>59.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.049707</td>\n",
       "      <td>-1.443758</td>\n",
       "      <td>-1.713508</td>\n",
       "      <td>0.332123</td>\n",
       "      <td>-1.207863</td>\n",
       "      <td>0.297350</td>\n",
       "      <td>0.297350</td>\n",
       "      <td>-0.195167</td>\n",
       "      <td>0.102109</td>\n",
       "      <td>-1.435939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.964695</td>\n",
       "      <td>-0.570855</td>\n",
       "      <td>-0.861601</td>\n",
       "      <td>-0.763668</td>\n",
       "      <td>-0.724442</td>\n",
       "      <td>-1.681836</td>\n",
       "      <td>-0.724207</td>\n",
       "      <td>-0.447214</td>\n",
       "      <td>1990-04-01</td>\n",
       "      <td>59.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.049707</td>\n",
       "      <td>-1.435928</td>\n",
       "      <td>-1.700094</td>\n",
       "      <td>-0.190786</td>\n",
       "      <td>-1.190094</td>\n",
       "      <td>0.225933</td>\n",
       "      <td>0.225934</td>\n",
       "      <td>-0.268462</td>\n",
       "      <td>0.075485</td>\n",
       "      <td>-1.400068</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.068686</td>\n",
       "      <td>-0.510472</td>\n",
       "      <td>-0.872081</td>\n",
       "      <td>-0.751331</td>\n",
       "      <td>-0.709170</td>\n",
       "      <td>-1.681836</td>\n",
       "      <td>-0.434524</td>\n",
       "      <td>-0.447214</td>\n",
       "      <td>1990-05-01</td>\n",
       "      <td>59.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>-0.049707</td>\n",
       "      <td>2.263392</td>\n",
       "      <td>1.868821</td>\n",
       "      <td>0.051043</td>\n",
       "      <td>1.834970</td>\n",
       "      <td>0.943655</td>\n",
       "      <td>0.943654</td>\n",
       "      <td>-0.442786</td>\n",
       "      <td>1.446641</td>\n",
       "      <td>1.522424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182657</td>\n",
       "      <td>0.586118</td>\n",
       "      <td>1.480132</td>\n",
       "      <td>1.103935</td>\n",
       "      <td>1.166361</td>\n",
       "      <td>1.681836</td>\n",
       "      <td>0.434524</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>2023-08-01</td>\n",
       "      <td>120.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>-0.049707</td>\n",
       "      <td>2.282965</td>\n",
       "      <td>1.880503</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>1.869464</td>\n",
       "      <td>0.091534</td>\n",
       "      <td>0.091535</td>\n",
       "      <td>0.058394</td>\n",
       "      <td>0.181982</td>\n",
       "      <td>1.540881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215823</td>\n",
       "      <td>0.744146</td>\n",
       "      <td>1.479049</td>\n",
       "      <td>1.155377</td>\n",
       "      <td>1.171625</td>\n",
       "      <td>1.681836</td>\n",
       "      <td>0.724207</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>2023-09-01</td>\n",
       "      <td>121.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>-0.049707</td>\n",
       "      <td>2.304495</td>\n",
       "      <td>1.893273</td>\n",
       "      <td>-0.624800</td>\n",
       "      <td>1.654135</td>\n",
       "      <td>-0.959690</td>\n",
       "      <td>-0.959691</td>\n",
       "      <td>-0.617110</td>\n",
       "      <td>-1.408826</td>\n",
       "      <td>1.423073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176813</td>\n",
       "      <td>0.752859</td>\n",
       "      <td>1.559479</td>\n",
       "      <td>1.064067</td>\n",
       "      <td>1.069487</td>\n",
       "      <td>1.681836</td>\n",
       "      <td>1.013890</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>2023-10-01</td>\n",
       "      <td>121.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.049707</td>\n",
       "      <td>2.326026</td>\n",
       "      <td>1.906008</td>\n",
       "      <td>-0.417377</td>\n",
       "      <td>1.359364</td>\n",
       "      <td>-1.378718</td>\n",
       "      <td>-1.378718</td>\n",
       "      <td>-0.852843</td>\n",
       "      <td>-1.914689</td>\n",
       "      <td>1.250958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190947</td>\n",
       "      <td>0.710049</td>\n",
       "      <td>1.472092</td>\n",
       "      <td>1.155434</td>\n",
       "      <td>1.117019</td>\n",
       "      <td>1.681836</td>\n",
       "      <td>1.303572</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>2023-11-01</td>\n",
       "      <td>121.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>20.174169</td>\n",
       "      <td>2.345599</td>\n",
       "      <td>1.917554</td>\n",
       "      <td>0.052530</td>\n",
       "      <td>1.138808</td>\n",
       "      <td>-1.116356</td>\n",
       "      <td>-1.116356</td>\n",
       "      <td>-0.286291</td>\n",
       "      <td>-1.442106</td>\n",
       "      <td>1.112848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238395</td>\n",
       "      <td>0.690065</td>\n",
       "      <td>0.757540</td>\n",
       "      <td>1.196903</td>\n",
       "      <td>1.135948</td>\n",
       "      <td>1.681836</td>\n",
       "      <td>1.593255</td>\n",
       "      <td>1.341641</td>\n",
       "      <td>2023-12-01</td>\n",
       "      <td>121.602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408 rows × 363 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fred_AAAFFM_PCA  fred_AHETPI  fred_AHETPI_LOG  fred_APU000072610_PCA  \\\n",
       "0          -0.049707    -1.463331        -1.747231              -0.190786   \n",
       "1          -0.049707    -1.453544        -1.730319              -0.190786   \n",
       "2          -0.049707    -1.445715        -1.716836              -0.190786   \n",
       "3          -0.049707    -1.443758        -1.713508               0.332123   \n",
       "4          -0.049707    -1.435928        -1.700094              -0.190786   \n",
       "..               ...          ...              ...                    ...   \n",
       "403        -0.049707     2.263392         1.868821               0.051043   \n",
       "404        -0.049707     2.282965         1.880503               0.049574   \n",
       "405        -0.049707     2.304495         1.893273              -0.624800   \n",
       "406        -0.049707     2.326026         1.906008              -0.417377   \n",
       "407        20.174169     2.345599         1.917554               0.052530   \n",
       "\n",
       "     fred_APU000074714  fred_APU000074714_CCA  fred_APU000074714_CCH  \\\n",
       "0            -1.209954               1.000346               1.000347   \n",
       "1            -1.215180              -0.133277              -0.133277   \n",
       "2            -1.229815              -0.283772              -0.283772   \n",
       "3            -1.207863               0.297350               0.297350   \n",
       "4            -1.190094               0.225933               0.225934   \n",
       "..                 ...                    ...                    ...   \n",
       "403           1.834970               0.943655               0.943654   \n",
       "404           1.869464               0.091534               0.091535   \n",
       "405           1.654135              -0.959690              -0.959691   \n",
       "406           1.359364              -1.378718              -1.378718   \n",
       "407           1.138808              -1.116356              -1.116356   \n",
       "\n",
       "     fred_APU000074714_CH1  fred_APU000074714_CHG  fred_APU000074714_LOG  ...  \\\n",
       "0                 0.092070               0.375009              -1.440204  ...   \n",
       "1                 0.066318              -0.070949              -1.450888  ...   \n",
       "2                 0.010852              -0.130854              -1.481073  ...   \n",
       "3                -0.195167               0.102109              -1.435939  ...   \n",
       "4                -0.268462               0.075485              -1.400068  ...   \n",
       "..                     ...                    ...                    ...  ...   \n",
       "403              -0.442786               1.446641               1.522424  ...   \n",
       "404               0.058394               0.181982               1.540881  ...   \n",
       "405              -0.617110              -1.408826               1.423073  ...   \n",
       "406              -0.852843              -1.914689               1.250958  ...   \n",
       "407              -0.286291              -1.442106               1.112848  ...   \n",
       "\n",
       "     CMO-Historical-Data-Monthly_Raw_materials  \\\n",
       "0                                    -0.967394   \n",
       "1                                    -0.908690   \n",
       "2                                    -0.948880   \n",
       "3                                    -0.964695   \n",
       "4                                    -1.068686   \n",
       "..                                         ...   \n",
       "403                                   0.182657   \n",
       "404                                   0.215823   \n",
       "405                                   0.176813   \n",
       "406                                   0.190947   \n",
       "407                                   0.238395   \n",
       "\n",
       "     CMO-Historical-Data-Monthly_Other_raw_materials  \\\n",
       "0                                          -0.671459   \n",
       "1                                          -0.630489   \n",
       "2                                          -0.621923   \n",
       "3                                          -0.570855   \n",
       "4                                          -0.510472   \n",
       "..                                               ...   \n",
       "403                                         0.586118   \n",
       "404                                         0.744146   \n",
       "405                                         0.752859   \n",
       "406                                         0.710049   \n",
       "407                                         0.690065   \n",
       "\n",
       "     CMO-Historical-Data-Monthly_Fertilizers  \\\n",
       "0                                  -0.892430   \n",
       "1                                  -0.885012   \n",
       "2                                  -0.873448   \n",
       "3                                  -0.861601   \n",
       "4                                  -0.872081   \n",
       "..                                       ...   \n",
       "403                                 1.480132   \n",
       "404                                 1.479049   \n",
       "405                                 1.559479   \n",
       "406                                 1.472092   \n",
       "407                                 0.757540   \n",
       "\n",
       "     CMO-Historical-Data-Monthly_Metals_minerals  \\\n",
       "0                                      -0.869017   \n",
       "1                                      -0.894980   \n",
       "2                                      -0.751645   \n",
       "3                                      -0.763668   \n",
       "4                                      -0.751331   \n",
       "..                                           ...   \n",
       "403                                     1.103935   \n",
       "404                                     1.155377   \n",
       "405                                     1.064067   \n",
       "406                                     1.155434   \n",
       "407                                     1.196903   \n",
       "\n",
       "     CMO-Historical-Data-Monthly_Base metals      year     month   quarter  \\\n",
       "0                                  -0.854851 -1.681836 -1.593255 -1.341641   \n",
       "1                                  -0.886989 -1.681836 -1.303572 -1.341641   \n",
       "2                                  -0.709559 -1.681836 -1.013890 -1.341641   \n",
       "3                                  -0.724442 -1.681836 -0.724207 -0.447214   \n",
       "4                                  -0.709170 -1.681836 -0.434524 -0.447214   \n",
       "..                                       ...       ...       ...       ...   \n",
       "403                                 1.166361  1.681836  0.434524  0.447214   \n",
       "404                                 1.171625  1.681836  0.724207  0.447214   \n",
       "405                                 1.069487  1.681836  1.013890  1.341641   \n",
       "406                                 1.117019  1.681836  1.303572  1.341641   \n",
       "407                                 1.135948  1.681836  1.593255  1.341641   \n",
       "\n",
       "     observation_date  fred_PCEPI  \n",
       "0          1990-01-01      58.553  \n",
       "1          1990-02-01      58.811  \n",
       "2          1990-03-01      59.033  \n",
       "3          1990-04-01      59.157  \n",
       "4          1990-05-01      59.290  \n",
       "..                ...         ...  \n",
       "403        2023-08-01     120.965  \n",
       "404        2023-09-01     121.387  \n",
       "405        2023-10-01     121.421  \n",
       "406        2023-11-01     121.415  \n",
       "407        2023-12-01     121.602  \n",
       "\n",
       "[408 rows x 363 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cwd=Path.cwd()\n",
    "data= pd.read_csv(cwd.parent.parent / 'Data' /'Train'/'train1990s.csv',parse_dates=[0])\n",
    "ranked_cols= rank_features_ccf(data.drop('observation_date',axis=1))\n",
    "display(ranked_cols)\n",
    "add_time_features(data)\n",
    "\n",
    "cols, array=numpy_exog(data)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaled_array=scaler.fit_transform(array)\n",
    "\n",
    "scaledDf= pd.DataFrame(scaled_array,columns=cols)\n",
    "\n",
    "scaledDf['observation_date']=data['observation_date']\n",
    "scaledDf['fred_PCEPI']=data['fred_PCEPI']\n",
    "display(scaledDf)\n",
    "\n",
    "# future_covariates= data[[\"observation_date\",\"year\",\"month\", \"quarter\"]]\n",
    "# past_covariates= data.drop([\"fred_PCEPI\",\"year\",\"month\", \"quarter\"],axis=1)\n",
    "# target= data[[\"observation_date\",\"fred_PCEPI\"]]\n",
    "\n",
    "# future_covariates_series= TimeSeries.from_dataframe(future_covariates,time_col=\"observation_date\",freq=\"MS\")\n",
    "# past_covariates_series= TimeSeries.from_dataframe(past_covariates,time_col=\"observation_date\",freq=\"MS\")\n",
    "# target_series= TimeSeries.from_dataframe(target,time_col=\"observation_date\",freq=\"MS\")\n",
    "\n",
    "# X_train_future,X_valid_future=train_test_split(future_covariates_series,test_size=12,axis=1,input_size=12,horizon=12,vertical_split_type='model-aware')\n",
    "# X_train,X_valid=train_test_split(past_covariates_series,test_size=12,axis=1,input_size=12,horizon=12,vertical_split_type='model-aware')\n",
    "# y_train,y_valid=train_test_split(target_series,test_size=12,axis=1,input_size=12,horizon=12,vertical_split_type='model-aware')\n",
    "\n",
    "# X_train,X_valid=train_test_split(series,test_size=12,axis=1,input_size=12,horizon=12,vertical_split_type='model-aware')\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid=train_test_split(data.drop(\"fred_PCEPI\",axis=1), data[\"fred_PCEPI\"],shuffle=False, test_size=12)\n",
    "\n",
    "# y_train= TimeSeries.from_dataframe(pd.concat((X_train[\"observation_date\"],y_train), axis=1),time_col='observation_date',freq='MS')\n",
    "# y_valid= TimeSeries.from_dataframe(pd.concat((X_valid[\"observation_date\"],y_valid), axis=1),time_col='observation_date',freq='MS')\n",
    "\n",
    "# display(pd.concat((X_train[[\"year\",\"month\", \"quarter\"]],X_valid[[\"year\",\"month\", \"quarter\"]])))\n",
    "# display(X_valid)\n",
    "\n",
    "# future_covariates=TimeSeries.from_dataframe(pd.concat((X_train['observation_date'],X_train[[\"year\",\"month\", \"quarter\"]]),axis=1),time_col='observation_date',freq='MS')\n",
    "# X_valid_future=TimeSeries.from_dataframe(pd.concat((X_valid['observation_date'],X_valid[[\"year\",\"month\", \"quarter\"]]),axis=1),time_col='observation_date',freq='MS')\n",
    "\n",
    "# X_train=TimeSeries.from_dataframe(X_train.drop([\"year\",\"month\", \"quarter\"],axis=1) ,time_col='observation_date',freq='MS')\n",
    "# X_valid=TimeSeries.from_dataframe(X_valid.drop([\"year\",\"month\", \"quarter\"],axis=1),time_col='observation_date',freq='MS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cwd=Path.cwd()\n",
    "data= pd.read_csv(cwd.parent.parent / 'Data' /'Train'/'train1990s.csv',parse_dates=[0])\n",
    "ranked_cols= rank_features_ccf(data.drop('observation_date',axis=1))\n",
    "display(ranked_cols)\n",
    "add_time_features(data)\n",
    "\n",
    "cols, array=numpy_exog(data)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaled_array=scaler.fit_transform(array)\n",
    "\n",
    "scaledDf= pd.DataFrame(scaled_array,columns=cols)\n",
    "\n",
    "scaledDf['observation_date']=data['observation_date']\n",
    "scaledDf['fred_PCEPI']=data['fred_PCEPI']\n",
    "display(scaledDf)\n",
    "\n",
    "# future_covariates= data[[\"observation_date\",\"year\",\"month\", \"quarter\"]]\n",
    "# past_covariates= data.drop([\"fred_PCEPI\",\"year\",\"month\", \"quarter\"],axis=1)\n",
    "# target= data[[\"observation_date\",\"fred_PCEPI\"]]\n",
    "\n",
    "# future_covariates_series= TimeSeries.from_dataframe(future_covariates,time_col=\"observation_date\",freq=\"MS\")\n",
    "# past_covariates_series= TimeSeries.from_dataframe(past_covariates,time_col=\"observation_date\",freq=\"MS\")\n",
    "# target_series= TimeSeries.from_dataframe(target,time_col=\"observation_date\",freq=\"MS\")\n",
    "\n",
    "# X_train_future,X_valid_future=train_test_split(future_covariates_series,test_size=12,axis=1,input_size=12,horizon=12,vertical_split_type='model-aware')\n",
    "# X_train,X_valid=train_test_split(past_covariates_series,test_size=12,axis=1,input_size=12,horizon=12,vertical_split_type='model-aware')\n",
    "# y_train,y_valid=train_test_split(target_series,test_size=12,axis=1,input_size=12,horizon=12,vertical_split_type='model-aware')\n",
    "\n",
    "# X_train,X_valid=train_test_split(series,test_size=12,axis=1,input_size=12,horizon=12,vertical_split_type='model-aware')\n",
    "\n",
    "\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid=train_test_split(data.drop(\"fred_PCEPI\",axis=1), data[\"fred_PCEPI\"],shuffle=False, test_size=12)\n",
    "\n",
    "# y_train= TimeSeries.from_dataframe(pd.concat((X_train[\"observation_date\"],y_train), axis=1),time_col='observation_date',freq='MS')\n",
    "# y_valid= TimeSeries.from_dataframe(pd.concat((X_valid[\"observation_date\"],y_valid), axis=1),time_col='observation_date',freq='MS')\n",
    "\n",
    "# display(pd.concat((X_train[[\"year\",\"month\", \"quarter\"]],X_valid[[\"year\",\"month\", \"quarter\"]])))\n",
    "# display(X_valid)\n",
    "\n",
    "# future_covariates=TimeSeries.from_dataframe(pd.concat((X_train['observation_date'],X_train[[\"year\",\"month\", \"quarter\"]]),axis=1),time_col='observation_date',freq='MS')\n",
    "# X_valid_future=TimeSeries.from_dataframe(pd.concat((X_valid['observation_date'],X_valid[[\"year\",\"month\", \"quarter\"]]),axis=1),time_col='observation_date',freq='MS')\n",
    "\n",
    "# X_train=TimeSeries.from_dataframe(X_train.drop([\"year\",\"month\", \"quarter\"],axis=1) ,time_col='observation_date',freq='MS')\n",
    "# X_valid=TimeSeries.from_dataframe(X_valid.drop([\"year\",\"month\", \"quarter\"],axis=1),time_col='observation_date',freq='MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:55:25,141 - INFO - Train dataset contains 362 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:55:25,434 - INFO - Time series values are 64-bits; casting model to float64.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                              | Type                             | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0      | train\n",
      "1  | val_metrics                       | MetricCollection                 | 0      | train\n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0      | train\n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 0      | train\n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 252 K  | train\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 1.8 K  | train\n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 1.1 K  | train\n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 1.1 K  | train\n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 1.1 K  | train\n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 1.1 K  | train\n",
      "10 | lstm_encoder                      | LSTM                             | 2.2 K  | train\n",
      "11 | lstm_decoder                      | LSTM                             | 2.2 K  | train\n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 576    | train\n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 1.4 K  | train\n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 676    | train\n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 576    | train\n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 1.1 K  | train\n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 576    | train\n",
      "18 | output_layer                      | Linear                           | 289    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "267 K     Trainable params\n",
      "0         Non-trainable params\n",
      "267 K     Total params\n",
      "1.071     Total estimated model params size (MB)\n",
      "5615      Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebfecb005c7243f39fb358ebf0c3539a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    595\u001b[0m     ckpt_path,\n\u001b[0;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    598\u001b[0m )\n\u001b[1;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[1;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\core\\module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1300\u001b[0m \n\u001b[0;32m   1301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1302\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\core\\optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:493\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    490\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    491\u001b[0m             )\n\u001b[1;32m--> 493\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 223\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:140\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\loops\\optimization\\automatic.py:241\u001b[0m, in \u001b[0;36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[1;34m(loss)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward_fn\u001b[39m(loss: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 241\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[1;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:213\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[1;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    211\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[1;32m--> 213\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpost_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\plugins\\precision\\precision.py:73\u001b[0m, in \u001b[0;36mPrecision.backward\u001b[1;34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\core\\module.py:1097\u001b[0m, in \u001b[0;36mLightningModule.backward\u001b[1;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1097\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m TFTModel(input_chunk_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m,output_chunk_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m,hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,pl_trainer_kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m      2\u001b[0m                                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccelerator\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m                                                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevices\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      4\u001b[0m                                                      })\n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpast_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfuture_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train_future\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\darts\\utils\\torch.py:80\u001b[0m, in \u001b[0;36mrandom_method.<locals>.decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fork_rng():\n\u001b[0;32m     79\u001b[0m     manual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_instance\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39mMAX_TORCH_SEED_VALUE))\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecorated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\darts\\models\\forecasting\\torch_forecasting_model.py:842\u001b[0m, in \u001b[0;36mTorchForecastingModel.fit\u001b[1;34m(self, series, past_covariates, future_covariates, val_series, val_past_covariates, val_future_covariates, trainer, verbose, epochs, max_samples_per_ts, dataloader_kwargs, sample_weight, val_sample_weight)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# call super fit only if user is actually fitting the model\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    838\u001b[0m     series\u001b[38;5;241m=\u001b[39mseq2series(series),\n\u001b[0;32m    839\u001b[0m     past_covariates\u001b[38;5;241m=\u001b[39mseq2series(past_covariates),\n\u001b[0;32m    840\u001b[0m     future_covariates\u001b[38;5;241m=\u001b[39mseq2series(future_covariates),\n\u001b[0;32m    841\u001b[0m )\n\u001b[1;32m--> 842\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_from_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\darts\\utils\\torch.py:80\u001b[0m, in \u001b[0;36mrandom_method.<locals>.decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fork_rng():\n\u001b[0;32m     79\u001b[0m     manual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_instance\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39mMAX_TORCH_SEED_VALUE))\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecorated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\darts\\models\\forecasting\\torch_forecasting_model.py:1022\u001b[0m, in \u001b[0;36mTorchForecastingModel.fit_from_dataset\u001b[1;34m(self, train_dataset, val_dataset, trainer, verbose, epochs, dataloader_kwargs)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;129m@random_method\u001b[39m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_from_dataset\u001b[39m(\n\u001b[0;32m    971\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    977\u001b[0m     dataloader_kwargs: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    978\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorchForecastingModel\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    979\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;124;03m    Train the model with a specific :class:`darts.utils.data.TrainingDataset` instance.\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;124;03m    These datasets implement a PyTorch ``Dataset``, and specify how the target and covariates are sliced\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;124;03m        Fitted model.\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1022\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_for_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataloader_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\darts\\models\\forecasting\\torch_forecasting_model.py:1211\u001b[0m, in \u001b[0;36mTorchForecastingModel._train\u001b[1;34m(self, trainer, model, train_loader, val_loader)\u001b[0m\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_training:\n\u001b[1;32m-> 1211\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m trainer\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kevin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:65\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[0;32m     64\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[1;32m---> 65\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m     68\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "model = TFTModel(input_chunk_length=12,output_chunk_length=12,hidden_size=16,batch_size=256,pl_trainer_kwargs={\n",
    "                                                     \"accelerator\":\"gpu\",\n",
    "                                                     \"devices\": -1,\n",
    "                                                     })\n",
    "\n",
    "model.fit(y_train,past_covariates=X_train,future_covariates=X_train_future, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darts_make_prediction_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 15:43:49,054 - WARNING - `predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ce272d18ae4fb58fb7157fc6f3a089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1f1f1f;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;TimeSeries (DataArray) (observation_date: 12, component: 1, sample: 1)&gt; Size: 96B\n",
       "array([[[1.14841955]],\n",
       "\n",
       "       [[2.07714733]],\n",
       "\n",
       "       [[1.27757226]],\n",
       "\n",
       "       [[0.96648556]],\n",
       "\n",
       "       [[0.42033161]],\n",
       "\n",
       "       [[2.33076042]],\n",
       "\n",
       "       [[1.19695445]],\n",
       "\n",
       "       [[2.07689132]],\n",
       "\n",
       "       [[1.70514204]],\n",
       "\n",
       "       [[0.63772722]],\n",
       "\n",
       "       [[1.8012141 ]],\n",
       "\n",
       "       [[2.0805614 ]]])\n",
       "Coordinates:\n",
       "  * observation_date  (observation_date) datetime64[ns] 96B 2022-02-01 ... 20...\n",
       "  * component         (component) object 8B &#x27;fred_PCEPI&#x27;\n",
       "Dimensions without coordinates: sample\n",
       "Attributes:\n",
       "    static_covariates:  None\n",
       "    hierarchy:          None\n",
       "    metadata:           None</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>TimeSeries (DataArray)</div><div class='xr-array-name'></div><ul class='xr-dim-list'><li><span class='xr-has-index'>observation_date</span>: 12</li><li><span class='xr-has-index'>component</span>: 1</li><li><span>sample</span>: 1</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-72bed0f3-23a1-4ba5-bc7a-95c3aaed0c8a' class='xr-array-in' type='checkbox' checked><label for='section-72bed0f3-23a1-4ba5-bc7a-95c3aaed0c8a' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>1.148 2.077 1.278 0.9665 0.4203 ... 2.077 1.705 0.6377 1.801 2.081</span></div><div class='xr-array-data'><pre>array([[[1.14841955]],\n",
       "\n",
       "       [[2.07714733]],\n",
       "\n",
       "       [[1.27757226]],\n",
       "\n",
       "       [[0.96648556]],\n",
       "\n",
       "       [[0.42033161]],\n",
       "\n",
       "       [[2.33076042]],\n",
       "\n",
       "       [[1.19695445]],\n",
       "\n",
       "       [[2.07689132]],\n",
       "\n",
       "       [[1.70514204]],\n",
       "\n",
       "       [[0.63772722]],\n",
       "\n",
       "       [[1.8012141 ]],\n",
       "\n",
       "       [[2.0805614 ]]])</pre></div></div></li><li class='xr-section-item'><input id='section-647dadcd-7939-4ce7-8801-2c8ada87f688' class='xr-section-summary-in' type='checkbox'  checked><label for='section-647dadcd-7939-4ce7-8801-2c8ada87f688' class='xr-section-summary' >Coordinates: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>observation_date</span></div><div class='xr-var-dims'>(observation_date)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2022-02-01 ... 2023-01-01</div><input id='attrs-07c462c0-9492-4b9a-a74b-36192441499e' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-07c462c0-9492-4b9a-a74b-36192441499e' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-645243ff-49ce-4884-bce9-6c222ce0af1e' class='xr-var-data-in' type='checkbox'><label for='data-645243ff-49ce-4884-bce9-6c222ce0af1e' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2022-02-01T00:00:00.000000000&#x27;, &#x27;2022-03-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-04-01T00:00:00.000000000&#x27;, &#x27;2022-05-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-06-01T00:00:00.000000000&#x27;, &#x27;2022-07-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-08-01T00:00:00.000000000&#x27;, &#x27;2022-09-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-10-01T00:00:00.000000000&#x27;, &#x27;2022-11-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-12-01T00:00:00.000000000&#x27;, &#x27;2023-01-01T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>component</span></div><div class='xr-var-dims'>(component)</div><div class='xr-var-dtype'>object</div><div class='xr-var-preview xr-preview'>&#x27;fred_PCEPI&#x27;</div><input id='attrs-5ec072da-d976-4576-9cb1-1fe3ce7cabea' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-5ec072da-d976-4576-9cb1-1fe3ce7cabea' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-4f1e3586-11ed-4080-afdd-d06ea3a53f01' class='xr-var-data-in' type='checkbox'><label for='data-4f1e3586-11ed-4080-afdd-d06ea3a53f01' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;fred_PCEPI&#x27;], dtype=object)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-cd5cb963-b024-4f59-b17f-606f2eba2f0a' class='xr-section-summary-in' type='checkbox'  ><label for='section-cd5cb963-b024-4f59-b17f-606f2eba2f0a' class='xr-section-summary' >Indexes: <span>(2)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>observation_date</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-bf82c174-c3cb-4e54-abfe-fa8112846981' class='xr-index-data-in' type='checkbox'/><label for='index-bf82c174-c3cb-4e54-abfe-fa8112846981' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2022-02-01&#x27;, &#x27;2022-03-01&#x27;, &#x27;2022-04-01&#x27;, &#x27;2022-05-01&#x27;,\n",
       "               &#x27;2022-06-01&#x27;, &#x27;2022-07-01&#x27;, &#x27;2022-08-01&#x27;, &#x27;2022-09-01&#x27;,\n",
       "               &#x27;2022-10-01&#x27;, &#x27;2022-11-01&#x27;, &#x27;2022-12-01&#x27;, &#x27;2023-01-01&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;observation_date&#x27;, freq=&#x27;MS&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>component</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-08b85e7a-e560-4afc-a9bc-e1f8161983df' class='xr-index-data-in' type='checkbox'/><label for='index-08b85e7a-e560-4afc-a9bc-e1f8161983df' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([&#x27;fred_PCEPI&#x27;], dtype=&#x27;object&#x27;, name=&#x27;component&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-4d14e549-fdc5-4fec-aeb3-6e3a0e3bbf8e' class='xr-section-summary-in' type='checkbox'  checked><label for='section-4d14e549-fdc5-4fec-aeb3-6e3a0e3bbf8e' class='xr-section-summary' >Attributes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>static_covariates :</span></dt><dd>None</dd><dt><span>hierarchy :</span></dt><dd>None</dd><dt><span>metadata :</span></dt><dd>None</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<TimeSeries (DataArray) (observation_date: 12, component: 1, sample: 1)> Size: 96B\n",
       "array([[[1.14841955]],\n",
       "\n",
       "       [[2.07714733]],\n",
       "\n",
       "       [[1.27757226]],\n",
       "\n",
       "       [[0.96648556]],\n",
       "\n",
       "       [[0.42033161]],\n",
       "\n",
       "       [[2.33076042]],\n",
       "\n",
       "       [[1.19695445]],\n",
       "\n",
       "       [[2.07689132]],\n",
       "\n",
       "       [[1.70514204]],\n",
       "\n",
       "       [[0.63772722]],\n",
       "\n",
       "       [[1.8012141 ]],\n",
       "\n",
       "       [[2.0805614 ]]])\n",
       "Coordinates:\n",
       "  * observation_date  (observation_date) datetime64[ns] 96B 2022-02-01 ... 20...\n",
       "  * component         (component) object 8B 'fred_PCEPI'\n",
       "Dimensions without coordinates: sample\n",
       "Attributes:\n",
       "    static_covariates:  None\n",
       "    hierarchy:          None\n",
       "    metadata:           None"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(12,series=y_train, past_covariates=X_valid,future_covariates=X_valid_future)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
