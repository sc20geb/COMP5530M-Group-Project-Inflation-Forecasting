{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA and SARIMA\n",
    "This notebook develops the arima model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pmdarima as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import pickle\n",
    "import sys\n",
    "sys.path.append(os.path.join('..', 'Helper'))\n",
    "sys.path.append(os.path.join('..', '..', 'Evaluation', 'Helper'))\n",
    "from dataPreprocessing import make_stationary, granger_causes, rank_features_ccf, get_untransformed_exog\n",
    "from evaluation_helpers import display_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd=Path.cwd()\n",
    "data= pd.read_csv(cwd.parent.parent / 'Data' /'Train'/'train1990s.csv',parse_dates=[0],date_format='%m%Y',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmodifiedDf = get_untransformed_exog(data)\n",
    "\n",
    "split= round(unmodifiedDf.shape[0]*0.9)\n",
    "train= unmodifiedDf.iloc[:split+1,:]\n",
    "valid= unmodifiedDf.iloc[split+1:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "ARIMA requires the data to be stationary, however AutoArima kindly handles it for you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make seasonal False for ARIMA (otherwise its SARIMA)\n",
    "arima_model= pm.auto_arima(train['fred_PCEPI'],start_p=1, start_q=1,seasonal=False, stepwise=True)\n",
    "preds=np.array(arima_model.predict(valid.shape[0]))\n",
    "Y= np.array(valid.iloc[:,0])\n",
    "\n",
    "#could instead use evaluate_model here, consider changing\n",
    "print(f'RMSE: {root_mean_squared_error(Y,preds)}')\n",
    "display_results(Y, preds, list(valid.index), 'ARIMA', print_dates=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make seasonal False for ARIMAX (otherwise its SARIMA)\n",
    "arimax_model= pm.auto_arima(y=train['fred_PCEPI'],X=train.drop(['fred_PCEPI'],axis=1),start_p=1, start_q=1,seasonal=False, stepwise=True)\n",
    "preds=np.array(arimax_model.predict(valid.shape[0],valid.drop(['fred_PCEPI'],axis=1)))\n",
    "Y= np.array(valid['fred_PCEPI'])\n",
    "\n",
    "print(f'RMSE: {root_mean_squared_error(Y,preds)}')\n",
    "display_results(Y, preds, list(valid.index), 'ARIMAX', print_dates=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change seasonal to True and m=12 for SARIMA\n",
    "sarima_model= pm.auto_arima(train['fred_PCEPI'],start_p=1, start_q=1,seasonal=True,m=12, stepwise=True)\n",
    "preds=np.array(sarima_model.predict(valid['fred_PCEPI'].shape[0]))\n",
    "Y= np.array(valid.iloc[:,0])\n",
    "print(f'RMSE: {root_mean_squared_error(Y,preds)}')\n",
    "display_results(Y, preds, list(valid.index), 'SARIMA', print_dates=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change seasonal to True and m=12 for SARIMA\n",
    "sarimax_model= pm.auto_arima(y=train['fred_PCEPI'],X=train.drop(['fred_PCEPI'],axis=1),start_p=1, start_q=1,m=12,seasonal=True, stepwise=True)\n",
    "preds=np.array(sarimax_model.predict(valid.shape[0],valid.drop(['fred_PCEPI'],axis=1)))\n",
    "Y= np.array(valid['fred_PCEPI'])\n",
    "\n",
    "print(f'RMSE: {root_mean_squared_error(Y,preds)}')\n",
    "display_results(Y, preds, list(valid.index), 'SARIMAX', print_dates=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown ARIMAX and SARIMAX are sensitive to large numbers of exogenous variables, therefore some method is required to rank the best features:\n",
    "mutual_info_regression\n",
    "cross correlation\n",
    "Variance Inflation Factor (VIF) (Remove variables with VIF > 5â€“10 to avoid unstable coefficient estimates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection:\n",
    "ARIMAX and SARIMAX are sensitive to the amount of feratures used and should"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noncaused(df:pd.DataFrame, targetCol:str):\n",
    "\n",
    "    '''\n",
    "    This function removes features which are not granger caused.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: panda dataframe with all exogenous variables and target.\n",
    "\n",
    "    targetCol: name of target variable in df.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Returns a datframe with all features being granger caused.\n",
    "    '''\n",
    "\n",
    "    df_selected= df.copy()\n",
    "    \n",
    "    dropCols=[]\n",
    "    # Loop over columns:\n",
    "    for col in df_selected.columns.drop(targetCol):\n",
    "\n",
    "        stationary= make_stationary(df_selected,col,targetCol)# makes stime series stationary\n",
    "\n",
    "        #remove columns which do not achieve stationarity\n",
    "        if stationary is np.nan:\n",
    "            dropCols.append(col)\n",
    "            \n",
    "        # Removes columnns which do not granger cause (sanity check)\n",
    "        elif not granger_causes(df_selected,col,targetCol):\n",
    "            dropCols.append(col)\n",
    "    \n",
    "    return df_selected.drop(dropCols, axis=1)\n",
    "\n",
    "def SARIMAX_grid_search(ranked_df,targetCol, valid=0.1, top_n=20, verbose=False):\n",
    "    '''\n",
    "    Performs a grid search on the optimal number of exogenous variables to use.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ranked_df: pandas dataframe where the columns are ordered in descending order of predictive power (ccf in this case).\n",
    "\n",
    "    targetCol: name of target column in ranked_df.\n",
    "\n",
    "    valid: the validation size (defaults to 10% of training data).\n",
    "\n",
    "    top_n: gridsearch up top_n exogenous variables in total.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple, where the 1st element is the optimal RMSE value,\n",
    "    the 2nd element is the best number of features to use. \n",
    "    '''\n",
    "    # Separate the target and exogenous variables:\n",
    "    target= ranked_df[targetCol]\n",
    "    df_exog= ranked_df.drop(targetCol, axis=1)\n",
    "\n",
    "    # Split into training data and validation data\n",
    "    split= round(ranked_df.shape[0]*(1. - valid))\n",
    "    train_exog= df_exog.iloc[:split+1,:]\n",
    "    valid_exog= df_exog.iloc[split+1:,:]\n",
    "\n",
    "    train_target= target.iloc[:split+1]\n",
    "    valid_target= target.iloc[split+1:]\n",
    "\n",
    "    # Values used to find the optimal solution\n",
    "    best_score=999\n",
    "    best_n=-1\n",
    "\n",
    "    # loop over possible n's:\n",
    "    for i in range(1,top_n+1):\n",
    "        if verbose: print(f'Training with {i+1} exogenous variables...')\n",
    "        #train model:\n",
    "        sarimax_model= pm.auto_arima(y=train_target,X=train_exog.iloc[:,:i],start_p=1, start_q=1,m=12,seasonal=True, stepwise=True)\n",
    "\n",
    "        #Infer on the validation data:\n",
    "        preds=np.array(sarimax_model.predict(valid_exog.shape[0],valid_exog.iloc[:,:i]))\n",
    "        \n",
    "        # Calculate RMSE score\n",
    "        Y= np.array(valid_target)\n",
    "        score=root_mean_squared_error(Y,preds)\n",
    "\n",
    "        # Update if a new minimum is found:\n",
    "        if score < best_score:\n",
    "            if verbose: print(f'New best score {score:.6f} found.')\n",
    "            best_score=score\n",
    "            best_n=i\n",
    "\n",
    "\n",
    "    print(f\"Best score: {best_score}\")\n",
    "    print(f\"Best number of features: {best_n}\")\n",
    "\n",
    "    return best_score, best_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal number of exogenous variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-granger-caused features, then find their ranking order by cross-correlation\n",
    "caused_df = remove_noncaused(unmodifiedDf,'fred_PCEPI')\n",
    "ranked_columns=rank_features_ccf(caused_df,'fred_PCEPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder DataFrame of caused features according to rankings\n",
    "# Removed target from caused_df to ensure has the same columns as provided for ordering, then add target back in at front\n",
    "ranked_df = caused_df.drop('fred_PCEPI', axis=1)\n",
    "ranked_df = ranked_df[list(ranked_columns)]\n",
    "ranked_df.insert(0, 'fred_PCEPI', caused_df['fred_PCEPI'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_score,best_n=SARIMAX_grid_search(ranked_df,'fred_PCEPI', top_n=20,valid=0.2)\n",
    "best_score,best_n=SARIMAX_grid_search(ranked_df,'fred_PCEPI', top_n=1,valid=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10% validation size:\n",
    "\n",
    "Best score: 0.39031823257263404\n",
    "\n",
    "Best number of features: 11\n",
    "\n",
    "20% validation size:\n",
    "\n",
    "Best score: 0.20367743319713377\n",
    "\n",
    "Best number of features: 9\n",
    "\n",
    "Using a validaion size of 10% overfitted, hence 20% generalized better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train final model:\n",
    "\n",
    "trains the model using the optimal parameters and saves the model to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target= ranked_df['fred_PCEPI']\n",
    "df_exog= ranked_df.drop('fred_PCEPI', axis=1)\n",
    "sarimax_model_optimal_full= pm.auto_arima(y=target,X=df_exog.iloc[:,:best_n],start_p=1, start_q=1,m=12,seasonal=True, stepwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SARIMAX.pkl','wb') as f:\n",
    "    pickle.dump(sarimax_model_optimal_full,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 9 column names\n",
    "used_cols=df_exog.columns[:best_n]\n",
    "test_data=pd.read_csv(cwd.parent.parent / 'Data' /'Test'/'test1990s.csv',parse_dates=[0],date_format='%m%Y',index_col=0)\n",
    "test_exog= test_data[used_cols]\n",
    "test_targets=test_data['fred_PCEPI']\n",
    "display(test_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('SARIMAX.pkl','rb') as f:\n",
    "    loaded_model=pickle.load(f)\n",
    "\n",
    "    preds=np.array(loaded_model.predict(test_exog.shape[0],test_exog))\n",
    "    Y= np.array(test_targets)\n",
    "\n",
    "    display(preds.shape, Y.shape)\n",
    "\n",
    "    print(f'RMSE: {root_mean_squared_error(Y,preds)}')\n",
    "    display_results(Y, preds, list(test_exog.index), 'SARIMAX', print_dates=10)\n",
    "    np.save('../../Predictions/SARIMAX.npy',preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
