{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up two levels from notebook (Training/MLR) to project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Project root added to sys.path:\", project_root)\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_path = os.path.join(project_root, 'Models', 'Weights', 'MLR')\n",
    "os.makedirs(model_save_path, exist_ok=True)  # Creates directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from Training.Helper.dataPreprocessing import TRAIN_DATA_PATH_1990S, integer_index\n",
    "\n",
    "date_col = 'observation_date'\n",
    "\n",
    "# Load and format training data (only using PCEPI)\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH_1990S, parse_dates=[date_col], date_format=\"%m/%y%\").iloc[:,:2]\n",
    "train_df['group'] = 0\n",
    "train_df = integer_index(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training.Helper.dataPreprocessing import train_val_test_split\n",
    "import numpy as np\n",
    "\n",
    "numVals = train_df.shape[0]\n",
    "\n",
    "valRatio = 0.2\n",
    "splitLoc = int(numVals*(1-valRatio))\n",
    "\n",
    "target_col = 'fred_PCEPI'\n",
    "\n",
    "# input values are the integer indices, output valuesthe PCEPI\n",
    "train_X, train_y, val_X, val_y, _, _ = train_val_test_split(list(train_df.index), train_df[target_col], train_size=0.8, val_size=0.2)\n",
    "train_X, val_X = np.array(train_X).reshape(-1, 1), np.array(val_X).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "#display(train.index.values.reshape(-1, 1).shape)\n",
    "#linear model on just PCEPI\n",
    "regr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = regr.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = regr.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y_hats = np.concatenate((y_train_hat, y_hat))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "ax = plt.axes()\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "plt.locator_params(axis='x', nbins=10)\n",
    "plt.plot(train_df['observation_date'], y_hats)\n",
    "plt.plot(train_df['observation_date'], train_df['fred_PCEPI'])\n",
    "ax.fill_between(train_df['observation_date'][splitLoc:], train_df['fred_PCEPI'][0], y_hats[-1], facecolor='green', step='pre', alpha=0.5)\n",
    "plt.title('Linear Regressor Predictions on PCEPI')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PCEPI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "linearValR2 = r2_score(val_y, y_hat)\n",
    "linearTrainR2 = r2_score(train_y, y_train_hat)\n",
    "linearValRMSE = root_mean_squared_error(val_y, y_hat)\n",
    "linearTrainRMSE = root_mean_squared_error(train_y, y_train_hat)\n",
    "#display(linearValError, linearTrainError)\n",
    "RMSEDf = pd.DataFrame(np.concatenate((np.array(['Linear']), np.array([linearTrainRMSE, linearValRMSE, linearTrainR2, linearValR2]))).reshape(1, -1), columns=['Model', 'Training RMSE', 'Validation RMSE', 'Training R2', 'Validation R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSEDf.to_csv('Linear_PCEPI_eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_val_index = val_X[-1][0]\n",
    "print(f'Final date in validation set: {train_df.iloc[final_val_index]['observation_date']}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training.Helper.dataPreprocessing import TEST_DATA_PATH_1990S, integer_index\n",
    "\n",
    "date_col = 'observation_date'\n",
    "\n",
    "# Load and format training data (only using PCEPI)\n",
    "test_df = pd.read_csv(TEST_DATA_PATH_1990S, parse_dates=[date_col], date_format=\"%m/%y%\").iloc[:,:2]\n",
    "test_df = integer_index(test_df, start=final_val_index+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = np.array(list(test_df.index)).reshape(-1, 1), test_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = regr.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_X, test_y)\n",
    "plt.plot(test_X, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date_end = int(len(train_df)*0.8)\n",
    "val_date_end = len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Make a plot showing all actual values and all predictions, including validation and test sets highlighted in different colours\n",
    "\n",
    "y_hats = np.concatenate((y_train_hat, y_hat, y_test_hat))\n",
    "ys = np.concatenate((train_y, val_y, test_y))\n",
    "xs = np.concatenate((train_X, val_X, test_X))\n",
    "df_dates = pd.concat((train_df[date_col], test_df[date_col]))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "ax = plt.axes()\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "plt.locator_params(axis='x', nbins=10)\n",
    "plt.plot(df_dates, y_hats)\n",
    "plt.plot(df_dates, ys)\n",
    "ax.fill_between(df_dates[train_date_end:val_date_end+1], train_y[0], max(y_hats[-1], ys[-1]), facecolor='green', step='pre', alpha=0.5)\n",
    "ax.fill_between(df_dates[val_date_end:], train_y[0], max(y_hats[-1], ys[-1]), facecolor='orange', step='pre', alpha=0.5)\n",
    "plt.title('Linear Regressor Predictions on PCEPI (with test)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PCEPI')\n",
    "plt.legend(['Linear prediction', 'Actual PCEPI'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(project_root, \"Predictions\", \"MLR.npy\")\n",
    "np.save(output_path, y_test_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Forecasting Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict\n",
    "from pytorch_forecasting.models import BaseModel\n",
    "from pytorch_forecasting.metrics.point import RMSE\n",
    "\n",
    "class LinearRegressionModule(torch.nn.Module):\n",
    " \n",
    "    def __init__(self, input_size : int, output_size : int):\n",
    "        super(LinearRegressionModule, self).__init__()\n",
    "        #a single 1-1 linear function\n",
    "        self.linear = torch.nn.Linear(input_size, output_size)\n",
    " \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(BaseModel):\n",
    "    def __init__(self, input_size: int, output_size: int, **kwargs):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(loss=RMSE(), **kwargs)\n",
    "        self.network = LinearRegressionModule(\n",
    "            input_size=self.hparams.input_size,\n",
    "            output_size=self.hparams.output_size\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        network_input = x[\"encoder_cont\"].squeeze(-1)\n",
    "        prediction = self.network(network_input)\n",
    "\n",
    "        # rescale predictions into target space\n",
    "        prediction = self.transform_output(prediction, target_scale=x[\"target_scale\"])\n",
    "\n",
    "        # We need to return a dictionary that at least contains the prediction\n",
    "        # The parameter can be directly forwarded from the input.\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "\n",
    "encoderLength = 10\n",
    "predictionLength = 10\n",
    "\n",
    "trainDataset = TimeSeriesDataSet(\n",
    "    train,\n",
    "    group_ids=['group'],\n",
    "    target='fred_PCEPI',\n",
    "    time_idx='time_idx',\n",
    "    min_encoder_length=encoderLength,\n",
    "    max_encoder_length=encoderLength,\n",
    "    min_prediction_length=predictionLength,\n",
    "    max_prediction_length=predictionLength,\n",
    "    time_varying_unknown_reals=['fred_PCEPI'],\n",
    ")\n",
    "\n",
    "valDataset = TimeSeriesDataSet.from_dataset(trainDataset, train_df, predict=True, stop_randomization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "trainLoader = trainDataset.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "valLoader = valDataset.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No categorical variables, one continuous variable, one continuous target variable. Normalise target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel.from_dataset(trainDataset, input_size=encoderLength, output_size=predictionLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "\n",
    "#turned off logging, but by default this produces Tensorboard-interpretable logs every 50 steps\n",
    "trainer = Trainer(fast_dev_run=False, callbacks=[early_stop_callback], logger=False)\n",
    "trainer.fit(model, train_dataloaders=trainLoader, val_dataloaders=valLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above takes a long time to train a simple linear regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    valLoader, return_y=True, trainer_kwargs=dict(accelerator=\"cpu\")\n",
    ")\n",
    "RMSE()(predictions.output, predictions.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions = model.predict(\n",
    "    valLoader, mode=\"raw\", return_x=True, trainer_kwargs=dict(accelerator=\"cpu\")\n",
    ")\n",
    "print(raw_predictions.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_prediction(\n",
    "    raw_predictions.x, raw_predictions.output, idx=0, add_loss_to_title=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seem to have got unlucky here?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
