{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up two levels from notebook (Training/MLR) to project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Project root added to sys.path:\", project_root)\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_path = os.path.join('.')\n",
    "os.makedirs(model_save_path, exist_ok=True)  # Creates directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from Training.Helper.dataPreprocessing import TRAIN_DATA_PATH_1990S, integer_index\n",
    "\n",
    "date_col = 'observation_date'\n",
    "\n",
    "# Load and format training data (only using PCEPI)\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH_1990S, parse_dates=[date_col], date_format=\"%m/%y%\")\n",
    "train_df['group'] = 0\n",
    "train_df = integer_index(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training.Helper.dataPreprocessing import TRAIN_DATA_SPLIT\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "target_col = 'fred_PCEPI'\n",
    "\n",
    "# input values are the integer indices, output values are PCEPI\n",
    "train_X, val_X, train_y, val_y = train_test_split(list(train_df.index), train_df[target_col].values, train_size=TRAIN_DATA_SPLIT, shuffle=False)\n",
    "train_X, val_X = np.array(train_X).reshape(-1, 1), np.array(val_X).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "#linear model on just PCEPI\n",
    "regr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = regr.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = regr.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "y_hats = np.concatenate((y_train_hat, y_hat))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "ax = plt.axes()\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "plt.locator_params(axis='x', nbins=10)\n",
    "plt.plot(train_df['observation_date'], y_hats)\n",
    "plt.plot(train_df['observation_date'], train_df['fred_PCEPI'])\n",
    "ax.fill_between(train_df['observation_date'][int(len(train_df)*TRAIN_DATA_SPLIT):], train_df['fred_PCEPI'][0], val_y[-1], facecolor='green', step='pre', alpha=0.5)\n",
    "plt.title('Linear Regressor Predictions on PCEPI')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PCEPI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.Helper.evaluation_helpers import calc_metrics_arrays\n",
    "\n",
    "# Metrics for normal linear regression model\n",
    "calc_metrics_arrays(val_y, y_hat, model_names=['LR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-'train' on full training set\n",
    "regr.fit(np.concatenate((train_X, val_X)), np.concatenate((train_y, val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_val_index = val_X[-1][0]\n",
    "print(f'Final date in validation set: {train_df.iloc[final_val_index][\"observation_date\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training.Helper.dataPreprocessing import TEST_DATA_PATH_1990S, integer_index\n",
    "\n",
    "date_col = 'observation_date'\n",
    "\n",
    "# Load and format test data (only using PCEPI)\n",
    "test_df = pd.read_csv(TEST_DATA_PATH_1990S, parse_dates=[date_col], date_format=\"%m/%y%\").iloc[:,:2]\n",
    "test_df = integer_index(test_df, start=final_val_index+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = np.array(list(test_df.index)).reshape(-1, 1), test_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = regr.predict(test_X)\n",
    "y_train_hat  = regr.predict(train_X)\n",
    "y_hat = regr.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date_end = int(len(train_df)*TRAIN_DATA_SPLIT)\n",
    "val_date_end = len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Make a plot showing all actual values and all predictions, including validation and test sets highlighted in different colours\n",
    "\n",
    "y_hats = np.concatenate((y_train_hat, y_hat, y_test_hat))\n",
    "ys = np.concatenate((train_y, val_y, test_y))\n",
    "xs = np.concatenate((train_X, val_X, test_X))\n",
    "df_dates = pd.concat((train_df[date_col], test_df[date_col]))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "ax = plt.axes()\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(10))\n",
    "plt.locator_params(axis='x', nbins=10)\n",
    "plt.plot(df_dates, y_hats)\n",
    "plt.plot(df_dates, ys)\n",
    "ax.fill_between(df_dates[train_date_end:val_date_end+1], train_y[0], max(y_hats[-1], ys[-1]), facecolor='green', step='pre', alpha=0.5)\n",
    "ax.fill_between(df_dates[val_date_end:], train_y[0], max(y_hats[-1], ys[-1]), facecolor='orange', step='pre', alpha=0.5)\n",
    "plt.title('Linear Regressor Predictions on PCEPI (with test)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PCEPI')\n",
    "plt.legend(['Linear prediction', 'Actual PCEPI'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exog = train_df.drop([target_col], axis=1)\n",
    "train_exog[date_col] = train_exog.index  # Replace date strings with integer indices for the regressor to pick up on\n",
    "train_exog = train_exog.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exog_X, val_exog_X = train_test_split(train_exog, train_size=TRAIN_DATA_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr = linear_model.LinearRegression()\n",
    "mlr.fit(train_exog_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_val_exog = mlr.predict(val_exog_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = regr.predict(test_X)\n",
    "horizons = [1, 3, 6, 12]\n",
    "predictions = [preds.copy() for _ in horizons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLR forecasts are all the same regardless of horizon, since does not adapt to input data\n",
    "for i, horizon in enumerate(horizons):\n",
    "    output_path = os.path.join(project_root, \"Predictions\", f\"Horizon{horizon}\", f\"MLR_horizon_{horizon}.npy\")\n",
    "    np.save(output_path, predictions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Forecasting Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict\n",
    "from pytorch_forecasting.models import BaseModel\n",
    "from pytorch_forecasting.metrics.point import RMSE\n",
    "\n",
    "class LinearRegressionModule(torch.nn.Module):\n",
    " \n",
    "    def __init__(self, input_size : int, output_size : int):\n",
    "        super(LinearRegressionModule, self).__init__()\n",
    "        #a single 1-1 linear function\n",
    "        self.linear = torch.nn.Linear(input_size, output_size)\n",
    " \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(BaseModel):\n",
    "    def __init__(self, input_size: int, output_size: int, **kwargs):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(loss=RMSE(), **kwargs)\n",
    "        self.network = LinearRegressionModule(\n",
    "            input_size=self.hparams.input_size,\n",
    "            output_size=self.hparams.output_size\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        network_input = x[\"encoder_cont\"].squeeze(-1)\n",
    "        prediction = self.network(network_input)\n",
    "\n",
    "        # rescale predictions into target space\n",
    "        prediction = self.transform_output(prediction, target_scale=x[\"target_scale\"])\n",
    "\n",
    "        # We need to return a dictionary that at least contains the prediction\n",
    "        # The parameter can be directly forwarded from the input.\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "\n",
    "encoderLength = 10\n",
    "predictionLength = 10\n",
    "\n",
    "trainDataset = TimeSeriesDataSet(\n",
    "    train,\n",
    "    group_ids=['group'],\n",
    "    target='fred_PCEPI',\n",
    "    time_idx='time_idx',\n",
    "    min_encoder_length=encoderLength,\n",
    "    max_encoder_length=encoderLength,\n",
    "    min_prediction_length=predictionLength,\n",
    "    max_prediction_length=predictionLength,\n",
    "    time_varying_unknown_reals=['fred_PCEPI'],\n",
    ")\n",
    "\n",
    "valDataset = TimeSeriesDataSet.from_dataset(trainDataset, train_df, predict=True, stop_randomization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "trainLoader = trainDataset.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "valLoader = valDataset.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No categorical variables, one continuous variable, one continuous target variable. Normalise target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel.from_dataset(trainDataset, input_size=encoderLength, output_size=predictionLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "\n",
    "#turned off logging, but by default this produces Tensorboard-interpretable logs every 50 steps\n",
    "trainer = Trainer(fast_dev_run=False, callbacks=[early_stop_callback], logger=False)\n",
    "trainer.fit(model, train_dataloaders=trainLoader, val_dataloaders=valLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above takes a long time to train a simple linear regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    valLoader, return_y=True, trainer_kwargs=dict(accelerator=\"cpu\")\n",
    ")\n",
    "RMSE()(predictions.output, predictions.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions = model.predict(\n",
    "    valLoader, mode=\"raw\", return_x=True, trainer_kwargs=dict(accelerator=\"cpu\")\n",
    ")\n",
    "print(raw_predictions.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_prediction(\n",
    "    raw_predictions.x, raw_predictions.output, idx=0, add_loss_to_title=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seem to have got unlucky here?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
