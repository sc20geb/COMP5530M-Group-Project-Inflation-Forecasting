{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up two levels from notebook (Training/MLR) to project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "print(\"Project root added to sys.path:\", project_root)\n",
    "\n",
    "# Ensure the model save directory exists\n",
    "model_save_path = os.path.join(project_root, 'Models', 'Weights', 'MLR')\n",
    "os.makedirs(model_save_path, exist_ok=True)  # Creates directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from Training.Helper.dataPreprocessing import TRAIN_DATA_PATH_1990S, integer_index\n",
    "\n",
    "date_col = 'observation_date'\n",
    "\n",
    "# Load and format training data (only using PCEPI)\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH_1990S, parse_dates=[date_col], date_format=\"%m/%y%\").iloc[:,:2]\n",
    "train_df = integer_index(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "target_col = 'fred_PCEPI'\n",
    "\n",
    "# input values are the integer indices (not dates), output values are PCEPI\n",
    "train_X, val_X, train_y, val_y = train_test_split(list(train_df.index), train_df[target_col], train_size=0.8, test_size=0.2, shuffle=False)\n",
    "train_X, val_X = np.array(train_X).reshape(-1, 1), np.array(val_X).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape, val_X.shape, train_y.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "#display(train.index.values.reshape(-1, 1).shape)\n",
    "#linear model on just PCEPI\n",
    "regr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = regr.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hat = regr.predict(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.Helper.evaluation_helpers import display_results, evaluate_model\n",
    "full_X = np.concatenate((train_X, val_X))\n",
    "full_y = np.concatenate((train_y, val_y))\n",
    "train_dates = train_df['observation_date'].values\n",
    "y_hats = np.concatenate((y_train_hat, y_hat))\n",
    "\n",
    "display_results(full_y, y_hats, train_dates, 'LR', highlight_date_indices=[(val_X[0][0], val_X[-1][0])], highlight_colours = ['green'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-'train' on full training set\n",
    "regr.fit(full_X, full_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.Helper.evaluation_helpers import calc_metrics\n",
    "\n",
    "preds_and_vals_df = pd.DataFrame(np.hstack((y_hat.reshape(-1, 1), val_y.values.reshape(-1, 1))), columns=['LR', 'ground_truth'])\n",
    "calc_metrics(preds_and_vals_df, horizon=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_val_index = val_X[-1][0]\n",
    "print(f'Final date in validation set: {train_df.iloc[final_val_index][\"observation_date\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Training.Helper.dataPreprocessing import TEST_DATA_PATH_1990S, integer_index\n",
    "\n",
    "# Load and format test data (only using PCEPI)\n",
    "test_df = pd.read_csv(TEST_DATA_PATH_1990S, parse_dates=[date_col], date_format=\"%m/%y%\").iloc[:,:2]\n",
    "test_df = integer_index(test_df, start=final_val_index+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, test_y = np.array(list(test_df.index)).reshape(-1, 1), test_df[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_hat = regr.predict(test_X)\n",
    "y_train_hat  = regr.predict(train_X)\n",
    "y_hat = regr.predict(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_date_end = train_X[-1][0]+1\n",
    "val_date_end = val_X[-1][0]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation.Helper.evaluation_helpers import display_results\n",
    "\n",
    "ys = np.concatenate((train_y, val_y, test_y))\n",
    "y_hats = np.concatenate((y_train_hat, y_hat, y_test_hat))\n",
    "xs = np.concatenate((train_X, val_X, test_X))\n",
    "df_dates = pd.concat((train_df[date_col], test_df[date_col]))\n",
    "\n",
    "display_results(ys, y_hats, df_dates.values, 'LR', highlight_date_indices=[(train_date_end, val_date_end), (val_date_end, xs[-1][0])], highlight_colours=['green', 'orange'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(project_root, \"Predictions\", \"LR.npy\")\n",
    "np.save(output_path, y_test_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Exogenous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Training.Helper.dataPreprocessing import TRAIN_DATA_PATH_1990S, integer_index\n",
    "\n",
    "date_col = 'observation_date'\n",
    "\n",
    "# Load and format training data (only using PCEPI)\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH_1990S, parse_dates=[date_col], date_format=\"%m/%y%\")\n",
    "train_df = integer_index(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train_df[target_col]\n",
    "#train_exog only contains exogenous variables in floating point format\n",
    "train_exog = train_df.drop([target_col, 'observation_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train_exog contains only floating point values: {(train_exog.dtypes == \"float64\").all()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in the integer index for the model\n",
    "train_exog['integer_index'] = train_exog.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "#display(train.index.values.reshape(-1, 1).shape)\n",
    "#linear model on just PCEPI\n",
    "regr.fit(train_exog.values, train_target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and format training data (only using PCEPI)\n",
    "test_df = pd.read_csv(TEST_DATA_PATH_1990S, parse_dates=[date_col], date_format=\"%m/%y%\")\n",
    "test_df = integer_index(test_df, start=train_exog.index[-1]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = test_df[target_col]\n",
    "#train_exog only contains exogenous variables in floating point format\n",
    "test_exog = test_df.drop([target_col, date_col], axis=1)\n",
    "# add in the integer index for the model\n",
    "test_exog['integer_index'] = test_exog.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = regr.predict(test_exog.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicts a very low number for some reason, there must be a variable throwing it off\n",
    "regr.predict(test_exog.iloc[9].values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(test_target.values, test_preds, test_df[date_col].values, 'MLR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the model generally slightlty underpredicts but swings largely with the exogenous values at 10/2024. More analysis will be required to identify the cause of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(project_root, \"Predictions\", \"MLR.npy\")\n",
    "np.save(output_path, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Forecasting Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Dict\n",
    "from pytorch_forecasting.models import BaseModel\n",
    "from pytorch_forecasting.metrics.point import RMSE\n",
    "\n",
    "class LinearRegressionModule(torch.nn.Module):\n",
    " \n",
    "    def __init__(self, input_size : int, output_size : int):\n",
    "        super(LinearRegressionModule, self).__init__()\n",
    "        #a single 1-1 linear function\n",
    "        self.linear = torch.nn.Linear(input_size, output_size)\n",
    " \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(BaseModel):\n",
    "    def __init__(self, input_size: int, output_size: int, **kwargs):\n",
    "        # saves arguments in signature to `.hparams` attribute, mandatory call - do not skip this\n",
    "        self.save_hyperparameters()\n",
    "        # pass additional arguments to BaseModel.__init__, mandatory call - do not skip this\n",
    "        super().__init__(loss=RMSE(), **kwargs)\n",
    "        self.network = LinearRegressionModule(\n",
    "            input_size=self.hparams.input_size,\n",
    "            output_size=self.hparams.output_size\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        # x is a batch generated based on the TimeSeriesDataset\n",
    "        network_input = x[\"encoder_cont\"].squeeze(-1)\n",
    "        prediction = self.network(network_input)\n",
    "\n",
    "        # rescale predictions into target space\n",
    "        prediction = self.transform_output(prediction, target_scale=x[\"target_scale\"])\n",
    "\n",
    "        # We need to return a dictionary that at least contains the prediction\n",
    "        # The parameter can be directly forwarded from the input.\n",
    "        # The conversion to a named tuple can be directly achieved with the `to_network_output` function.\n",
    "        return self.to_network_output(prediction=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "\n",
    "encoderLength = 10\n",
    "predictionLength = 10\n",
    "\n",
    "trainDataset = TimeSeriesDataSet(\n",
    "    train,\n",
    "    group_ids=['group'],\n",
    "    target='fred_PCEPI',\n",
    "    time_idx='time_idx',\n",
    "    min_encoder_length=encoderLength,\n",
    "    max_encoder_length=encoderLength,\n",
    "    min_prediction_length=predictionLength,\n",
    "    max_prediction_length=predictionLength,\n",
    "    time_varying_unknown_reals=['fred_PCEPI'],\n",
    ")\n",
    "\n",
    "valDataset = TimeSeriesDataSet.from_dataset(trainDataset, train_df, predict=True, stop_randomization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "trainLoader = trainDataset.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "valLoader = valDataset.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No categorical variables, one continuous variable, one continuous target variable. Normalise target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel.from_dataset(trainDataset, input_size=encoderLength, output_size=predictionLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "\n",
    "#turned off logging, but by default this produces Tensorboard-interpretable logs every 50 steps\n",
    "trainer = Trainer(fast_dev_run=False, callbacks=[early_stop_callback], logger=False)\n",
    "trainer.fit(model, train_dataloaders=trainLoader, val_dataloaders=valLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above takes a long time to train a simple linear regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(\n",
    "    valLoader, return_y=True, trainer_kwargs=dict(accelerator=\"cpu\")\n",
    ")\n",
    "RMSE()(predictions.output, predictions.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions = model.predict(\n",
    "    valLoader, mode=\"raw\", return_x=True, trainer_kwargs=dict(accelerator=\"cpu\")\n",
    ")\n",
    "print(raw_predictions.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_prediction(\n",
    "    raw_predictions.x, raw_predictions.output, idx=0, add_loss_to_title=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seem to have got unlucky here?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
